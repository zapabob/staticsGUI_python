#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Professional Python GUI Statistical Analysis Software
ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«çµ±è¨ˆè§£æã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢

Author: Ryo Minegishi
Email: r.minegishi1987@gmail.com
GitHub: @zapabob
License: MIT
"""

import sys
import os
import json
import pickle
import signal
import time
import uuid
import threading
from datetime import datetime
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# GUI ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

# æ•°å€¤è¨ˆç®—ãƒ»ãƒ‡ãƒ¼ã‚¿å‡¦ç†
import numpy as np
import pandas as pd
import scipy.stats as stats
from scipy import signal as scipy_signal

# çµ±è¨ˆè§£æ
import statsmodels.api as sm
import statsmodels.stats.api as sms
import pingouin as pg
from lifelines import KaplanMeierFitter, CoxPHFitter

# æ©Ÿæ¢°å­¦ç¿’
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
import xgboost as xgb
import lightgbm as lgb

# å¯è¦–åŒ–
import matplotlib.pyplot as plt
import matplotlib.style as mpl_style
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
from tqdm import tqdm
import psutil
import memory_profiler

# ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from professional_utils import (
        professional_logger, performance_monitor, exception_handler,
        security_manager, database_manager
    )
    from professional_reports import report_generator
    PROFESSIONAL_FEATURES_AVAILABLE = True
    print("âœ… ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    PROFESSIONAL_FEATURES_AVAILABLE = False
    print(f"âš ï¸ ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")

# AIçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from ai_integration import ai_analyzer
    AI_INTEGRATION_AVAILABLE = True
except ImportError:
    AI_INTEGRATION_AVAILABLE = False
    print("âš ï¸ AIçµ±åˆæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³ï¼‰")

# CUDA/GPU æ¤œå‡º
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    CUDA_AVAILABLE = torch.cuda.is_available()
    GPU_NAME = torch.cuda.get_device_name(0) if CUDA_AVAILABLE else "None"
    DEVICE = torch.device('cuda' if CUDA_AVAILABLE else 'cpu')
except ImportError:
    CUDA_AVAILABLE = False
    GPU_NAME = "None"
    DEVICE = "cpu"

# è¿½åŠ ã®æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import MinMaxScaler, RobustScaler
from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
from sklearn.svm import SVC, SVR
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor

# ãƒ†ãƒ¼ãƒè¨­å®š
ctk.set_appearance_mode("light")
ctk.set_default_color_theme("blue")
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class SessionManager:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ»é›»æºæ–­ä¿è­·ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, app_instance):
        self.app = app_instance
        self.session_id = str(uuid.uuid4())
        self.backup_dir = Path("backup")
        self.checkpoint_dir = Path("checkpoints")
        self.auto_save_interval = 300  # 5åˆ†é–“éš”
        self.backup_count = 10
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.backup_dir.mkdir(exist_ok=True)
        self.checkpoint_dir.mkdir(exist_ok=True)
        
        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š
        signal.signal(signal.SIGINT, self._emergency_save)
        signal.signal(signal.SIGTERM, self._emergency_save)
        if hasattr(signal, 'SIGBREAK'):
            signal.signal(signal.SIGBREAK, self._emergency_save)
        
        # è‡ªå‹•ä¿å­˜ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹
        self._start_auto_save()
        
        print(f"ğŸ›¡ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹: {self.session_id}")
        print(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {self.backup_dir.absolute()}")
    
    def _start_auto_save(self):
        """è‡ªå‹•ä¿å­˜ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹"""
        self.auto_save_timer = threading.Timer(self.auto_save_interval, self._auto_save)
        self.auto_save_timer.daemon = True
        self.auto_save_timer.start()
    
    def _auto_save(self):
        """å®šæœŸè‡ªå‹•ä¿å­˜"""
        try:
            self.save_session()
            print(f"âœ… è‡ªå‹•ä¿å­˜å®Œäº†: {datetime.now().strftime('%H:%M:%S')}")
        except Exception as e:
            print(f"âŒ è‡ªå‹•ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            self._start_auto_save()  # æ¬¡ã®è‡ªå‹•ä¿å­˜ã‚’äºˆç´„
    
    def _emergency_save(self, signum=None, frame=None):
        """ç·Šæ€¥ä¿å­˜ï¼ˆç•°å¸¸çµ‚äº†æ™‚ï¼‰"""
        print("\nğŸš¨ ç·Šæ€¥ä¿å­˜ã‚’å®Ÿè¡Œä¸­...")
        try:
            self.save_session(emergency=True)
            print("âœ… ç·Šæ€¥ä¿å­˜å®Œäº†")
        except Exception as e:
            print(f"âŒ ç·Šæ€¥ä¿å­˜å¤±æ•—: {e}")
        finally:
            sys.exit(0)
    
    def save_session(self, emergency=False):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        prefix = "emergency_" if emergency else "auto_"
        
        session_data = {
            'session_id': self.session_id,
            'timestamp': timestamp,
            'data': getattr(self.app, 'current_data', None),
            'analysis_results': getattr(self.app, 'analysis_results', {}),
            'settings': getattr(self.app, 'user_settings', {}),
            'gpu_info': {'available': CUDA_AVAILABLE, 'name': GPU_NAME}
        }
        
        # JSONä¿å­˜
        json_file = self.checkpoint_dir / f"{prefix}session_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(session_data, f, ensure_ascii=False, indent=2, default=str)
        
        # Pickleä¿å­˜ï¼ˆå¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ç”¨ï¼‰
        pkl_file = self.checkpoint_dir / f"{prefix}session_{timestamp}.pkl"
        with open(pkl_file, 'wb') as f:
            pickle.dump(session_data, f)
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
        self._rotate_backups()
        
        return json_file
    
    def _rotate_backups(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†"""
        backup_files = sorted(self.checkpoint_dir.glob("auto_session_*.json"))
        if len(backup_files) > self.backup_count:
            for old_file in backup_files[:-self.backup_count]:
                old_file.unlink()
                pkl_file = old_file.with_suffix('.pkl')
                if pkl_file.exists():
                    pkl_file.unlink()
    
    def load_latest_session(self):
        """æœ€æ–°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å¾©æ—§"""
        backup_files = sorted(self.checkpoint_dir.glob("*.json"))
        if not backup_files:
            return None
        
        latest_file = backup_files[-1]
        try:
            with open(latest_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©æ—§ã‚¨ãƒ©ãƒ¼: {e}")
            return None

class MLAnalysisWindow:
    """æ©Ÿæ¢°å­¦ç¿’åˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦"""
    
    def __init__(self, parent, data, variable_selection=None):
        self.parent = parent
        self.data = data
        self.variable_selection = variable_selection or {}
        self.window = None
        self.models = {}
        self.results = {}
    
    def show(self):
        """ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¡¨ç¤º"""
        self.window = tk.Toplevel(self.parent)
        self.window.title("ğŸ¤– Machine Learning Analysis")
        self.window.geometry("800x600")
        
        # ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ 
        main_frame = ctk.CTkFrame(self.window)
        main_frame.pack(fill="both", expand=True, padx=10, pady=10)
        
        # ã‚¿ã‚¹ã‚¯é¸æŠ
        task_frame = ctk.CTkFrame(main_frame)
        task_frame.pack(fill="x", padx=5, pady=5)
        
        ctk.CTkLabel(task_frame, text="ğŸ¯ Machine Learning Task", font=("Arial", 16, "bold")).pack(pady=5)
        
        self.task_var = tk.StringVar(value="classification")
        task_radio1 = ctk.CTkRadioButton(task_frame, text="Classification", variable=self.task_var, value="classification")
        task_radio2 = ctk.CTkRadioButton(task_frame, text="Regression", variable=self.task_var, value="regression")
        task_radio1.pack(side="left", padx=20)
        task_radio2.pack(side="left", padx=20)
        
        # ç‰¹å¾´é‡ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¸æŠ
        feature_frame = ctk.CTkFrame(main_frame)
        feature_frame.pack(fill="x", padx=5, pady=5)
        
        ctk.CTkLabel(feature_frame, text="ğŸ“Š Feature & Target Selection").pack(pady=5)
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¸æŠ
        target_frame = ctk.CTkFrame(feature_frame)
        target_frame.pack(fill="x", padx=5, pady=2)
        
        ctk.CTkLabel(target_frame, text="Target Variable:").pack(side="left", padx=5)
        self.target_var = ctk.CTkComboBox(target_frame, values=list(self.data.columns))
        self.target_var.pack(side="left", padx=5)
        
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ
        algo_frame = ctk.CTkFrame(main_frame)
        algo_frame.pack(fill="x", padx=5, pady=5)
        
        ctk.CTkLabel(algo_frame, text="ğŸ”§ Algorithm Selection").pack(pady=5)
        
        self.algo_var = ctk.CTkComboBox(algo_frame, values=[
            "Random Forest", "XGBoost", "LightGBM", "SVM", 
            "Gradient Boosting", "Decision Tree", "Neural Network"
        ])
        self.algo_var.pack(pady=5)
        self.algo_var.set("Random Forest")
        
        # GPUä½¿ç”¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        if CUDA_AVAILABLE:
            gpu_frame = ctk.CTkFrame(main_frame)
            gpu_frame.pack(fill="x", padx=5, pady=5)
            
            self.use_gpu = tk.BooleanVar(value=True)
            gpu_check = ctk.CTkCheckBox(gpu_frame, text=f"âš¡ Use GPU ({GPU_NAME})", variable=self.use_gpu)
            gpu_check.pack(pady=5)
        
        # å®Ÿè¡Œãƒœã‚¿ãƒ³
        button_frame = ctk.CTkFrame(main_frame)
        button_frame.pack(fill="x", padx=5, pady=10)
        
        run_btn = ctk.CTkButton(button_frame, text="ğŸš€ Run Analysis", command=self.run_analysis)
        run_btn.pack(side="left", padx=5)
        
        optimize_btn = ctk.CTkButton(button_frame, text="âš™ï¸ Hyperparameter Optimization", command=self.optimize_hyperparameters)
        optimize_btn.pack(side="left", padx=5)
        
        # çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
        self.result_text = ctk.CTkTextbox(main_frame, height=300)
        self.result_text.pack(fill="both", expand=True, padx=5, pady=5)
    
    def run_analysis(self):
        """æ©Ÿæ¢°å­¦ç¿’åˆ†æå®Ÿè¡Œ"""
        try:
            target_col = self.target_var.get()
            if not target_col:
                messagebox.showwarning("Warning", "Please select target variable")
                return
            
            self.result_text.delete("1.0", "end")
            self.result_text.insert("1.0", "ğŸ¤– Starting Machine Learning Analysis...\n\n")
            
            # å¤‰æ•°é¸æŠã®æ´»ç”¨
            if self.variable_selection.get('control_variables'):
                # çµ±åˆ¶å¤‰æ•°ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
                feature_cols = self.variable_selection['control_variables']
                self.result_text.insert("end", f"ğŸ¯ Using selected control variables: {', '.join(feature_cols)}\n\n")
            else:
                # å¾“æ¥ã®æ–¹æ³•ï¼ˆæ•°å€¤å‹åˆ—ã‚’è‡ªå‹•é¸æŠï¼‰
                feature_cols = self.data.select_dtypes(include=[np.number]).columns.tolist()
                if target_col in feature_cols:
                    feature_cols.remove(target_col)
                self.result_text.insert("end", f"ğŸ“Š Using all numeric variables as features\n\n")
            
            if len(feature_cols) == 0:
                messagebox.showerror("Error", "No feature variables found")
                return
            
            X = self.data[feature_cols].fillna(0)
            y = self.data[target_col].fillna(0)
            
            # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†
            task_type = self.task_var.get()
            
            if task_type == "classification":
                # åˆ†é¡ã‚¿ã‚¹ã‚¯
                if y.dtype == 'object':
                    le = LabelEncoder()
                    y = le.fit_transform(y)
                
                results = self._run_classification(X, y)
            else:
                # å›å¸°ã‚¿ã‚¹ã‚¯
                results = self._run_regression(X, y)
            
            # çµæœè¡¨ç¤º
            self._display_results(results)
            
        except Exception as e:
            messagebox.showerror("Error", f"Analysis failed: {str(e)}")
            self.result_text.insert("end", f"\nâŒ Error: {str(e)}")
    
    def _run_classification(self, X, y):
        """åˆ†é¡ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ"""
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ
        algo = self.algo_var.get()
        
        if algo == "Random Forest":
            model = RandomForestClassifier(n_estimators=100, random_state=42)
        elif algo == "XGBoost":
            model = xgb.XGBClassifier(random_state=42)
        elif algo == "LightGBM":
            model = lgb.LGBMClassifier(random_state=42, verbose=-1)
        elif algo == "SVM":
            model = SVC(random_state=42)
        elif algo == "Gradient Boosting":
            model = GradientBoostingClassifier(random_state=42)
        elif algo == "Decision Tree":
            model = DecisionTreeClassifier(random_state=42)
        else:  # Neural Network
            return self._run_neural_network_classification(X_train_scaled, X_test_scaled, y_train, y_test)
        
        # å­¦ç¿’
        with tqdm(total=1, desc="Training") as pbar:
            model.fit(X_train_scaled, y_train)
            pbar.update(1)
        
        # äºˆæ¸¬
        y_pred = model.predict(X_test_scaled)
        y_pred_proba = model.predict_proba(X_test_scaled) if hasattr(model, 'predict_proba') else None
        
        # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)
        
        # ç‰¹å¾´é‡é‡è¦åº¦
        if hasattr(model, 'feature_importances_'):
            feature_importance = dict(zip(X.columns, model.feature_importances_))
        else:
            feature_importance = None
        
        return {
            'task': 'classification',
            'algorithm': algo,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'feature_importance': feature_importance,
            'model': model,
            'confusion_matrix': confusion_matrix(y_test, y_pred)
        }
    
    def _run_regression(self, X, y):
        """å›å¸°ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ"""
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ
        algo = self.algo_var.get()
        
        if algo == "Random Forest":
            model = RandomForestRegressor(n_estimators=100, random_state=42)
        elif algo == "XGBoost":
            model = xgb.XGBRegressor(random_state=42)
        elif algo == "LightGBM":
            model = lgb.LGBMRegressor(random_state=42, verbose=-1)
        elif algo == "SVM":
            model = SVR()
        elif algo == "Gradient Boosting":
            model = GradientBoostingRegressor(random_state=42)
        elif algo == "Decision Tree":
            model = DecisionTreeRegressor(random_state=42)
        else:  # Neural Network
            return self._run_neural_network_regression(X_train_scaled, X_test_scaled, y_train, y_test)
        
        # å­¦ç¿’
        with tqdm(total=1, desc="Training") as pbar:
            model.fit(X_train_scaled, y_train)
            pbar.update(1)
        
        # äºˆæ¸¬
        y_pred = model.predict(X_test_scaled)
        
        # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # ç‰¹å¾´é‡é‡è¦åº¦
        if hasattr(model, 'feature_importances_'):
            feature_importance = dict(zip(X.columns, model.feature_importances_))
        else:
            feature_importance = None
        
        return {
            'task': 'regression',
            'algorithm': algo,
            'mse': mse,
            'rmse': np.sqrt(mse),
            'mae': mae,
            'r2_score': r2,
            'feature_importance': feature_importance,
            'model': model
        }
    
    def _run_neural_network_classification(self, X_train, X_test, y_train, y_test):
        """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†é¡"""
        # PyTorchã§ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å®Ÿè£…
        n_features = X_train.shape[1]
        n_classes = len(np.unique(y_train))
        
        class SimpleNN(nn.Module):
            def __init__(self, input_size, hidden_size, num_classes):
                super(SimpleNN, self).__init__()
                self.fc1 = nn.Linear(input_size, hidden_size)
                self.fc2 = nn.Linear(hidden_size, hidden_size//2)
                self.fc3 = nn.Linear(hidden_size//2, num_classes)
                self.relu = nn.ReLU()
                self.dropout = nn.Dropout(0.2)
                
            def forward(self, x):
                x = self.relu(self.fc1(x))
                x = self.dropout(x)
                x = self.relu(self.fc2(x))
                x = self.dropout(x)
                x = self.fc3(x)
                return x
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’Tensorã«å¤‰æ›
        X_train_tensor = torch.FloatTensor(X_train).to(DEVICE)
        X_test_tensor = torch.FloatTensor(X_test).to(DEVICE)
        y_train_tensor = torch.LongTensor(y_train).to(DEVICE)
        y_test_tensor = torch.LongTensor(y_test).to(DEVICE)
        
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = SimpleNN(n_features, 128, n_classes).to(DEVICE)
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        # å­¦ç¿’
        model.train()
        epochs = 100
        with tqdm(total=epochs, desc="Neural Network Training") as pbar:
            for epoch in range(epochs):
                optimizer.zero_grad()
                outputs = model(X_train_tensor)
                loss = criterion(outputs, y_train_tensor)
                loss.backward()
                optimizer.step()
                pbar.update(1)
        
        # è©•ä¾¡
        model.eval()
        with torch.no_grad():
            test_outputs = model(X_test_tensor)
            _, predicted = torch.max(test_outputs.data, 1)
            
        y_pred = predicted.cpu().numpy()
        y_test_np = y_test_tensor.cpu().numpy()
        
        accuracy = accuracy_score(y_test_np, y_pred)
        precision = precision_score(y_test_np, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_test_np, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_test_np, y_pred, average='weighted', zero_division=0)
        
        return {
            'task': 'classification',
            'algorithm': 'Neural Network (PyTorch)',
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'feature_importance': None,
            'model': model,
            'device': str(DEVICE),
            'confusion_matrix': confusion_matrix(y_test_np, y_pred)
        }
    
    def _run_neural_network_regression(self, X_train, X_test, y_train, y_test):
        """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›å¸°"""
        # å®Ÿè£…ã¯åŒæ§˜ã®æ§‹é€ ã§å›å¸°ç”¨ã«èª¿æ•´
        n_features = X_train.shape[1]
        
        class SimpleRegressionNN(nn.Module):
            def __init__(self, input_size, hidden_size):
                super(SimpleRegressionNN, self).__init__()
                self.fc1 = nn.Linear(input_size, hidden_size)
                self.fc2 = nn.Linear(hidden_size, hidden_size//2)
                self.fc3 = nn.Linear(hidden_size//2, 1)
                self.relu = nn.ReLU()
                self.dropout = nn.Dropout(0.2)
                
            def forward(self, x):
                x = self.relu(self.fc1(x))
                x = self.dropout(x)
                x = self.relu(self.fc2(x))
                x = self.dropout(x)
                x = self.fc3(x)
                return x
        
        # åŒæ§˜ã®å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹
        X_train_tensor = torch.FloatTensor(X_train).to(DEVICE)
        X_test_tensor = torch.FloatTensor(X_test).to(DEVICE)
        y_train_tensor = torch.FloatTensor(y_train.values.reshape(-1, 1)).to(DEVICE)
        y_test_tensor = torch.FloatTensor(y_test.values.reshape(-1, 1)).to(DEVICE)
        
        model = SimpleRegressionNN(n_features, 128).to(DEVICE)
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        # å­¦ç¿’
        model.train()
        epochs = 100
        with tqdm(total=epochs, desc="Neural Network Training") as pbar:
            for epoch in range(epochs):
                optimizer.zero_grad()
                outputs = model(X_train_tensor)
                loss = criterion(outputs, y_train_tensor)
                loss.backward()
                optimizer.step()
                pbar.update(1)
        
        # è©•ä¾¡
        model.eval()
        with torch.no_grad():
            y_pred_tensor = model(X_test_tensor)
            
        y_pred = y_pred_tensor.cpu().numpy().flatten()
        y_test_np = y_test_tensor.cpu().numpy().flatten()
        
        mse = mean_squared_error(y_test_np, y_pred)
        mae = mean_absolute_error(y_test_np, y_pred)
        r2 = r2_score(y_test_np, y_pred)
        
        return {
            'task': 'regression',
            'algorithm': 'Neural Network (PyTorch)',
            'mse': mse,
            'rmse': np.sqrt(mse),
            'mae': mae,
            'r2_score': r2,
            'feature_importance': None,
            'model': model,
            'device': str(DEVICE)
        }
    
    def _display_results(self, results):
        """çµæœè¡¨ç¤º"""
        result_text = f"\nğŸ¯ Machine Learning Results\n"
        result_text += "=" * 50 + "\n\n"
        result_text += f"Algorithm: {results['algorithm']}\n"
        result_text += f"Task: {results['task'].capitalize()}\n"
        
        if 'device' in results:
            result_text += f"Device: {results['device']}\n"
        
        result_text += "\nğŸ“Š Performance Metrics:\n"
        
        if results['task'] == 'classification':
            result_text += f"â€¢ Accuracy: {results['accuracy']:.4f}\n"
            result_text += f"â€¢ Precision: {results['precision']:.4f}\n"
            result_text += f"â€¢ Recall: {results['recall']:.4f}\n"
            result_text += f"â€¢ F1-Score: {results['f1_score']:.4f}\n"
        else:
            result_text += f"â€¢ RÂ² Score: {results['r2_score']:.4f}\n"
            result_text += f"â€¢ MSE: {results['mse']:.4f}\n"
            result_text += f"â€¢ RMSE: {results['rmse']:.4f}\n"
            result_text += f"â€¢ MAE: {results['mae']:.4f}\n"
        
        if results['feature_importance']:
            result_text += "\nğŸ” Feature Importance (Top 5):\n"
            sorted_features = sorted(results['feature_importance'].items(), 
                                   key=lambda x: x[1], reverse=True)[:5]
            for feature, importance in sorted_features:
                result_text += f"â€¢ {feature}: {importance:.4f}\n"
        
        self.result_text.insert("end", result_text)
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        self.models[results['algorithm']] = results['model']
        self.results[results['algorithm']] = results
    
    def optimize_hyperparameters(self):
        """ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–"""
        messagebox.showinfo("Info", "âš™ï¸ Hyperparameter optimization starting...")
        # Optunaç­‰ã‚’ä½¿ã£ãŸæœ€é©åŒ–å®Ÿè£…ã¯æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§è¡Œã„ã¾ã™

class DeepLearningWindow:
    """æ·±å±¤å­¦ç¿’åˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦"""
    
    def __init__(self, parent, data, variable_selection=None):
        self.parent = parent
        self.data = data
        self.variable_selection = variable_selection or {}
        self.window = None
    
    def show(self):
        """ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¡¨ç¤º"""
        self.window = tk.Toplevel(self.parent)
        self.window.title("ğŸ§  Deep Learning Analysis")
        self.window.geometry("800x600")
        
        main_frame = ctk.CTkFrame(self.window)
        main_frame.pack(fill="both", expand=True, padx=10, pady=10)
        
        # æ·±å±¤å­¦ç¿’ãƒ¡ãƒ‹ãƒ¥ãƒ¼
        ctk.CTkLabel(main_frame, text="ğŸ§  Deep Learning Models", font=("Arial", 16, "bold")).pack(pady=10)
        
        # å„ç¨®æ·±å±¤å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒœã‚¿ãƒ³
        models = [
            ("ğŸ” Autoencoder", self.run_autoencoder),
            ("ğŸ“ˆ LSTM Time Series", self.run_lstm),
            ("ğŸ¯ Advanced CNN", self.run_cnn),
            ("ğŸ”® Transformer", self.run_transformer)
        ]
        
        for name, command in models:
            btn = ctk.CTkButton(main_frame, text=name, command=command, width=200, height=40)
            btn.pack(pady=5)
        
        # çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
        self.result_text = ctk.CTkTextbox(main_frame, height=300)
        self.result_text.pack(fill="both", expand=True, padx=5, pady=10)
    
    def run_autoencoder(self):
        messagebox.showinfo("Info", "ğŸ” Autoencoder implementation coming soon!")
    
    def run_lstm(self):
        messagebox.showinfo("Info", "ğŸ“ˆ LSTM implementation coming soon!")
    
    def run_cnn(self):
        messagebox.showinfo("Info", "ğŸ¯ CNN implementation coming soon!")
    
    def run_transformer(self):
        messagebox.showinfo("Info", "ğŸ”® Transformer implementation coming soon!")

class VariableSelectionWindow:
    """å¤‰æ•°é¸æŠã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆçµ±åˆ¶å¤‰æ•°ãƒ»ç›®çš„å¤‰æ•°ãƒ»å‰°ä½™å¤‰æ•°ï¼‰"""
    
    def __init__(self, parent, data, callback=None):
        self.parent = parent
        self.data = data
        self.callback = callback
        self.columns = list(data.columns)
        
        # å¤‰æ•°åˆ†é¡
        self.control_variables = []  # çµ±åˆ¶å¤‰æ•°
        self.target_variables = []   # ç›®çš„å¤‰æ•°
        self.residual_variables = [] # å‰°ä½™å¤‰æ•°
        
        self.window = None
        
    def show(self):
        """å¤‰æ•°é¸æŠã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¡¨ç¤º"""
        self.window = ctk.CTkToplevel(self.parent)
        self.window.title("ğŸ¯ Variable Selection - å¤‰æ•°é¸æŠ")
        self.window.geometry("800x700")
        self.window.grab_set()  # ãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åŒ–
        
        # ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ 
        main_frame = ctk.CTkFrame(self.window)
        main_frame.pack(fill="both", expand=True, padx=20, pady=20)
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        title_label = ctk.CTkLabel(main_frame, text="ğŸ¯ å¤‰æ•°åˆ†é¡è¨­å®š", font=("Arial", 18, "bold"))
        title_label.pack(pady=(0, 20))
        
        # èª¬æ˜æ–‡
        info_frame = ctk.CTkFrame(main_frame)
        info_frame.pack(fill="x", pady=(0, 20))
        
        info_text = """
ğŸ“Š å¤‰æ•°åˆ†é¡ã«ã¤ã„ã¦:
â€¢ çµ±åˆ¶å¤‰æ•°: åˆ†æã§åˆ¶å¾¡ã—ãŸã„èª¬æ˜å¤‰æ•°ï¼ˆç‹¬ç«‹å¤‰æ•°ï¼‰
â€¢ ç›®çš„å¤‰æ•°: äºˆæ¸¬ãƒ»èª¬æ˜ã—ãŸã„å¾“å±å¤‰æ•°ï¼ˆã‚¢ã‚¦ãƒˆã‚«ãƒ ï¼‰
â€¢ å‰°ä½™å¤‰æ•°: åˆ†æã«å«ã‚ãªã„å¤‰æ•°ï¼ˆé™¤å¤–å¯¾è±¡ï¼‰

âš ï¸ æ³¨æ„: æ©Ÿæ¢°å­¦ç¿’ã§ã¯çµ±åˆ¶å¤‰æ•°ã‚’ç‰¹å¾´é‡ã€ç›®çš„å¤‰æ•°ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™
        """
        info_label = ctk.CTkLabel(info_frame, text=info_text, justify="left")
        info_label.pack(padx=10, pady=10)
        
        # 3åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
        columns_frame = ctk.CTkFrame(main_frame)
        columns_frame.pack(fill="both", expand=True, pady=(0, 20))
        
        # åˆ©ç”¨å¯èƒ½ãªå¤‰æ•°ãƒªã‚¹ãƒˆ
        available_frame = ctk.CTkFrame(columns_frame)
        available_frame.pack(side="left", fill="both", expand=True, padx=(0, 5))
        
        ctk.CTkLabel(available_frame, text="ğŸ“‹ Available Variables", font=("Arial", 14, "bold")).pack(pady=5)
        self.available_listbox = tk.Listbox(available_frame, selectmode=tk.MULTIPLE, height=15)
        self.available_listbox.pack(fill="both", expand=True, padx=5, pady=5)
        
        for col in self.columns:
            self.available_listbox.insert(tk.END, col)
        
        # çµ±åˆ¶å¤‰æ•°ãƒªã‚¹ãƒˆ
        control_frame = ctk.CTkFrame(columns_frame)
        control_frame.pack(side="left", fill="both", expand=True, padx=5)
        
        ctk.CTkLabel(control_frame, text="ğŸ›ï¸ Control Variables\n(çµ±åˆ¶å¤‰æ•°)", font=("Arial", 14, "bold")).pack(pady=5)
        self.control_listbox = tk.Listbox(control_frame, height=15)
        self.control_listbox.pack(fill="both", expand=True, padx=5, pady=5)
        
        # ç›®çš„å¤‰æ•°ãƒªã‚¹ãƒˆ
        target_frame = ctk.CTkFrame(columns_frame)
        target_frame.pack(side="left", fill="both", expand=True, padx=5)
        
        ctk.CTkLabel(target_frame, text="ğŸ¯ Target Variables\n(ç›®çš„å¤‰æ•°)", font=("Arial", 14, "bold")).pack(pady=5)
        self.target_listbox = tk.Listbox(target_frame, height=15)
        self.target_listbox.pack(fill="both", expand=True, padx=5, pady=5)
        
        # å‰°ä½™å¤‰æ•°ãƒªã‚¹ãƒˆ
        residual_frame = ctk.CTkFrame(columns_frame)
        residual_frame.pack(side="left", fill="both", expand=True, padx=(5, 0))
        
        ctk.CTkLabel(residual_frame, text="ğŸ“¦ Residual Variables\n(å‰°ä½™å¤‰æ•°)", font=("Arial", 14, "bold")).pack(pady=5)
        self.residual_listbox = tk.Listbox(residual_frame, height=15)
        self.residual_listbox.pack(fill="both", expand=True, padx=5, pady=5)
        
        # æ“ä½œãƒœã‚¿ãƒ³
        button_frame = ctk.CTkFrame(main_frame)
        button_frame.pack(fill="x", pady=(0, 20))
        
        # å¤‰æ•°ç§»å‹•ãƒœã‚¿ãƒ³
        move_frame = ctk.CTkFrame(button_frame)
        move_frame.pack(pady=10)
        
        ctk.CTkButton(move_frame, text="â†’ Control", command=self._move_to_control, width=100).pack(side="left", padx=2)
        ctk.CTkButton(move_frame, text="â†’ Target", command=self._move_to_target, width=100).pack(side="left", padx=2)
        ctk.CTkButton(move_frame, text="â†’ Residual", command=self._move_to_residual, width=100).pack(side="left", padx=2)
        ctk.CTkButton(move_frame, text="â† Remove", command=self._remove_from_lists, width=100).pack(side="left", padx=2)
        
        # ãƒªã‚»ãƒƒãƒˆãƒ»è‡ªå‹•åˆ†é¡ãƒœã‚¿ãƒ³
        auto_frame = ctk.CTkFrame(button_frame)
        auto_frame.pack(pady=5)
        
        ctk.CTkButton(auto_frame, text="ğŸ”„ Reset All", command=self._reset_all, width=120).pack(side="left", padx=5)
        ctk.CTkButton(auto_frame, text="ğŸ¤– Auto Classify", command=self._auto_classify, width=120).pack(side="left", padx=5)
        ctk.CTkButton(auto_frame, text="ğŸ“Š Show Summary", command=self._show_summary, width=120).pack(side="left", padx=5)
        
        # ç¢ºå®šãƒ»ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³
        action_frame = ctk.CTkFrame(main_frame)
        action_frame.pack(fill="x")
        
        ctk.CTkButton(action_frame, text="âœ… Apply Selection", command=self._apply_selection, 
                     fg_color="green", width=150, height=40).pack(side="left", padx=10)
        ctk.CTkButton(action_frame, text="âŒ Cancel", command=self._cancel, 
                     fg_color="red", width=100, height=40).pack(side="right", padx=10)
    
    def _move_to_control(self):
        """çµ±åˆ¶å¤‰æ•°ã«ç§»å‹•"""
        selected = self.available_listbox.curselection()
        for i in reversed(selected):
            var = self.available_listbox.get(i)
            self.control_listbox.insert(tk.END, var)
            self.available_listbox.delete(i)
    
    def _move_to_target(self):
        """ç›®çš„å¤‰æ•°ã«ç§»å‹•"""
        selected = self.available_listbox.curselection()
        for i in reversed(selected):
            var = self.available_listbox.get(i)
            self.target_listbox.insert(tk.END, var)
            self.available_listbox.delete(i)
    
    def _move_to_residual(self):
        """å‰°ä½™å¤‰æ•°ã«ç§»å‹•"""
        selected = self.available_listbox.curselection()
        for i in reversed(selected):
            var = self.available_listbox.get(i)
            self.residual_listbox.insert(tk.END, var)
            self.available_listbox.delete(i)
    
    def _remove_from_lists(self):
        """ãƒªã‚¹ãƒˆã‹ã‚‰å¤‰æ•°ã‚’å‰Šé™¤ã—ã¦åˆ©ç”¨å¯èƒ½ãƒªã‚¹ãƒˆã«æˆ»ã™"""
        # çµ±åˆ¶å¤‰æ•°ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
        selected = self.control_listbox.curselection()
        for i in reversed(selected):
            var = self.control_listbox.get(i)
            self.available_listbox.insert(tk.END, var)
            self.control_listbox.delete(i)
        
        # ç›®çš„å¤‰æ•°ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
        selected = self.target_listbox.curselection()
        for i in reversed(selected):
            var = self.target_listbox.get(i)
            self.available_listbox.insert(tk.END, var)
            self.target_listbox.delete(i)
        
        # å‰°ä½™å¤‰æ•°ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
        selected = self.residual_listbox.curselection()
        for i in reversed(selected):
            var = self.residual_listbox.get(i)
            self.available_listbox.insert(tk.END, var)
            self.residual_listbox.delete(i)
    
    def _reset_all(self):
        """å…¨ã¦ãƒªã‚»ãƒƒãƒˆ"""
        self.available_listbox.delete(0, tk.END)
        self.control_listbox.delete(0, tk.END)
        self.target_listbox.delete(0, tk.END)
        self.residual_listbox.delete(0, tk.END)
        
        for col in self.columns:
            self.available_listbox.insert(tk.END, col)
    
    def _auto_classify(self):
        """è‡ªå‹•åˆ†é¡ï¼ˆãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼‰"""
        self._reset_all()
        
        # æ•°å€¤å‹å¤‰æ•°ã‚’çµ±åˆ¶å¤‰æ•°ã€æ–‡å­—åˆ—ãƒ»ã‚«ãƒ†ã‚´ãƒªå‹ã‚’å‰°ä½™å¤‰æ•°ã«åˆ†é¡
        numeric_cols = self.data.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = self.data.select_dtypes(include=['object', 'category']).columns.tolist()
        
        # 'id', 'index' ãªã©ã¯å‰°ä½™å¤‰æ•°ã«
        id_patterns = ['id', 'index', 'idx', 'key', 'ç•ªå·', 'no', 'num']
        
        self.available_listbox.delete(0, tk.END)
        
        for col in self.columns:
            col_lower = col.lower()
            if any(pattern in col_lower for pattern in id_patterns):
                self.residual_listbox.insert(tk.END, col)
            elif col in numeric_cols and col not in categorical_cols:
                if 'target' in col_lower or 'outcome' in col_lower or 'result' in col_lower:
                    self.target_listbox.insert(tk.END, col)
                else:
                    self.control_listbox.insert(tk.END, col)
            else:
                self.residual_listbox.insert(tk.END, col)
    
    def _show_summary(self):
        """å¤‰æ•°åˆ†é¡ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        control_vars = [self.control_listbox.get(i) for i in range(self.control_listbox.size())]
        target_vars = [self.target_listbox.get(i) for i in range(self.target_listbox.size())]
        residual_vars = [self.residual_listbox.get(i) for i in range(self.residual_listbox.size())]
        
        summary = f"""
ğŸ“Š Variable Classification Summary
================================

ğŸ›ï¸ Control Variables ({len(control_vars)}):
{', '.join(control_vars) if control_vars else 'None'}

ğŸ¯ Target Variables ({len(target_vars)}):
{', '.join(target_vars) if target_vars else 'None'}

ğŸ“¦ Residual Variables ({len(residual_vars)}):
{', '.join(residual_vars) if residual_vars else 'None'}

ğŸ“ˆ Data Types:
{self.data.dtypes.to_string()}
        """
        
        messagebox.showinfo("Variable Summary", summary)
    
    def _apply_selection(self):
        """é¸æŠã‚’é©ç”¨"""
        self.control_variables = [self.control_listbox.get(i) for i in range(self.control_listbox.size())]
        self.target_variables = [self.target_listbox.get(i) for i in range(self.target_listbox.size())]
        self.residual_variables = [self.residual_listbox.get(i) for i in range(self.residual_listbox.size())]
        
        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        if not self.control_variables and not self.target_variables:
            messagebox.showerror("Error", "Please select at least one control or target variable!")
            return
        
        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
        if self.callback:
            result = {
                'control_variables': self.control_variables,
                'target_variables': self.target_variables,
                'residual_variables': self.residual_variables,
                'data_subset': self._create_data_subset()
            }
            self.callback(result)
        
        self.window.destroy()
    
    def _create_data_subset(self):
        """é¸æŠã•ã‚ŒãŸå¤‰æ•°ã§ãƒ‡ãƒ¼ã‚¿ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
        selected_vars = self.control_variables + self.target_variables
        if selected_vars:
            return self.data[selected_vars].copy()
        return self.data.copy()
    
    def _cancel(self):
        """ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        self.window.destroy()

class AIAnalysisWindow:
    """AIçµ±è¨ˆåˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦"""
    
    def __init__(self, parent, data):
        self.parent = parent
        self.data = data
        self.window = None
        
    def show(self):
        """AIåˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¡¨ç¤º"""
        if not AI_INTEGRATION_AVAILABLE:
            messagebox.showerror("Error", "AIçµ±åˆæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
            return
            
        self.window = ctk.CTkToplevel(self.parent)
        self.window.title("ğŸ¤– AI Statistical Analysis - AIçµ±è¨ˆåˆ†æ")
        self.window.geometry("1000x800")
        self.window.grab_set()
        
        # ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ 
        main_frame = ctk.CTkFrame(self.window)
        main_frame.pack(fill="both", expand=True, padx=20, pady=20)
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        title_label = ctk.CTkLabel(main_frame, text="ğŸ¤– AI Statistical Analysis", font=("Arial", 18, "bold"))
        title_label.pack(pady=(0, 20))
        
        # ã‚¿ãƒ–ãƒ“ãƒ¥ãƒ¼
        tabview = ctk.CTkTabview(main_frame)
        tabview.pack(fill="both", expand=True)
        
        # è‡ªç„¶è¨€èªåˆ†æã‚¿ãƒ–
        nlp_tab = tabview.add("Natural Language")
        self._create_nlp_tab(nlp_tab)
        
        # ç”»åƒåˆ†æã‚¿ãƒ–
        image_tab = tabview.add("Image Analysis")
        self._create_image_tab(image_tab)
        
        # å±¥æ­´ã‚¿ãƒ–
        history_tab = tabview.add("Analysis History")
        self._create_history_tab(history_tab)
    
    def _create_nlp_tab(self, parent):
        """è‡ªç„¶è¨€èªåˆ†æã‚¿ãƒ–ä½œæˆ"""
        # èª¬æ˜æ–‡
        info_label = ctk.CTkLabel(parent, text="ğŸ—£ï¸ è‡ªç„¶è¨€èªã§çµ±è¨ˆåˆ†æã‚’æŒ‡ç¤ºã—ã¦ãã ã•ã„", font=("Arial", 14, "bold"))
        info_label.pack(pady=10)
        
        # å…¥åŠ›ãƒ•ãƒ¬ãƒ¼ãƒ 
        input_frame = ctk.CTkFrame(parent)
        input_frame.pack(fill="x", padx=10, pady=10)
        
        # ã‚¯ã‚¨ãƒªå…¥åŠ›
        ctk.CTkLabel(input_frame, text="åˆ†æè¦æ±‚:").pack(anchor="w", padx=10, pady=(10, 5))
        self.query_text = ctk.CTkTextbox(input_frame, height=100)
        self.query_text.pack(fill="x", padx=10, pady=(0, 10))
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªãƒœã‚¿ãƒ³
        sample_frame = ctk.CTkFrame(input_frame)
        sample_frame.pack(fill="x", padx=10, pady=(0, 10))
        
        samples = [
            "ãƒ‡ãƒ¼ã‚¿ã®ç›¸é–¢åˆ†æã‚’è¡Œã£ã¦",
            "ç·šå½¢å›å¸°åˆ†æã‚’ã—ã¦çµæœã‚’å¯è¦–åŒ–",
            "è¨˜è¿°çµ±è¨ˆã‚’è¡¨ç¤ºã—ã¦",
            "ç•°å¸¸å€¤ã®æ¤œå‡ºã¨é™¤å»",
            "ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æã‚’å®Ÿè¡Œ"
        ]
        
        for i, sample in enumerate(samples):
            btn = ctk.CTkButton(sample_frame, text=sample, width=180, height=30,
                               command=lambda s=sample: self.query_text.insert("1.0", s))
            btn.grid(row=i//3, column=i%3, padx=5, pady=5)
        
        # å®Ÿè¡Œãƒœã‚¿ãƒ³
        ctk.CTkButton(input_frame, text="ğŸš€ AI Analysis", command=self._run_nlp_analysis,
                     fg_color="green", width=200, height=40).pack(pady=10)
        
        # çµæœè¡¨ç¤º
        ctk.CTkLabel(parent, text="AI Response:", font=("Arial", 12, "bold")).pack(anchor="w", padx=10, pady=(20, 5))
        self.nlp_result_text = ctk.CTkTextbox(parent, height=300)
        self.nlp_result_text.pack(fill="both", expand=True, padx=10, pady=(0, 10))
        
        # ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œãƒœã‚¿ãƒ³
        ctk.CTkButton(parent, text="ğŸ”§ Execute Generated Code", command=self._execute_nlp_code,
                     fg_color="blue", width=200, height=35).pack(pady=10)
    
    def _create_image_tab(self, parent):
        """ç”»åƒåˆ†æã‚¿ãƒ–ä½œæˆ"""
        # èª¬æ˜æ–‡
        info_label = ctk.CTkLabel(parent, text="ğŸ“· ç”»åƒã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºãƒ»åˆ†æ", font=("Arial", 14, "bold"))
        info_label.pack(pady=10)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠãƒ•ãƒ¬ãƒ¼ãƒ 
        file_frame = ctk.CTkFrame(parent)
        file_frame.pack(fill="x", padx=10, pady=10)
        
        self.image_path_var = tk.StringVar()
        ctk.CTkLabel(file_frame, text="ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«:").pack(anchor="w", padx=10, pady=(10, 5))
        
        path_frame = ctk.CTkFrame(file_frame)
        path_frame.pack(fill="x", padx=10, pady=(0, 10))
        
        self.image_path_entry = ctk.CTkEntry(path_frame, textvariable=self.image_path_var, width=400)
        self.image_path_entry.pack(side="left", fill="x", expand=True, padx=(0, 10))
        
        ctk.CTkButton(path_frame, text="ğŸ“ Browse", command=self._browse_image, width=100).pack(side="right")
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
        ctk.CTkLabel(file_frame, text="è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³):").pack(anchor="w", padx=10, pady=(10, 5))
        self.context_entry = ctk.CTkEntry(file_frame, placeholder_text="ä¾‹: ã“ã®è¡¨ã¯å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã§ã™")
        self.context_entry.pack(fill="x", padx=10, pady=(0, 10))
        
        # å®Ÿè¡Œãƒœã‚¿ãƒ³
        ctk.CTkButton(file_frame, text="ğŸ” Analyze Image", command=self._run_image_analysis,
                     fg_color="orange", width=200, height=40).pack(pady=10)
        
        # çµæœè¡¨ç¤º
        ctk.CTkLabel(parent, text="Image Analysis Result:", font=("Arial", 12, "bold")).pack(anchor="w", padx=10, pady=(20, 5))
        self.image_result_text = ctk.CTkTextbox(parent, height=300)
        self.image_result_text.pack(fill="both", expand=True, padx=10, pady=(0, 10))
        
        # ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œãƒœã‚¿ãƒ³
        ctk.CTkButton(parent, text="ğŸ”§ Execute Generated Code", command=self._execute_image_code,
                     fg_color="blue", width=200, height=35).pack(pady=10)
    
    def _create_history_tab(self, parent):
        """å±¥æ­´ã‚¿ãƒ–ä½œæˆ"""
        ctk.CTkLabel(parent, text="ğŸ“š Analysis History", font=("Arial", 14, "bold")).pack(pady=10)
        
        # å±¥æ­´ãƒªã‚¹ãƒˆ
        self.history_listbox = tk.Listbox(parent, height=20)
        self.history_listbox.pack(fill="both", expand=True, padx=10, pady=10)
        
        # å±¥æ­´æ“ä½œãƒœã‚¿ãƒ³
        history_btn_frame = ctk.CTkFrame(parent)
        history_btn_frame.pack(fill="x", padx=10, pady=10)
        
        ctk.CTkButton(history_btn_frame, text="ğŸ”„ Refresh", command=self._refresh_history, width=100).pack(side="left", padx=5)
        ctk.CTkButton(history_btn_frame, text="ğŸ“¤ Export", command=self._export_history, width=100).pack(side="left", padx=5)
        ctk.CTkButton(history_btn_frame, text="ğŸ—‘ï¸ Clear", command=self._clear_history, width=100).pack(side="left", padx=5)
    
    def _browse_image(self):
        """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ"""
        file_path = filedialog.askopenfilename(
            title="Select Image File",
            filetypes=[
                ("Image files", "*.png *.jpg *.jpeg *.gif *.bmp *.tiff *.webp"),
                ("All files", "*.*")
            ]
        )
        if file_path:
            self.image_path_var.set(file_path)
    
    def _run_nlp_analysis(self):
        """è‡ªç„¶è¨€èªåˆ†æå®Ÿè¡Œ"""
        query = self.query_text.get("1.0", "end-1c").strip()
        if not query:
            messagebox.showwarning("Warning", "åˆ†æè¦æ±‚ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return
        
        self.nlp_result_text.delete("1.0", "end")
        self.nlp_result_text.insert("1.0", "ğŸ¤– AIåˆ†æä¸­... ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
        
        # éåŒæœŸå®Ÿè¡Œ
        import threading
        thread = threading.Thread(target=self._nlp_analysis_thread, args=(query,))
        thread.daemon = True
        thread.start()
    
    def _nlp_analysis_thread(self, query):
        """è‡ªç„¶è¨€èªåˆ†æã‚¹ãƒ¬ãƒƒãƒ‰"""
        try:
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            result = loop.run_until_complete(ai_analyzer.analyze_natural_language_query(query, self.data))
            
            # UIæ›´æ–°ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œï¼‰
            self.window.after(0, lambda: self._update_nlp_result(result))
            
        except Exception as e:
            error_msg = f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}"
            self.window.after(0, lambda: self.nlp_result_text.delete("1.0", "end"))
            self.window.after(0, lambda: self.nlp_result_text.insert("1.0", error_msg))
    
    def _update_nlp_result(self, result):
        """è‡ªç„¶è¨€èªåˆ†æçµæœæ›´æ–°"""
        self.nlp_result_text.delete("1.0", "end")
        
        if result["success"]:
            display_text = f"""ğŸ¤– AI Provider: {result.get('provider', 'Unknown')} ({result.get('model', 'Unknown')})

ğŸ“ AI Response:
{result['ai_response']}

ğŸ Generated Python Code:
{result['python_code']}
"""
            self.nlp_result_text.insert("1.0", display_text)
            self.last_nlp_code = result['python_code']
        else:
            self.nlp_result_text.insert("1.0", f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
    
    def _run_image_analysis(self):
        """ç”»åƒåˆ†æå®Ÿè¡Œ"""
        image_path = self.image_path_var.get().strip()
        if not image_path:
            messagebox.showwarning("Warning", "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
            return
        
        if not Path(image_path).exists():
            messagebox.showerror("Error", "æŒ‡å®šã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        context = self.context_entry.get().strip()
        
        self.image_result_text.delete("1.0", "end")
        self.image_result_text.insert("1.0", "ğŸ” ç”»åƒåˆ†æä¸­... ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
        
        # éåŒæœŸå®Ÿè¡Œ
        import threading
        thread = threading.Thread(target=self._image_analysis_thread, args=(image_path, context))
        thread.daemon = True
        thread.start()
    
    def _image_analysis_thread(self, image_path, context):
        """ç”»åƒåˆ†æã‚¹ãƒ¬ãƒƒãƒ‰"""
        try:
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            result = loop.run_until_complete(ai_analyzer.analyze_image_data(image_path, context))
            
            # UIæ›´æ–°ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œï¼‰
            self.window.after(0, lambda: self._update_image_result(result))
            
        except Exception as e:
            error_msg = f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}"
            self.window.after(0, lambda: self.image_result_text.delete("1.0", "end"))
            self.window.after(0, lambda: self.image_result_text.insert("1.0", error_msg))
    
    def _update_image_result(self, result):
        """ç”»åƒåˆ†æçµæœæ›´æ–°"""
        self.image_result_text.delete("1.0", "end")
        
        if result["success"]:
            display_text = f"""ğŸ¤– AI Provider: {result.get('provider', 'Unknown')} ({result.get('model', 'Unknown')})

ğŸ“ AI Response:
{result['ai_response']}

ğŸ”¤ OCR Text:
{result.get('ocr_text', 'ãªã—')}

ğŸ Generated Python Code:
{result['python_code']}
"""
            self.image_result_text.insert("1.0", display_text)
            self.last_image_code = result['python_code']
        else:
            self.image_result_text.insert("1.0", f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
    
    def _execute_nlp_code(self):
        """è‡ªç„¶è¨€èªåˆ†æã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ"""
        if hasattr(self, 'last_nlp_code') and self.last_nlp_code:
            self._execute_code(self.last_nlp_code)
        else:
            messagebox.showwarning("Warning", "å®Ÿè¡Œã™ã‚‹ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
    
    def _execute_image_code(self):
        """ç”»åƒåˆ†æã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ"""
        if hasattr(self, 'last_image_code') and self.last_image_code:
            self._execute_code(self.last_image_code)
        else:
            messagebox.showwarning("Warning", "å®Ÿè¡Œã™ã‚‹ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
    
    def _execute_code(self, code):
        """ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ"""
        try:
            result = ai_analyzer.execute_generated_code(code, self.data)
            
            if result["success"]:
                messagebox.showinfo("Success", "ã‚³ãƒ¼ãƒ‰ãŒæ­£å¸¸ã«å®Ÿè¡Œã•ã‚Œã¾ã—ãŸï¼")
            else:
                messagebox.showerror("Execution Error", f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼:\n{result['error']}")
        except Exception as e:
            messagebox.showerror("Error", f"å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n{str(e)}")
    
    def _refresh_history(self):
        """å±¥æ­´æ›´æ–°"""
        self.history_listbox.delete(0, tk.END)
        for i, record in enumerate(ai_analyzer.analysis_history):
            timestamp = record.get('timestamp', 'Unknown')
            query = record.get('query', 'No query')[:50]
            self.history_listbox.insert(tk.END, f"{i+1}. [{timestamp}] {query}...")
    
    def _export_history(self):
        """å±¥æ­´ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if not ai_analyzer.analysis_history:
            messagebox.showinfo("Info", "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        file_path = filedialog.asksaveasfilename(
            title="Export Analysis History",
            defaultextension=".json",
            filetypes=[("JSON files", "*.json"), ("All files", "*.*")]
        )
        
        if file_path:
            try:
                import json
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(ai_analyzer.analysis_history, f, ensure_ascii=False, indent=2, default=str)
                messagebox.showinfo("Success", f"å±¥æ­´ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ:\n{file_path}")
            except Exception as e:
                messagebox.showerror("Error", f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼:\n{str(e)}")
    
    def _clear_history(self):
        """å±¥æ­´ã‚¯ãƒªã‚¢"""
        if messagebox.askyesno("Confirm", "ã™ã¹ã¦ã®å±¥æ­´ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ"):
            ai_analyzer.analysis_history.clear()
            self.history_listbox.delete(0, tk.END)
            messagebox.showinfo("Success", "å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")

class StatisticalAnalysisGUI:
    """ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«çµ±è¨ˆè§£æGUI"""
    
    def __init__(self):
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†åˆæœŸåŒ–
        self.session_manager = SessionManager(self)
        
        # ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½åˆæœŸåŒ–
        try:
            from professional_utils import professional_logger, performance_monitor
            from professional_reports import professional_report_generator
            from advanced_statistics import advanced_analyzer
            from parallel_optimization import parallel_processor, optimized_stats, memory_manager
            from survival_analysis import complete_survival_analyzer
            from bayesian_analysis import deep_bayesian_analyzer
            from ml_pipeline_automation import ml_pipeline_automator
            
            print("âœ… å®Œå…¨ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            print("ğŸ§  é«˜åº¦çµ±è¨ˆè§£ææ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            print("ğŸš€ ä¸¦åˆ—å‡¦ç†ãƒ»æœ€é©åŒ–æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            print("â±ï¸ ç”Ÿå­˜è§£ææ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            print("ğŸ² ãƒ™ã‚¤ã‚ºçµ±è¨ˆè§£ææ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            print("ğŸ¤– æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è‡ªå‹•åŒ–ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
            
            self.professional_features = True
            self.advanced_features = True
            self.advanced_analyzer = advanced_analyzer
            self.parallel_processor = parallel_processor
            self.memory_manager = memory_manager
            self.survival_analyzer = complete_survival_analyzer
            self.bayesian_analyzer = deep_bayesian_analyzer
            self.ml_automator = ml_pipeline_automator
            
        except ImportError as e:
            print(f"âš ï¸ ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãŒä¸€éƒ¨åˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")
            self.professional_features = False
            self.advanced_features = False
        
        # ãƒ‡ãƒ¼ã‚¿ç®¡ç†
        self.current_data = None
        self.analysis_results = {}
        self.user_settings = {}
        
        # å¤‰æ•°é¸æŠçŠ¶æ…‹
        self.control_variables = []  # çµ±åˆ¶å¤‰æ•°
        self.target_variables = []   # ç›®çš„å¤‰æ•°
        self.residual_variables = [] # å‰°ä½™å¤‰æ•°
        self.variable_selection_applied = False
        
        # GUIåˆæœŸåŒ–
        self._initialize_gui()
        
        # å¾©æ—§ãƒã‚§ãƒƒã‚¯
        self._check_recovery()
    
    def _initialize_gui(self):
        """GUIåˆæœŸåŒ–"""
        self.root = ctk.CTk()
        self.root.title("ğŸ”¬ Professional Statistical Analysis Software")
        self.root.geometry("1400x900")
        
        # ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼
        self._create_menu()
        
        # ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ 
        self._create_main_frame()
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼
        self._create_status_bar()
        
        # åˆæœŸçŠ¶æ…‹è¡¨ç¤º
        self._update_status(f"Ready | Session: {self.session_manager.session_id[:8]}...")
    
    def _create_menu(self):
        """ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ä½œæˆ"""
        menubar = tk.Menu(self.root)
        self.root.config(menu=menubar)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¡ãƒ‹ãƒ¥ãƒ¼
        file_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="File", menu=file_menu)
        file_menu.add_command(label="Open Data...", command=self.load_data)
        file_menu.add_command(label="Save Session", command=self.save_session)
        file_menu.add_separator()
        file_menu.add_command(label="Exit", command=self.root.quit)
        
        # è§£æãƒ¡ãƒ‹ãƒ¥ãƒ¼
        analysis_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Analysis", menu=analysis_menu)
        analysis_menu.add_command(label="Variable Selection", command=self.variable_selection)
        analysis_menu.add_separator()
        analysis_menu.add_command(label="ğŸ¤– AI Analysis", command=self.ai_analysis)
        analysis_menu.add_separator()
        analysis_menu.add_command(label="Descriptive Statistics", command=self.descriptive_stats)
        analysis_menu.add_command(label="Hypothesis Testing", command=self.hypothesis_testing)
        analysis_menu.add_command(label="Regression Analysis", command=self.regression_analysis)
        analysis_menu.add_command(label="Machine Learning", command=self.machine_learning)
        analysis_menu.add_command(label="Deep Learning", command=self.deep_learning)
        
        # é«˜åº¦è§£æãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if hasattr(self, 'advanced_features') and self.advanced_features:
            analysis_menu.add_separator()
            advanced_menu = tk.Menu(analysis_menu, tearoff=0)
            analysis_menu.add_cascade(label="ğŸ§  Advanced Analysis", menu=advanced_menu)
            advanced_menu.add_command(label="ğŸ”¬ Multivariate Analysis", command=self.multivariate_analysis)
            advanced_menu.add_command(label="ğŸ“ˆ Time Series Analysis", command=self.time_series_analysis)
            advanced_menu.add_command(label="â±ï¸ Survival Analysis", command=self.survival_analysis)
            advanced_menu.add_command(label="ğŸ² Bayesian Analysis", command=self.bayesian_analysis)
            advanced_menu.add_command(label="ğŸ“Š Comprehensive EDA", command=self.comprehensive_eda)
        
        # ãƒ„ãƒ¼ãƒ«ãƒ¡ãƒ‹ãƒ¥ãƒ¼
        tools_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Tools", menu=tools_menu)
        tools_menu.add_command(label="Data Quality Check", command=self.data_quality_check)
        tools_menu.add_separator()
        if PROFESSIONAL_FEATURES_AVAILABLE:
            tools_menu.add_command(label="ğŸ“‹ Generate Report", command=self.generate_professional_report)
            tools_menu.add_command(label="ğŸ“Š Performance Report", command=self.show_performance_report)
            tools_menu.add_separator()
        tools_menu.add_command(label="GPU Status", command=self.show_gpu_status)
        tools_menu.add_command(label="Memory Usage", command=self.show_memory_usage)
    
    def _create_main_frame(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ"""
        # ã‚µã‚¤ãƒ‰ãƒ‘ãƒãƒ«
        self.sidebar = ctk.CTkFrame(self.root, width=300)
        self.sidebar.pack(side="left", fill="y", padx=10, pady=10)
        
        # ãƒ‡ãƒ¼ã‚¿æƒ…å ±ãƒ‘ãƒãƒ«
        self.data_info_frame = ctk.CTkFrame(self.sidebar)
        self.data_info_frame.pack(fill="x", padx=5, pady=5)
        
        self.data_info_label = ctk.CTkLabel(self.data_info_frame, text="ğŸ“Š Data Information")
        self.data_info_label.pack(pady=5)
        
        self.data_text = ctk.CTkTextbox(self.data_info_frame, height=150)
        self.data_text.pack(fill="x", padx=5, pady=5)
        
        # æ“ä½œãƒ‘ãƒãƒ«
        self.control_frame = ctk.CTkFrame(self.sidebar)
        self.control_frame.pack(fill="x", padx=5, pady=5)
        
        # ãƒœã‚¿ãƒ³é…ç½®
        self.load_btn = ctk.CTkButton(self.control_frame, text="ğŸ“ Load Data", command=self.load_data)
        self.load_btn.pack(fill="x", padx=5, pady=2)
        
        self.var_select_btn = ctk.CTkButton(self.control_frame, text="ğŸ¯ Variable Selection", command=self.variable_selection)
        self.var_select_btn.pack(fill="x", padx=5, pady=2)
        
        self.ai_btn = ctk.CTkButton(self.control_frame, text="ğŸ¤– AI Analysis", command=self.ai_analysis, fg_color="purple")
        self.ai_btn.pack(fill="x", padx=5, pady=2)
        
        self.desc_btn = ctk.CTkButton(self.control_frame, text="ğŸ“ˆ Descriptive Stats", command=self.descriptive_stats)
        self.desc_btn.pack(fill="x", padx=5, pady=2)
        
        self.test_btn = ctk.CTkButton(self.control_frame, text="ğŸ”¬ Hypothesis Test", command=self.hypothesis_testing)
        self.test_btn.pack(fill="x", padx=5, pady=2)
        
        self.reg_btn = ctk.CTkButton(self.control_frame, text="ğŸ“Š Regression", command=self.regression_analysis)
        self.reg_btn.pack(fill="x", padx=5, pady=2)
        
        self.ml_btn = ctk.CTkButton(self.control_frame, text="ğŸ¤– Machine Learning", command=self.machine_learning)
        self.ml_btn.pack(fill="x", padx=5, pady=2)
        
        self.dl_btn = ctk.CTkButton(self.control_frame, text="ğŸ§  Deep Learning", command=self.deep_learning)
        self.dl_btn.pack(fill="x", padx=5, pady=2)
        
        # ãƒ¡ã‚¤ãƒ³ä½œæ¥­ã‚¨ãƒªã‚¢
        self.main_frame = ctk.CTkFrame(self.root)
        self.main_frame.pack(side="right", fill="both", expand=True, padx=10, pady=10)
        
        # çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
        self.result_text = ctk.CTkTextbox(self.main_frame, font=("Consolas", 12))
        self.result_text.pack(fill="both", expand=True, padx=5, pady=5)
        
        # åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        welcome_msg = f"""
ğŸ”¬ Professional Statistical Analysis Software
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ›¡ï¸ Session ID: {self.session_manager.session_id}
âš¡ GPU Status: {'âœ… Available' if CUDA_AVAILABLE else 'âŒ Not Available'}
ğŸ¯ GPU Device: {GPU_NAME}
ğŸ’¾ Auto-save: Every 5 minutes
ğŸ”„ Backup: Automatic rotation (10 files)

ğŸ“‹ Quick Start:
1. Load your dataset using 'Load Data' button
2. Explore with 'Descriptive Stats'
3. Run hypothesis tests or regression analysis
4. Apply machine learning algorithms
5. Export results and visualizations

Ready for professional statistical analysis! ğŸš€
        """
        self.result_text.insert("1.0", welcome_msg)
    
    def _create_status_bar(self):
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼ä½œæˆ"""
        self.status_bar = ctk.CTkFrame(self.root, height=30)
        self.status_bar.pack(side="bottom", fill="x", padx=10, pady=5)
        
        self.status_label = ctk.CTkLabel(self.status_bar, text="Ready")
        self.status_label.pack(side="left", padx=10)
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¡¨ç¤º
        self.memory_label = ctk.CTkLabel(self.status_bar, text="Memory: 0 MB")
        self.memory_label.pack(side="right", padx=10)
        
        # ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚¿ã‚¤ãƒãƒ¼
        self._update_memory_usage()
    
    def _update_memory_usage(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ›´æ–°"""
        try:
            memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
            self.memory_label.configure(text=f"Memory: {memory_mb:.1f} MB")
        except:
            pass
        
        # 30ç§’å¾Œã«å†å®Ÿè¡Œ
        self.root.after(30000, self._update_memory_usage)
    
    def _update_status(self, message):
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°"""
        self.status_label.configure(text=message)
    
    def _check_recovery(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©æ—§ãƒã‚§ãƒƒã‚¯"""
        latest_session = self.session_manager.load_latest_session()
        if latest_session:
            result = messagebox.askyesno(
                "Session Recovery", 
                "Previous session found. Do you want to restore it?"
            )
            if result:
                self._restore_session(latest_session)
    
    def _restore_session(self, session_data):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©æ—§"""
        try:
            if session_data.get('data') is not None:
                self.current_data = pd.DataFrame(session_data['data'])
                self._update_data_info()
            
            self.analysis_results = session_data.get('analysis_results', {})
            self.user_settings = session_data.get('settings', {})
            
            self._update_status("Session restored successfully")
            self.result_text.insert("end", "\n\nâœ… Session restored from previous backup\n")
            
        except Exception as e:
            messagebox.showerror("Recovery Error", f"Failed to restore session: {e}")
    
    def load_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        file_path = filedialog.askopenfilename(
            title="Select Data File",
            filetypes=[
                ("CSV files", "*.csv"),
                ("Excel files", "*.xlsx;*.xls"),
                ("JSON files", "*.json"),
                ("All files", "*.*")
            ]
        )
        
        if not file_path:
            return
        
        try:
            self._update_status("Loading data...")
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
            progress_window = tk.Toplevel(self.root)
            progress_window.title("Loading Data")
            progress_window.geometry("400x100")
            
            progress_bar = ttk.Progressbar(progress_window, mode='indeterminate')
            progress_bar.pack(pady=20)
            progress_bar.start()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã«ã‚ˆã‚‹èª­ã¿è¾¼ã¿
            file_ext = Path(file_path).suffix.lower()
            
            if file_ext == '.csv':
                self.current_data = pd.read_csv(file_path)
            elif file_ext in ['.xlsx', '.xls']:
                self.current_data = pd.read_excel(file_path)
            elif file_ext == '.json':
                self.current_data = pd.read_json(file_path)
            else:
                raise ValueError(f"Unsupported file format: {file_ext}")
            
            progress_window.destroy()
            
            self._update_data_info()
            self._update_status(f"Data loaded: {len(self.current_data)} rows")
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜
            self.session_manager.save_session()
            
        except Exception as e:
            if 'progress_window' in locals():
                progress_window.destroy()
            messagebox.showerror("Error", f"Failed to load data: {e}")
            self._update_status("Data loading failed")
    
    def _update_data_info(self):
        """ãƒ‡ãƒ¼ã‚¿æƒ…å ±æ›´æ–°"""
        if self.current_data is None:
            self.data_text.delete("1.0", "end")
            return
        
        info_text = f"""Shape: {self.current_data.shape[0]} rows Ã— {self.current_data.shape[1]} columns

Columns:
{chr(10).join(f"â€¢ {col} ({self.current_data[col].dtype})" for col in self.current_data.columns[:10])}
{"..." if len(self.current_data.columns) > 10 else ""}

Missing Values: {self.current_data.isnull().sum().sum()}
Memory Usage: {self.current_data.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB"""
        
        # å¤‰æ•°é¸æŠçŠ¶æ…‹ã‚’è¿½åŠ 
        if self.variable_selection_applied:
            info_text += f"""

ğŸ¯ Variable Selection:
Control: {len(self.control_variables)} vars
Target: {len(self.target_variables)} vars  
Residual: {len(self.residual_variables)} vars"""
        
        self.data_text.delete("1.0", "end")
        self.data_text.insert("1.0", info_text)
    
    def descriptive_stats(self):
        """è¨˜è¿°çµ±è¨ˆ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            self._update_status("Computing descriptive statistics...")
            
            numeric_cols = self.current_data.select_dtypes(include=[np.number]).columns
            
            if len(numeric_cols) == 0:
                messagebox.showwarning("Warning", "No numeric columns found")
                return
            
            # åŸºæœ¬çµ±è¨ˆé‡
            desc_stats = self.current_data[numeric_cols].describe()
            
            # æ­ªåº¦ãƒ»å°–åº¦
            skewness = self.current_data[numeric_cols].skew()
            kurtosis = self.current_data[numeric_cols].kurtosis()
            
            # çµæœè¡¨ç¤º
            result = f"""
ğŸ“Š DESCRIPTIVE STATISTICS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Basic Statistics:
{desc_stats.round(4)}

Distribution Shape:
Skewness:
{skewness.round(4)}

Kurtosis:
{kurtosis.round(4)}

ğŸ” Data Quality Summary:
â€¢ Total observations: {len(self.current_data)}
â€¢ Numeric variables: {len(numeric_cols)}
â€¢ Complete cases: {self.current_data.dropna().shape[0]}
â€¢ Missing rate: {(self.current_data.isnull().sum().sum() / (len(self.current_data) * len(self.current_data.columns)) * 100):.1f}%
            """
            
            self.result_text.delete("1.0", "end")
            self.result_text.insert("1.0", result)
            
            # çµæœä¿å­˜
            self.analysis_results['descriptive_stats'] = {
                'basic_stats': desc_stats.to_dict(),
                'skewness': skewness.to_dict(),
                'kurtosis': kurtosis.to_dict()
            }
            
            self._update_status("Descriptive statistics completed")
            
        except Exception as e:
            messagebox.showerror("Error", f"Analysis failed: {e}")
            self._update_status("Analysis failed")
    
    def hypothesis_testing(self):
        """ä»®èª¬æ¤œå®š"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªæ­£è¦æ€§æ¤œå®šä¾‹
        try:
            numeric_cols = self.current_data.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) == 0:
                messagebox.showwarning("Warning", "No numeric columns found")
                return
            
            self._update_status("Running hypothesis tests...")
            
            results = []
            for col in numeric_cols[:5]:  # æœ€åˆã®5åˆ—ã®ã¿
                data = self.current_data[col].dropna()
                if len(data) < 3:
                    continue
                
                # Shapiro-Wilkæ­£è¦æ€§æ¤œå®š
                stat, p_value = stats.shapiro(data)
                results.append({
                    'Variable': col,
                    'Test': 'Shapiro-Wilk',
                    'Statistic': stat,
                    'P-value': p_value,
                    'Result': 'Normal' if p_value > 0.05 else 'Non-normal'
                })
            
            # çµæœè¡¨ç¤º
            result_text = "\nğŸ”¬ HYPOTHESIS TESTING RESULTS\n"
            result_text += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
            result_text += "Normality Tests (Shapiro-Wilk):\n\n"
            
            for res in results:
                result_text += f"Variable: {res['Variable']}\n"
                result_text += f"  Statistic: {res['Statistic']:.4f}\n"
                result_text += f"  P-value: {res['P-value']:.6f}\n"
                result_text += f"  Result: {res['Result']} (Î± = 0.05)\n\n"
            
            self.result_text.delete("1.0", "end")
            self.result_text.insert("1.0", result_text)
            
            self.analysis_results['hypothesis_tests'] = results
            self._update_status("Hypothesis testing completed")
            
        except Exception as e:
            messagebox.showerror("Error", f"Testing failed: {e}")
            self._update_status("Testing failed")
    
    def regression_analysis(self):
        """å›å¸°åˆ†æ"""
        messagebox.showinfo("Info", "Regression analysis feature coming soon!")
    
    def machine_learning(self):
        """é«˜åº¦ãªæ©Ÿæ¢°å­¦ç¿’åˆ†æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        # å¤‰æ•°é¸æŠæƒ…å ±ã‚’æº–å‚™
        variable_selection = {
            'control_variables': self.control_variables,
            'target_variables': self.target_variables,
            'residual_variables': self.residual_variables,
            'applied': self.variable_selection_applied
        }
        
        # æ©Ÿæ¢°å­¦ç¿’ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹ã
        ml_window = MLAnalysisWindow(self.root, self.current_data, variable_selection)
        ml_window.show()
    
    def deep_learning(self):
        """æ·±å±¤å­¦ç¿’åˆ†æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        # å¤‰æ•°é¸æŠæƒ…å ±ã‚’æº–å‚™
        variable_selection = {
            'control_variables': self.control_variables,
            'target_variables': self.target_variables,
            'residual_variables': self.residual_variables,
            'applied': self.variable_selection_applied
        }
        
        # æ·±å±¤å­¦ç¿’ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹ã
        dl_window = DeepLearningWindow(self.root, self.current_data, variable_selection)
        dl_window.show()
    
    def data_quality_check(self):
        """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            self._update_status("Checking data quality...")
            
            # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆ
            total_cells = len(self.current_data) * len(self.current_data.columns)
            missing_cells = self.current_data.isnull().sum().sum()
            duplicate_rows = self.current_data.duplicated().sum()
            
            quality_report = f"""
ğŸ” DATA QUALITY REPORT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Dataset Overview:
â€¢ Total rows: {len(self.current_data):,}
â€¢ Total columns: {len(self.current_data.columns)}
â€¢ Total cells: {total_cells:,}

Completeness:
â€¢ Missing cells: {missing_cells:,} ({missing_cells/total_cells*100:.2f}%)
â€¢ Complete rows: {len(self.current_data.dropna()):,}
â€¢ Duplicate rows: {duplicate_rows:,}

Column Details:
"""
            
            for col in self.current_data.columns:
                missing_pct = self.current_data[col].isnull().sum() / len(self.current_data) * 100
                unique_count = self.current_data[col].nunique()
                quality_report += f"â€¢ {col}: {missing_pct:.1f}% missing, {unique_count} unique values\n"
            
            self.result_text.delete("1.0", "end")
            self.result_text.insert("1.0", quality_report)
            
            self._update_status("Data quality check completed")
            
        except Exception as e:
            messagebox.showerror("Error", f"Quality check failed: {e}")
    
    def show_gpu_status(self):
        """GPUçŠ¶æ…‹è¡¨ç¤º"""
        gpu_info = f"""
âš¡ GPU INFORMATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

CUDA Available: {'âœ… Yes' if CUDA_AVAILABLE else 'âŒ No'}
GPU Device: {GPU_NAME}
"""
        
        if CUDA_AVAILABLE:
            gpu_info += f"""
GPU Memory:
â€¢ Total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB
â€¢ Allocated: {torch.cuda.memory_allocated() / 1024**3:.1f} GB
â€¢ Cached: {torch.cuda.memory_reserved() / 1024**3:.1f} GB

Compute Capability: {torch.cuda.get_device_properties(0).major}.{torch.cuda.get_device_properties(0).minor}
"""
        
        self.result_text.delete("1.0", "end")
        self.result_text.insert("1.0", gpu_info)
    
    def show_memory_usage(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¡¨ç¤º"""
        memory_info = f"""
ğŸ’¾ MEMORY INFORMATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Process Memory:
â€¢ RSS: {psutil.Process().memory_info().rss / 1024**2:.1f} MB
â€¢ VMS: {psutil.Process().memory_info().vms / 1024**2:.1f} MB

System Memory:
â€¢ Total: {psutil.virtual_memory().total / 1024**3:.1f} GB
â€¢ Available: {psutil.virtual_memory().available / 1024**3:.1f} GB
â€¢ Used: {psutil.virtual_memory().percent:.1f}%
"""
        
        self.result_text.delete("1.0", "end")
        self.result_text.insert("1.0", memory_info)
    
    def variable_selection(self):
        """å¤‰æ•°é¸æŠã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹ã"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        def on_variable_selection(result):
            """å¤‰æ•°é¸æŠçµæœã‚’å‡¦ç†"""
            self.control_variables = result['control_variables']
            self.target_variables = result['target_variables']
            self.residual_variables = result['residual_variables']
            self.variable_selection_applied = True
            
            # ãƒ‡ãƒ¼ã‚¿æƒ…å ±æ›´æ–°
            self._update_data_info()
            
            # çµæœè¡¨ç¤º
            summary = f"""
ğŸ¯ Variable Selection Applied
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š Control Variables ({len(self.control_variables)}):
{', '.join(self.control_variables) if self.control_variables else 'None'}

ğŸ¯ Target Variables ({len(self.target_variables)}):
{', '.join(self.target_variables) if self.target_variables else 'None'}

ğŸ“¦ Residual Variables ({len(self.residual_variables)}):
{', '.join(self.residual_variables) if self.residual_variables else 'None'}

âœ… Variable selection has been applied successfully!
Use these selections in subsequent analyses (ML, regression, etc.)
            """
            
            self.result_text.delete("1.0", "end")
            self.result_text.insert("1.0", summary)
            self._update_status("Variable selection applied")
        
        # å¤‰æ•°é¸æŠã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹ã
        var_window = VariableSelectionWindow(self.root, self.current_data, on_variable_selection)
        var_window.show()
    
    def generate_professional_report(self):
        """ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not PROFESSIONAL_FEATURES_AVAILABLE:
            messagebox.showerror("Error", "ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        if self.current_data is None:
            messagebox.showerror("Error", "ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        try:
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            progress_window = ctk.CTkToplevel(self.root)
            progress_window.title("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
            progress_window.geometry("400x150")
            progress_window.transient(self.root)
            progress_window.grab_set()
            
            progress_label = ctk.CTkLabel(progress_window, text="ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
            progress_label.pack(pady=20)
            
            progress_bar = ctk.CTkProgressBar(progress_window)
            progress_bar.pack(pady=20, padx=40, fill="x")
            progress_bar.set(0)
            
            def generate_report():
                try:
                    progress_bar.set(0.2)
                    progress_window.update()
                    
                    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                    report_file = report_generator.generate_comprehensive_report(
                        data=self.current_data,
                        analysis_results=self.analysis_results,
                        title="HAD Professional Statistical Analysis Report",
                        subtitle=f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                    )
                    
                    progress_bar.set(1.0)
                    progress_window.update()
                    
                    progress_window.destroy()
                    
                    # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    result = messagebox.askyesno(
                        "ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†", 
                        f"ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ:\n{report_file}\n\nãƒ¬ãƒãƒ¼ãƒˆã‚’é–‹ãã¾ã™ã‹ï¼Ÿ"
                    )
                    
                    if result:
                        import webbrowser
                        webbrowser.open(f"file://{Path(report_file).absolute()}")
                    
                    # ãƒ­ã‚°è¨˜éŒ²
                    if PROFESSIONAL_FEATURES_AVAILABLE:
                        professional_logger.info("ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†", 
                                                file_path=report_file,
                                                data_shape=self.current_data.shape)
                
                except Exception as e:
                    progress_window.destroy()
                    messagebox.showerror("Error", f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼:\n{str(e)}")
                    if PROFESSIONAL_FEATURES_AVAILABLE:
                        professional_logger.error("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå¤±æ•—", exception=e)
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
            import threading
            thread = threading.Thread(target=generate_report)
            thread.daemon = True
            thread.start()
        
        except Exception as e:
            messagebox.showerror("Error", f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼:\n{str(e)}")
    
    def show_performance_report(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º"""
        if not PROFESSIONAL_FEATURES_AVAILABLE:
            messagebox.showerror("Error", "ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        try:
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆå–å¾—
            perf_report = performance_monitor.get_performance_report()
            
            # ãƒ¬ãƒãƒ¼ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            report_window = ctk.CTkToplevel(self.root)
            report_window.title("ğŸ“Š Performance Report")
            report_window.geometry("800x600")
            report_window.transient(self.root)
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹
            text_widget = ctk.CTkTextbox(report_window, font=("Consolas", 11))
            text_widget.pack(fill="both", expand=True, padx=10, pady=10)
            
            # ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ç”Ÿæˆ
            report_content = "ğŸš€ HAD Professional Performance Report\n"
            report_content += "=" * 60 + "\n\n"
            report_content += f"ğŸ“… Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            report_content += f"ğŸ’¾ Session ID: {self.session_manager.session_id}\n\n"
            
            if perf_report:
                report_content += "ğŸ“Š Function Performance Metrics:\n"
                report_content += "-" * 40 + "\n"
                
                for func_name, metrics in perf_report.items():
                    report_content += f"\nğŸ”§ {func_name}:\n"
                    report_content += f"   â€¢ Call Count: {metrics['call_count']}\n"
                    report_content += f"   â€¢ Success Rate: {metrics['success_rate']:.2%}\n"
                    report_content += f"   â€¢ Avg Duration: {metrics['avg_duration']:.4f}s\n"
                    report_content += f"   â€¢ Max Duration: {metrics['max_duration']:.4f}s\n"
                    report_content += f"   â€¢ Min Duration: {metrics['min_duration']:.4f}s\n"
                    report_content += f"   â€¢ Avg Memory: {metrics['avg_memory_diff']:.2f}MB\n"
            else:
                report_content += "â„¹ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã¾ã åé›†ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
                report_content += "ã„ãã¤ã‹ã®è§£æã‚’å®Ÿè¡Œã—ã¦ã‹ã‚‰å†åº¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
            
            # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
            report_content += "\n" + "=" * 60 + "\n"
            report_content += "ğŸ–¥ï¸ System Information:\n"
            report_content += f"   â€¢ Python: {sys.version.split()[0]}\n"
            report_content += f"   â€¢ CUDA Available: {CUDA_AVAILABLE}\n"
            report_content += f"   â€¢ GPU: {GPU_NAME}\n"
            
            try:
                import psutil
                memory_info = psutil.virtual_memory()
                report_content += f"   â€¢ Total Memory: {memory_info.total / 1024**3:.1f} GB\n"
                report_content += f"   â€¢ Available Memory: {memory_info.available / 1024**3:.1f} GB\n"
                report_content += f"   â€¢ Memory Usage: {memory_info.percent}%\n"
                report_content += f"   â€¢ CPU Count: {psutil.cpu_count()}\n"
            except:
                pass
            
            text_widget.insert("1.0", report_content)
            
            # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒœã‚¿ãƒ³
            export_btn = ctk.CTkButton(
                report_window,
                text="ğŸ“„ Export Report",
                command=lambda: self._export_performance_report(report_content)
            )
            export_btn.pack(pady=10)
        
        except Exception as e:
            messagebox.showerror("Error", f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼:\n{str(e)}")
    
    def _export_performance_report(self, content):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        try:
            file_path = filedialog.asksaveasfilename(
                defaultextension=".txt",
                filetypes=[("Text files", "*.txt"), ("All files", "*.*")]
            )
            if file_path:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                messagebox.showinfo("Success", f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ:\n{file_path}")
        except Exception as e:
            messagebox.showerror("Error", f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼:\n{str(e)}")

    def ai_analysis(self):
        """AIçµ±è¨ˆåˆ†æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        # AIåˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹ã
        ai_window = AIAnalysisWindow(self.root, self.current_data)
        ai_window.show()
    
    def save_session(self):
        """æ‰‹å‹•ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜"""
        try:
            saved_file = self.session_manager.save_session()
            messagebox.showinfo("Success", f"Session saved: {saved_file.name}")
        except Exception as e:
            messagebox.showerror("Error", f"Failed to save session: {e}")
    
    def _open_ml_dialog(self):
        """æ©Ÿæ¢°å­¦ç¿’ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’é–‹ã"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return
        
        # æ©Ÿæ¢°å­¦ç¿’ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã®å®Ÿè£…ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        ml_window = tk.Toplevel(self.root)
        ml_window.title("æ©Ÿæ¢°å­¦ç¿’è§£æ")
        ml_window.geometry("600x400")
        
        # æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•é¸æŠ
        ttk.Label(ml_window, text="æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•:").pack(pady=5)
        ml_method = ttk.Combobox(ml_window, values=[
            "Random Forest", "XGBoost", "LightGBM", 
            "SVM", "Logistic Regression", "Linear Regression"
        ])
        ml_method.pack(pady=5)
        ml_method.set("Random Forest")
        
        # å®Ÿè¡Œãƒœã‚¿ãƒ³
        def run_ml():
            method = ml_method.get()
            messagebox.showinfo("Info", f"{method}ã‚’å®Ÿè¡Œã—ã¾ã™ï¼ˆå®Ÿè£…äºˆå®šï¼‰")
        
        ttk.Button(ml_window, text="å®Ÿè¡Œ", command=run_ml).pack(pady=10)
    
    def _open_dl_dialog(self):
        """æ·±å±¤å­¦ç¿’ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’é–‹ã"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return
        
        # æ·±å±¤å­¦ç¿’ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã®å®Ÿè£…ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        dl_window = tk.Toplevel(self.root)
        dl_window.title("æ·±å±¤å­¦ç¿’è§£æ")
        dl_window.geometry("600x400")
        
        # GPUçŠ¶æ…‹è¡¨ç¤º
        gpu_status = "âœ… CUDAåˆ©ç”¨å¯èƒ½" if CUDA_AVAILABLE else "âŒ CPUä½¿ç”¨"
        ttk.Label(dl_window, text=f"GPUçŠ¶æ…‹: {gpu_status}").pack(pady=5)
        
        # æ·±å±¤å­¦ç¿’æ‰‹æ³•é¸æŠ
        ttk.Label(dl_window, text="æ·±å±¤å­¦ç¿’æ‰‹æ³•:").pack(pady=5)
        dl_method = ttk.Combobox(dl_window, values=[
            "Neural Network", "CNN", "RNN", "LSTM", "Transformer"
        ])
        dl_method.pack(pady=5)
        dl_method.set("Neural Network")
        
        # å®Ÿè¡Œãƒœã‚¿ãƒ³
        def run_dl():
            method = dl_method.get()
            messagebox.showinfo("Info", f"{method}ã‚’å®Ÿè¡Œã—ã¾ã™ï¼ˆå®Ÿè£…äºˆå®šï¼‰")
        
        ttk.Button(dl_window, text="å®Ÿè¡Œ", command=run_dl).pack(pady=10)
        dl_window = DeepLearningWindow(self.root, self.current_data)
        dl_window.show()
    
    # ==================== é«˜åº¦çµ±è¨ˆè§£æãƒ¡ã‚½ãƒƒãƒ‰ ====================
    
    def multivariate_analysis(self):
        """å¤šå¤‰é‡è§£æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first!")
            return
        
        if not hasattr(self, 'advanced_features') or not self.advanced_features:
            messagebox.showwarning("Warning", "Advanced features not available!")
            return
        
        try:
            self._update_status("ğŸ”¬ å®Ÿè¡Œä¸­: å¤šå¤‰é‡è§£æ...")
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ä½œæˆ
            progress_window = tk.Toplevel(self.root)
            progress_window.title("å¤šå¤‰é‡è§£æå®Ÿè¡Œä¸­")
            progress_window.geometry("400x150")
            progress_window.transient(self.root)
            progress_window.grab_set()
            
            progress_label = ctk.CTkLabel(progress_window, text="å¤šå¤‰é‡è§£æã‚’å®Ÿè¡Œä¸­ã§ã™...")
            progress_label.pack(pady=20)
            
            progress_bar = ctk.CTkProgressBar(progress_window)
            progress_bar.pack(pady=10, padx=20, fill="x")
            progress_bar.set(0)
            
            def run_analysis():
                try:
                    # ãƒ‡ãƒ¼ã‚¿æœ€é©åŒ–
                    progress_bar.set(0.2)
                    progress_window.update()
                    optimized_data = self.parallel_processor.optimize_dataframe_operations(self.current_data)
                    
                    # å¤šå¤‰é‡è§£æå®Ÿè¡Œ
                    progress_bar.set(0.5)
                    progress_window.update()
                    results = self.advanced_analyzer.multivariate_analysis(optimized_data)
                    
                    # çµæœè¡¨ç¤º
                    progress_bar.set(1.0)
                    progress_window.update()
                    
                    # çµæœã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ä½œæˆ
                    result_window = tk.Toplevel(self.root)
                    result_window.title("ğŸ”¬ å¤šå¤‰é‡è§£æçµæœ")
                    result_window.geometry("1000x700")
                    
                    # ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ï¼ˆã‚¿ãƒ–ï¼‰ä½œæˆ
                    notebook = ctk.CTkTabview(result_window)
                    notebook.pack(fill="both", expand=True, padx=10, pady=10)
                    
                    # PCAçµæœã‚¿ãƒ–
                    pca_tab = notebook.add("ä¸»æˆåˆ†åˆ†æ")
                    pca_text = ctk.CTkTextbox(pca_tab, font=("Consolas", 11))
                    pca_text.pack(fill="both", expand=True, padx=5, pady=5)
                    
                    pca_results = results.get('pca', {})
                    pca_content = f"""
ğŸ“Š ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰çµæœ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ KaiseråŸºæº–ã«ã‚ˆã‚‹æˆåˆ†æ•°: {pca_results.get('n_components_kaiser', 'N/A')}
ğŸ“ˆ ç´¯ç©å¯„ä¸ç‡80%ã®æˆåˆ†æ•°: {pca_results.get('n_components_80', 'N/A')}

ğŸ“Š å¯„ä¸ç‡ï¼ˆä¸Šä½10æˆåˆ†ï¼‰:
"""
                    explained_var = pca_results.get('explained_variance_ratio', [])
                    for i, var in enumerate(explained_var[:10]):
                        pca_content += f"PC{i+1}: {var*100:.2f}%\n"
                    
                    cumulative_var = pca_results.get('cumulative_variance', [])
                    if cumulative_var:
                        pca_content += f"\nğŸ“ˆ ç´¯ç©å¯„ä¸ç‡ï¼ˆPC10ã¾ã§ï¼‰: {cumulative_var[min(9, len(cumulative_var)-1)]*100:.2f}%\n"
                    
                    pca_text.insert("1.0", pca_content)
                    
                    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã‚¿ãƒ–
                    cluster_tab = notebook.add("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°")
                    cluster_text = ctk.CTkTextbox(cluster_tab, font=("Consolas", 11))
                    cluster_text.pack(fill="both", expand=True, padx=5, pady=5)
                    
                    clustering_results = results.get('clustering', {})
                    kmeans_results = clustering_results.get('kmeans', {})
                    
                    cluster_content = f"""
ğŸ¯ K-means ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿æ•°: {kmeans_results.get('optimal_k', 'N/A')}

ğŸ“Š ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿æ•°åˆ¥ï¼‰:
"""
                    silhouette_scores = kmeans_results.get('silhouette_scores', [])
                    for i, score in enumerate(silhouette_scores):
                        cluster_content += f"K={i+2}: {score:.4f}\n"
                    
                    dbscan_results = clustering_results.get('dbscan', {})
                    if 'n_clusters' in dbscan_results:
                        cluster_content += f"\nğŸ” DBSCANæ¤œå‡ºã‚¯ãƒ©ã‚¹ã‚¿æ•°: {dbscan_results['n_clusters']}\n"
                    
                    cluster_text.insert("1.0", cluster_content)
                    
                    # ç›¸é–¢åˆ†æã‚¿ãƒ–
                    corr_tab = notebook.add("ç›¸é–¢åˆ†æ")
                    corr_text = ctk.CTkTextbox(corr_tab, font=("Consolas", 11))
                    corr_text.pack(fill="both", expand=True, padx=5, pady=5)
                    
                    correlation_results = results.get('correlation', {})
                    high_corr = correlation_results.get('high_correlations', [])
                    
                    corr_content = """
ğŸ”— ç›¸é–¢åˆ†æçµæœ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸ é«˜ç›¸é–¢ãƒšã‚¢ï¼ˆ|r| > 0.7ï¼‰:

"""
                    if high_corr:
                        for pair in high_corr:
                            corr_content += f"â€¢ {pair['var1']} âŸ· {pair['var2']}: r = {pair['correlation']:.4f}\n"
                    else:
                        corr_content += "é«˜ç›¸é–¢ãƒšã‚¢ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n"
                    
                    corr_text.insert("1.0", corr_content)
                    
                    progress_window.destroy()
                    self._update_status("âœ… å¤šå¤‰é‡è§£æå®Œäº†")
                    
                except Exception as e:
                    progress_window.destroy()
                    messagebox.showerror("Error", f"å¤šå¤‰é‡è§£æã‚¨ãƒ©ãƒ¼: {e}")
                    self._update_status("âŒ å¤šå¤‰é‡è§£æå¤±æ•—")
            
            # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
            threading.Thread(target=run_analysis, daemon=True).start()
            
        except Exception as e:
            messagebox.showerror("Error", f"å¤šå¤‰é‡è§£æã‚¨ãƒ©ãƒ¼: {e}")
            self._update_status("âŒ å¤šå¤‰é‡è§£æå¤±æ•—")
    
    def time_series_analysis(self):
        """æ™‚ç³»åˆ—è§£æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first!")
            return
        
        if not hasattr(self, 'advanced_features') or not self.advanced_features:
            messagebox.showwarning("Warning", "Advanced features not available!")
            return
        
        # æ™‚ç³»åˆ—è§£æç”¨ã®ãƒ€ã‚¤ã‚¢ãƒ­ã‚°
        dialog = tk.Toplevel(self.root)
        dialog.title("ğŸ“ˆ æ™‚ç³»åˆ—è§£æè¨­å®š")
        dialog.geometry("400x300")
        dialog.transient(self.root)
        dialog.grab_set()
        
        # æ—¥ä»˜åˆ—é¸æŠ
        date_frame = ctk.CTkFrame(dialog)
        date_frame.pack(fill="x", padx=10, pady=5)
        
        ctk.CTkLabel(date_frame, text="æ—¥ä»˜åˆ—:").pack(side="left", padx=5)
        date_var = ctk.CTkComboBox(date_frame, values=list(self.current_data.columns))
        date_var.pack(side="right", padx=5)
        
        # å€¤åˆ—é¸æŠ
        value_frame = ctk.CTkFrame(dialog)
        value_frame.pack(fill="x", padx=10, pady=5)
        
        ctk.CTkLabel(value_frame, text="å€¤åˆ—:").pack(side="left", padx=5)
        value_var = ctk.CTkComboBox(value_frame, values=list(self.current_data.select_dtypes(include=[np.number]).columns))
        value_var.pack(side="right", padx=5)
        
        def run_ts_analysis():
            date_col = date_var.get()
            value_col = value_var.get()
            
            if not date_col or not value_col:
                messagebox.showwarning("Warning", "Please select both date and value columns!")
                return
            
            dialog.destroy()
            
            try:
                self._update_status("ğŸ“ˆ å®Ÿè¡Œä¸­: æ™‚ç³»åˆ—è§£æ...")
                results = self.advanced_analyzer.time_series_analysis(self.current_data, date_col, value_col)
                
                # çµæœè¡¨ç¤º
                result_text = f"""
ğŸ“ˆ æ™‚ç³»åˆ—è§£æçµæœ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š åŸºæœ¬çµ±è¨ˆ:
å¹³å‡: {results['basic_stats']['mean']:.4f}
æ¨™æº–åå·®: {results['basic_stats']['std']:.4f}
è¦³æ¸¬æ•°: {results['basic_stats']['observations']}

ğŸ” å®šå¸¸æ€§æ¤œå®š:
ADFæ¤œå®š på€¤: {results['stationarity_tests']['adf']['p_value']:.6f}
â†’ å®šå¸¸æ€§: {'Yes' if results['stationarity_tests']['adf']['is_stationary'] else 'No'}

KPSSæ¤œå®š på€¤: {results['stationarity_tests']['kpss']['p_value']:.6f}
â†’ å®šå¸¸æ€§: {'Yes' if results['stationarity_tests']['kpss']['is_stationary'] else 'No'}
"""
                
                arima_results = results.get('arima', {})
                if 'best_params' in arima_results:
                    result_text += f"""
ğŸ“Š ARIMA ãƒ¢ãƒ‡ãƒ«:
æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {arima_results['best_params']}
AIC: {arima_results['aic']:.4f}
BIC: {arima_results['bic']:.4f}
"""
                
                self.result_text.delete("1.0", tk.END)
                self.result_text.insert("1.0", result_text)
                self._update_status("âœ… æ™‚ç³»åˆ—è§£æå®Œäº†")
                
            except Exception as e:
                messagebox.showerror("Error", f"æ™‚ç³»åˆ—è§£æã‚¨ãƒ©ãƒ¼: {e}")
                self._update_status("âŒ æ™‚ç³»åˆ—è§£æå¤±æ•—")
        
        # å®Ÿè¡Œãƒœã‚¿ãƒ³
        button_frame = ctk.CTkFrame(dialog)
        button_frame.pack(fill="x", padx=10, pady=10)
        
        ctk.CTkButton(button_frame, text="å®Ÿè¡Œ", command=run_ts_analysis).pack(side="right", padx=5)
        ctk.CTkButton(button_frame, text="ã‚­ãƒ£ãƒ³ã‚»ãƒ«", command=dialog.destroy).pack(side="right", padx=5)
    
    def survival_analysis(self):
        """ç”Ÿå­˜è§£æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first!")
            return
        
        if not hasattr(self, 'advanced_features') or not self.advanced_features:
            messagebox.showwarning("Warning", "Advanced features not available!")
            return
        
        messagebox.showinfo("Info", "ç”Ÿå­˜è§£ææ©Ÿèƒ½ã¯é–‹ç™ºä¸­ã§ã™ã€‚æ¬¡å›ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§è¿½åŠ äºˆå®šã§ã™ã€‚")
    
    def bayesian_analysis(self):
        """ãƒ™ã‚¤ã‚ºçµ±è¨ˆè§£æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first!")
            return
        
        if not hasattr(self, 'advanced_features') or not self.advanced_features:
            messagebox.showwarning("Warning", "Advanced features not available!")
            return
        
        messagebox.showinfo("Info", "ãƒ™ã‚¤ã‚ºçµ±è¨ˆè§£ææ©Ÿèƒ½ã¯é–‹ç™ºä¸­ã§ã™ã€‚PyMCãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™ã€‚")
    
    def comprehensive_eda(self):
        """åŒ…æ‹¬çš„æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿è§£æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first!")
            return
        
        if not hasattr(self, 'advanced_features') or not self.advanced_features:
            messagebox.showwarning("Warning", "Advanced features not available!")
            return
        
        try:
            self._update_status("ğŸ“Š å®Ÿè¡Œä¸­: åŒ…æ‹¬çš„EDA...")
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            progress_window = tk.Toplevel(self.root)
            progress_window.title("åŒ…æ‹¬çš„EDAå®Ÿè¡Œä¸­")
            progress_window.geometry("400x120")
            progress_window.transient(self.root)
            progress_window.grab_set()
            
            progress_label = ctk.CTkLabel(progress_window, text="ãƒ‡ãƒ¼ã‚¿è§£æä¸­...")
            progress_label.pack(pady=10)
            
            progress_bar = ctk.CTkProgressBar(progress_window)
            progress_bar.pack(pady=10, padx=20, fill="x")
            progress_bar.set(0)
            
            def run_eda():
                try:
                    progress_bar.set(0.3)
                    progress_window.update()
                    
                    results = self.advanced_analyzer.comprehensive_eda(self.current_data)
                    
                    progress_bar.set(1.0)
                    progress_window.update()
                    
                    # çµæœè¡¨ç¤º
                    result_text = f"""
ğŸ“Š åŒ…æ‹¬çš„æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿è§£æï¼ˆEDAï¼‰çµæœ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:
â€¢ ç·è¡Œæ•°: {results['data_overview']['total_rows']:,}
â€¢ ç·åˆ—æ•°: {results['data_overview']['total_columns']}
â€¢ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {results['data_overview']['memory_usage_mb']:.1f} MB
â€¢ æ•°å€¤åˆ—: {results['data_overview']['numeric_columns']}
â€¢ ã‚«ãƒ†ã‚´ãƒªåˆ—: {results['data_overview']['categorical_columns']}

âŒ æ¬ æå€¤åˆ†æ:
â€¢ æ¬ æå€¤ç·æ•°: {results['missing_values']['total_missing']:,}
â€¢ æ¬ æå€¤ã®ã‚ã‚‹åˆ—æ•°: {results['missing_values']['columns_with_missing']}
â€¢ å®Œå…¨ãªè¡Œæ•°: {results['missing_values']['complete_rows']:,}

ğŸ¯ å¤–ã‚Œå€¤æ¤œå‡ºï¼ˆä¸Šä½5åˆ—ï¼‰:
"""
                    outliers = results.get('outliers', {})
                    for i, (col, info) in enumerate(list(outliers.items())[:5]):
                        result_text += f"â€¢ {col}: IQRæ³• {info['iqr_outliers']}å€‹ ({info['outlier_percentage_iqr']:.1f}%)\n"
                    
                    # åˆ†å¸ƒåˆ†æ
                    distributions = results.get('distributions', {})
                    normal_cols = [col for col, info in distributions.items() if info.get('is_normal', False)]
                    
                    result_text += f"""

ğŸ“ˆ åˆ†å¸ƒåˆ†æ:
â€¢ æ­£è¦åˆ†å¸ƒã«å¾“ã†åˆ—: {len(normal_cols)}å€‹
â€¢ éæ­£è¦åˆ†å¸ƒã®åˆ—: {len(distributions) - len(normal_cols)}å€‹

ğŸ”— é–¢ä¿‚æ€§åˆ†æ:
"""
                    relationships = results.get('relationships', {})
                    if 'strong_correlations' in relationships:
                        strong_corr = relationships['strong_correlations']
                        result_text += f"â€¢ å¼·ã„ç›¸é–¢ã‚’æŒã¤ãƒšã‚¢: {len(strong_corr)}å€‹\n"
                        
                        if strong_corr:
                            result_text += "\nå¼·ç›¸é–¢ãƒšã‚¢:\n"
                            for pair in strong_corr[:5]:  # ä¸Šä½5å€‹
                                result_text += f"  - {pair['var1']} âŸ· {pair['var2']}: r = {pair['correlation']:.3f}\n"
                    
                    result_text += f"""

âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±:
â€¢ è§£æå®Œäº†æ™‚åˆ»: {results['timestamp']}
â€¢ ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {results['data_shape']}
"""
                    
                    progress_window.destroy()
                    
                    self.result_text.delete("1.0", tk.END)
                    self.result_text.insert("1.0", result_text)
                    self._update_status("âœ… åŒ…æ‹¬çš„EDAå®Œäº†")
                    
                except Exception as e:
                    progress_window.destroy()
                    messagebox.showerror("Error", f"EDAã‚¨ãƒ©ãƒ¼: {e}")
                    self._update_status("âŒ EDAå¤±æ•—")
            
            threading.Thread(target=run_eda, daemon=True).start()
            
        except Exception as e:
            messagebox.showerror("Error", f"EDAã‚¨ãƒ©ãƒ¼: {e}")
            self._update_status("âŒ EDAå¤±æ•—")
    
    def run(self):
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        try:
            self.root.mainloop()
        except KeyboardInterrupt:
            print("\nğŸ›‘ Application interrupted by user")
        finally:
            # çµ‚äº†æ™‚ä¿å­˜
            try:
                self.session_manager.save_session()
                print("âœ… Final session saved")
            except:
                pass

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ”¬ Professional Statistical Analysis Software")
    print("=" * 50)
    print(f"Python: {sys.version}")
    print(f"CUDA: {'Available' if CUDA_AVAILABLE else 'Not Available'}")
    if CUDA_AVAILABLE:
        print(f"GPU: {GPU_NAME}")
    print("=" * 50)
    
    try:
        app = StatisticalAnalysisGUI()
        app.run()
    except Exception as e:
        print(f"âŒ Application error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 