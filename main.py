#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Professional Python GUI Statistical Analysis Software
ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«çµ±è¨ˆè§£æã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢

Author: Ryo Minegishi
Email: r.minegishi1987@gmail.com
GitHub: @zapabob
License: MIT
"""

import sys
import os
import json
import pickle
import signal
import time
import uuid
import threading
from datetime import datetime
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# GUI ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

# æ•°å€¤è¨ˆç®—ãƒ»ãƒ‡ãƒ¼ã‚¿å‡¦ç†
import numpy as np
import pandas as pd
import scipy.stats as stats
from scipy import signal as scipy_signal

# çµ±è¨ˆè§£æ
import statsmodels.api as sm
import statsmodels.stats.api as sms
import pingouin as pg
from lifelines import KaplanMeierFitter, CoxPHFitter

# æ©Ÿæ¢°å­¦ç¿’
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
import xgboost as xgb
import lightgbm as lgb

# å¯è¦–åŒ–
import matplotlib.pyplot as plt
import matplotlib.style as mpl_style
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
from tqdm import tqdm
import psutil
import memory_profiler

# ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from professional_utils import (
        professional_logger, performance_monitor, exception_handler,
        security_manager, database_manager
    )
    from professional_reports import report_generator
    PROFESSIONAL_FEATURES_AVAILABLE = True
    print("âœ… ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    PROFESSIONAL_FEATURES_AVAILABLE = False
    print(f"âš ï¸ ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")

# é«˜åº¦å¯è¦–åŒ–ãƒ»ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from advanced_visualization import AdvancedVisualizer
    from data_preprocessing import DataPreprocessor
    ADVANCED_FEATURES_AVAILABLE = True
    print("âœ… é«˜åº¦å¯è¦–åŒ–ãƒ»ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
except ImportError as e:
    ADVANCED_FEATURES_AVAILABLE = False
    print(f"âš ï¸ é«˜åº¦å¯è¦–åŒ–ãƒ»ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {e}")
    
    # ã‚¹ã‚¿ãƒ–ã‚¯ãƒ©ã‚¹ä½œæˆ
    class AdvancedVisualizer:
        def __init__(self):
            pass
        def correlation_heatmap(self, *args, **kwargs):
            return None, "é«˜åº¦å¯è¦–åŒ–æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
    
    class DataPreprocessor:
        def __init__(self):
            pass
        def detect_outliers(self, *args, **kwargs):
            return {"success": False, "error": "ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"}

# AIçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from ai_integration import ai_analyzer
    AI_INTEGRATION_AVAILABLE = True
except ImportError as e:
    AI_INTEGRATION_AVAILABLE = False
    print("âš ï¸ AIçµ±åˆæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³ï¼‰")
    
    # AIæ©Ÿèƒ½ã®ã‚¹ã‚¿ãƒ–
    class AIStub:
        def __init__(self):
            self.analysis_history = []
        
        async def analyze_natural_language_query(self, *args, **kwargs):
            return {"success": False, "error": "AIæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"}
        
        async def analyze_image_data(self, *args, **kwargs):
            return {"success": False, "error": "AIæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"}
        
        def execute_generated_code(self, *args, **kwargs):
            return {"success": False, "error": "AIæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"}
    
    ai_analyzer = AIStub()

# CUDA/GPU æ¤œå‡º
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    CUDA_AVAILABLE = torch.cuda.is_available()
    GPU_NAME = torch.cuda.get_device_name(0) if CUDA_AVAILABLE else "None"
    DEVICE = torch.device('cuda' if CUDA_AVAILABLE else 'cpu')
except ImportError:
    CUDA_AVAILABLE = False
    GPU_NAME = "None"
    DEVICE = "cpu"

# è¿½åŠ ã®æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import MinMaxScaler, RobustScaler
from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor
from sklearn.svm import SVC, SVR
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor

# ãƒ†ãƒ¼ãƒè¨­å®š
ctk.set_appearance_mode("light")
ctk.set_default_color_theme("blue")
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class SessionManager:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ»é›»æºæ–­ä¿è­·ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, app_instance):
        self.app = app_instance
        self.session_id = str(uuid.uuid4())
        self.backup_dir = Path("backup")
        self.checkpoint_dir = Path("checkpoints")
        self.auto_save_interval = 300  # 5åˆ†é–“éš”
        self.backup_count = 10
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.backup_dir.mkdir(exist_ok=True)
        self.checkpoint_dir.mkdir(exist_ok=True)
        
        # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š
        try:
            signal.signal(signal.SIGINT, self._emergency_save)
            signal.signal(signal.SIGTERM, self._emergency_save)
            if hasattr(signal, 'SIGBREAK'):
                signal.signal(signal.SIGBREAK, self._emergency_save)
        except Exception as e:
            print(f"âš ï¸ ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        
        # è‡ªå‹•ä¿å­˜ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹
        self._start_auto_save()
        
        print(f"ğŸ›¡ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹: {self.session_id}")
        print(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {self.backup_dir.absolute()}")
    
    def _start_auto_save(self):
        """è‡ªå‹•ä¿å­˜ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹"""
        try:
            self.auto_save_timer = threading.Timer(self.auto_save_interval, self._auto_save)
            self.auto_save_timer.daemon = True
            self.auto_save_timer.start()
        except Exception as e:
            print(f"âš ï¸ è‡ªå‹•ä¿å­˜ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _auto_save(self):
        """å®šæœŸè‡ªå‹•ä¿å­˜"""
        try:
            self.save_session()
            print(f"âœ… è‡ªå‹•ä¿å­˜å®Œäº†: {datetime.now().strftime('%H:%M:%S')}")
        except Exception as e:
            print(f"âŒ è‡ªå‹•ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        finally:
            self._start_auto_save()  # æ¬¡ã®è‡ªå‹•ä¿å­˜ã‚’äºˆç´„
    
    def _emergency_save(self, signum=None, frame=None):
        """ç·Šæ€¥ä¿å­˜ï¼ˆç•°å¸¸çµ‚äº†æ™‚ï¼‰"""
        print("\nğŸš¨ ç·Šæ€¥ä¿å­˜ã‚’å®Ÿè¡Œä¸­...")
        try:
            self.save_session(emergency=True)
            print("âœ… ç·Šæ€¥ä¿å­˜å®Œäº†")
        except Exception as e:
            print(f"âŒ ç·Šæ€¥ä¿å­˜å¤±æ•—: {e}")
        finally:
            sys.exit(0)
    
    def save_session(self, emergency=False):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        prefix = "emergency_" if emergency else "auto_"
        
        session_data = {
            'session_id': self.session_id,
            'timestamp': timestamp,
            'data': getattr(self.app, 'current_data', None),
            'analysis_results': getattr(self.app, 'analysis_results', {}),
            'settings': getattr(self.app, 'user_settings', {}),
            'gpu_info': {'available': CUDA_AVAILABLE, 'name': GPU_NAME}
        }
        
        # JSONä¿å­˜
        json_file = self.checkpoint_dir / f"{prefix}session_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(session_data, f, ensure_ascii=False, indent=2, default=str)
        
        # Pickleä¿å­˜ï¼ˆå¤§å®¹é‡ãƒ‡ãƒ¼ã‚¿ç”¨ï¼‰
        pkl_file = self.checkpoint_dir / f"{prefix}session_{timestamp}.pkl"
        with open(pkl_file, 'wb') as f:
            pickle.dump(session_data, f)
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
        self._rotate_backups()
        
        return json_file
    
    def _rotate_backups(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†"""
        backup_files = sorted(self.checkpoint_dir.glob("auto_session_*.json"))
        if len(backup_files) > self.backup_count:
            for old_file in backup_files[:-self.backup_count]:
                old_file.unlink()
                pkl_file = old_file.with_suffix('.pkl')
                if pkl_file.exists():
                    pkl_file.unlink()
    
    def load_latest_session(self):
        """æœ€æ–°ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å¾©æ—§"""
        backup_files = sorted(self.checkpoint_dir.glob("*.json"))
        if not backup_files:
            return None
        
        latest_file = backup_files[-1]
        try:
            with open(latest_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©æ—§ã‚¨ãƒ©ãƒ¼: {e}")
            return None

class MLAnalysisWindow:
    """æ©Ÿæ¢°å­¦ç¿’åˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦"""
    
    def __init__(self, parent, data, variable_selection=None):
        self.parent = parent
        self.data = data
        self.variable_selection = variable_selection or {}
        self.window = None
        self.models = {}
        self.results = {}
    
    def show(self):
        """ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¡¨ç¤º"""
        self.window = tk.Toplevel(self.parent)
        self.window.title("ğŸ¤– Machine Learning Analysis")
        self.window.geometry("800x600")
        
        # ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ 
        main_frame = ctk.CTkFrame(self.window)
        main_frame.pack(fill="both", expand=True, padx=10, pady=10)
        
        # ã‚¿ã‚¹ã‚¯é¸æŠ
        task_frame = ctk.CTkFrame(main_frame)
        task_frame.pack(fill="x", padx=5, pady=5)
        
        ctk.CTkLabel(task_frame, text="ğŸ¯ Machine Learning Task", font=("Arial", 16, "bold")).pack(pady=5)
        
        self.task_var = tk.StringVar(value="classification")
        task_radio1 = ctk.CTkRadioButton(task_frame, text="Classification", variable=self.task_var, value="classification")
        task_radio2 = ctk.CTkRadioButton(task_frame, text="Regression", variable=self.task_var, value="regression")
        task_radio1.pack(side="left", padx=20)
        task_radio2.pack(side="left", padx=20)
        
        # ç‰¹å¾´é‡ãƒ»ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¸æŠ
        feature_frame = ctk.CTkFrame(main_frame)
        feature_frame.pack(fill="x", padx=5, pady=5)
        
        ctk.CTkLabel(feature_frame, text="ğŸ“Š Feature & Target Selection").pack(pady=5)
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¸æŠ
        target_frame = ctk.CTkFrame(feature_frame)
        target_frame.pack(fill="x", padx=5, pady=2)
        
        ctk.CTkLabel(target_frame, text="Target Variable:").pack(side="left", padx=5)
        self.target_var = ctk.CTkComboBox(target_frame, values=list(self.data.columns))
        self.target_var.pack(side="left", padx=5)
        
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ
        algo_frame = ctk.CTkFrame(main_frame)
        algo_frame.pack(fill="x", padx=5, pady=5)
        
        ctk.CTkLabel(algo_frame, text="ğŸ”§ Algorithm Selection").pack(pady=5)
        
        self.algo_var = ctk.CTkComboBox(algo_frame, values=[
            "Random Forest", "XGBoost", "LightGBM", "SVM", 
            "Gradient Boosting", "Decision Tree", "Neural Network"
        ])
        self.algo_var.pack(pady=5)
        self.algo_var.set("Random Forest")
        
        # GPUä½¿ç”¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        if CUDA_AVAILABLE:
            gpu_frame = ctk.CTkFrame(main_frame)
            gpu_frame.pack(fill="x", padx=5, pady=5)
            
            self.use_gpu = tk.BooleanVar(value=True)
            gpu_check = ctk.CTkCheckBox(gpu_frame, text=f"âš¡ Use GPU ({GPU_NAME})", variable=self.use_gpu)
            gpu_check.pack(pady=5)
        
        # å®Ÿè¡Œãƒœã‚¿ãƒ³
        button_frame = ctk.CTkFrame(main_frame)
        button_frame.pack(fill="x", padx=5, pady=10)
        
        run_btn = ctk.CTkButton(button_frame, text="ğŸš€ Run Analysis", command=self.run_analysis)
        run_btn.pack(side="left", padx=5)
        
        optimize_btn = ctk.CTkButton(button_frame, text="âš™ï¸ Hyperparameter Optimization", command=self.optimize_hyperparameters)
        optimize_btn.pack(side="left", padx=5)
        
        # çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
        self.result_text = ctk.CTkTextbox(main_frame, height=300)
        self.result_text.pack(fill="both", expand=True, padx=5, pady=5)
    
    def run_analysis(self):
        """æ©Ÿæ¢°å­¦ç¿’åˆ†æå®Ÿè¡Œ"""
        try:
            target_col = self.target_var.get()
            if not target_col:
                messagebox.showwarning("Warning", "Please select target variable")
                return
            
            self.result_text.delete("1.0", "end")
            self.result_text.insert("1.0", "ğŸ¤– Starting Machine Learning Analysis...\n\n")
            
            # å¤‰æ•°é¸æŠã®æ´»ç”¨
            if self.variable_selection.get('control_variables'):
                # çµ±åˆ¶å¤‰æ•°ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
                feature_cols = self.variable_selection['control_variables']
                self.result_text.insert("end", f"ğŸ¯ Using selected control variables: {', '.join(feature_cols)}\n\n")
            else:
                # å¾“æ¥ã®æ–¹æ³•ï¼ˆæ•°å€¤å‹åˆ—ã‚’è‡ªå‹•é¸æŠï¼‰
                feature_cols = self.data.select_dtypes(include=[np.number]).columns.tolist()
                if target_col in feature_cols:
                    feature_cols.remove(target_col)
                self.result_text.insert("end", f"ğŸ“Š Using all numeric variables as features\n\n")
            
            if len(feature_cols) == 0:
                messagebox.showerror("Error", "No feature variables found")
                return
            
            X = self.data[feature_cols].fillna(0)
            y = self.data[target_col].fillna(0)
            
            # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†
            task_type = self.task_var.get()
            
            if task_type == "classification":
                # åˆ†é¡ã‚¿ã‚¹ã‚¯
                if y.dtype == 'object':
                    le = LabelEncoder()
                    y = le.fit_transform(y)
                
                results = self._run_classification(X, y)
            else:
                # å›å¸°ã‚¿ã‚¹ã‚¯
                results = self._run_regression(X, y)
            
            # çµæœè¡¨ç¤º
            self._display_results(results)
            
        except Exception as e:
            messagebox.showerror("Error", f"Analysis failed: {str(e)}")
            self.result_text.insert("end", f"\nâŒ Error: {str(e)}")
    
    def _run_classification(self, X, y):
        """åˆ†é¡ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ"""
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ
        algo = self.algo_var.get()
        
        if algo == "Random Forest":
            model = RandomForestClassifier(n_estimators=100, random_state=42)
        elif algo == "XGBoost":
            model = xgb.XGBClassifier(random_state=42)
        elif algo == "LightGBM":
            model = lgb.LGBMClassifier(random_state=42, verbose=-1)
        elif algo == "SVM":
            model = SVC(random_state=42)
        elif algo == "Gradient Boosting":
            model = GradientBoostingClassifier(random_state=42)
        elif algo == "Decision Tree":
            model = DecisionTreeClassifier(random_state=42)
        else:  # Neural Network
            return self._run_neural_network_classification(X_train_scaled, X_test_scaled, y_train, y_test)
        
        # å­¦ç¿’
        with tqdm(total=1, desc="Training") as pbar:
            model.fit(X_train_scaled, y_train)
            pbar.update(1)
        
        # äºˆæ¸¬
        y_pred = model.predict(X_test_scaled)
        y_pred_proba = model.predict_proba(X_test_scaled) if hasattr(model, 'predict_proba') else None
        
        # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)
        
        # ç‰¹å¾´é‡é‡è¦åº¦
        if hasattr(model, 'feature_importances_'):
            feature_importance = dict(zip(X.columns, model.feature_importances_))
        else:
            feature_importance = None
        
        return {
            'task': 'classification',
            'algorithm': algo,
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'feature_importance': feature_importance,
            'model': model,
            'confusion_matrix': confusion_matrix(y_test, y_pred)
        }
    
    def _run_regression(self, X, y):
        """å›å¸°ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ"""
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ
        algo = self.algo_var.get()
        
        if algo == "Random Forest":
            model = RandomForestRegressor(n_estimators=100, random_state=42)
        elif algo == "XGBoost":
            model = xgb.XGBRegressor(random_state=42)
        elif algo == "LightGBM":
            model = lgb.LGBMRegressor(random_state=42, verbose=-1)
        elif algo == "SVM":
            model = SVR()
        elif algo == "Gradient Boosting":
            model = GradientBoostingRegressor(random_state=42)
        elif algo == "Decision Tree":
            model = DecisionTreeRegressor(random_state=42)
        else:  # Neural Network
            return self._run_neural_network_regression(X_train_scaled, X_test_scaled, y_train, y_test)
        
        # å­¦ç¿’
        with tqdm(total=1, desc="Training") as pbar:
            model.fit(X_train_scaled, y_train)
            pbar.update(1)
        
        # äºˆæ¸¬
        y_pred = model.predict(X_test_scaled)
        
        # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
        
        # ç‰¹å¾´é‡é‡è¦åº¦
        if hasattr(model, 'feature_importances_'):
            feature_importance = dict(zip(X.columns, model.feature_importances_))
        else:
            feature_importance = None
        
        return {
            'task': 'regression',
            'algorithm': algo,
            'mse': mse,
            'rmse': np.sqrt(mse),
            'mae': mae,
            'r2_score': r2,
            'feature_importance': feature_importance,
            'model': model
        }
    
    def _run_neural_network_classification(self, X_train, X_test, y_train, y_test):
        """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†é¡"""
        # PyTorchã§ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å®Ÿè£…
        n_features = X_train.shape[1]
        n_classes = len(np.unique(y_train))
        
        class SimpleNN(nn.Module):
            def __init__(self, input_size, hidden_size, num_classes):
                super(SimpleNN, self).__init__()
                self.fc1 = nn.Linear(input_size, hidden_size)
                self.fc2 = nn.Linear(hidden_size, hidden_size//2)
                self.fc3 = nn.Linear(hidden_size//2, num_classes)
                self.relu = nn.ReLU()
                self.dropout = nn.Dropout(0.2)
                
            def forward(self, x):
                x = self.relu(self.fc1(x))
                x = self.dropout(x)
                x = self.relu(self.fc2(x))
                x = self.dropout(x)
                x = self.fc3(x)
                return x
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’Tensorã«å¤‰æ›
        X_train_tensor = torch.FloatTensor(X_train).to(DEVICE)
        X_test_tensor = torch.FloatTensor(X_test).to(DEVICE)
        y_train_tensor = torch.LongTensor(y_train).to(DEVICE)
        y_test_tensor = torch.LongTensor(y_test).to(DEVICE)
        
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = SimpleNN(n_features, 128, n_classes).to(DEVICE)
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        # å­¦ç¿’
        model.train()
        epochs = 100
        with tqdm(total=epochs, desc="Neural Network Training") as pbar:
            for epoch in range(epochs):
                optimizer.zero_grad()
                outputs = model(X_train_tensor)
                loss = criterion(outputs, y_train_tensor)
                loss.backward()
                optimizer.step()
                pbar.update(1)
        
        # è©•ä¾¡
        model.eval()
        with torch.no_grad():
            test_outputs = model(X_test_tensor)
            _, predicted = torch.max(test_outputs.data, 1)
            
        y_pred = predicted.cpu().numpy()
        y_test_np = y_test_tensor.cpu().numpy()
        
        accuracy = accuracy_score(y_test_np, y_pred)
        precision = precision_score(y_test_np, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_test_np, y_pred, average='weighted', zero_division=0)
        f1 = f1_score(y_test_np, y_pred, average='weighted', zero_division=0)
        
        return {
            'task': 'classification',
            'algorithm': 'Neural Network (PyTorch)',
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'feature_importance': None,
            'model': model,
            'device': str(DEVICE),
            'confusion_matrix': confusion_matrix(y_test_np, y_pred)
        }
    
    def _run_neural_network_regression(self, X_train, X_test, y_train, y_test):
        """ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å›å¸°"""
        # å®Ÿè£…ã¯åŒæ§˜ã®æ§‹é€ ã§å›å¸°ç”¨ã«èª¿æ•´
        n_features = X_train.shape[1]
        
        class SimpleRegressionNN(nn.Module):
            def __init__(self, input_size, hidden_size):
                super(SimpleRegressionNN, self).__init__()
                self.fc1 = nn.Linear(input_size, hidden_size)
                self.fc2 = nn.Linear(hidden_size, hidden_size//2)
                self.fc3 = nn.Linear(hidden_size//2, 1)
                self.relu = nn.ReLU()
                self.dropout = nn.Dropout(0.2)
                
            def forward(self, x):
                x = self.relu(self.fc1(x))
                x = self.dropout(x)
                x = self.relu(self.fc2(x))
                x = self.dropout(x)
                x = self.fc3(x)
                return x
        
        # åŒæ§˜ã®å­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹
        X_train_tensor = torch.FloatTensor(X_train).to(DEVICE)
        X_test_tensor = torch.FloatTensor(X_test).to(DEVICE)
        y_train_tensor = torch.FloatTensor(y_train.values.reshape(-1, 1)).to(DEVICE)
        y_test_tensor = torch.FloatTensor(y_test.values.reshape(-1, 1)).to(DEVICE)
        
        model = SimpleRegressionNN(n_features, 128).to(DEVICE)
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        # å­¦ç¿’
        model.train()
        epochs = 100
        with tqdm(total=epochs, desc="Neural Network Training") as pbar:
            for epoch in range(epochs):
                optimizer.zero_grad()
                outputs = model(X_train_tensor)
                loss = criterion(outputs, y_train_tensor)
                loss.backward()
                optimizer.step()
                pbar.update(1)
        
        # è©•ä¾¡
        model.eval()
        with torch.no_grad():
            y_pred_tensor = model(X_test_tensor)
            
        y_pred = y_pred_tensor.cpu().numpy().flatten()
        y_test_np = y_test_tensor.cpu().numpy().flatten()
        
        mse = mean_squared_error(y_test_np, y_pred)
        mae = mean_absolute_error(y_test_np, y_pred)
        r2 = r2_score(y_test_np, y_pred)
        
        return {
            'task': 'regression',
            'algorithm': 'Neural Network (PyTorch)',
            'mse': mse,
            'rmse': np.sqrt(mse),
            'mae': mae,
            'r2_score': r2,
            'feature_importance': None,
            'model': model,
            'device': str(DEVICE)
        }
    
    def _display_results(self, results):
        """çµæœè¡¨ç¤º"""
        result_text = f"\nğŸ¯ Machine Learning Results\n"
        result_text += "=" * 50 + "\n\n"
        result_text += f"Algorithm: {results['algorithm']}\n"
        result_text += f"Task: {results['task'].capitalize()}\n"
        
        if 'device' in results:
            result_text += f"Device: {results['device']}\n"
        
        result_text += "\nğŸ“Š Performance Metrics:\n"
        
        if results['task'] == 'classification':
            result_text += f"â€¢ Accuracy: {results['accuracy']:.4f}\n"
            result_text += f"â€¢ Precision: {results['precision']:.4f}\n"
            result_text += f"â€¢ Recall: {results['recall']:.4f}\n"
            result_text += f"â€¢ F1-Score: {results['f1_score']:.4f}\n"
        else:
            result_text += f"â€¢ RÂ² Score: {results['r2_score']:.4f}\n"
            result_text += f"â€¢ MSE: {results['mse']:.4f}\n"
            result_text += f"â€¢ RMSE: {results['rmse']:.4f}\n"
            result_text += f"â€¢ MAE: {results['mae']:.4f}\n"
        
        if results['feature_importance']:
            result_text += "\nğŸ” Feature Importance (Top 5):\n"
            sorted_features = sorted(results['feature_importance'].items(), 
                                   key=lambda x: x[1], reverse=True)[:5]
            for feature, importance in sorted_features:
                result_text += f"â€¢ {feature}: {importance:.4f}\n"
        
        self.result_text.insert("end", result_text)
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        self.models[results['algorithm']] = results['model']
        self.results[results['algorithm']] = results
    
    def optimize_hyperparameters(self):
        """ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–"""
        messagebox.showinfo("Info", "âš™ï¸ Hyperparameter optimization starting...")
        # Optunaç­‰ã‚’ä½¿ã£ãŸæœ€é©åŒ–å®Ÿè£…ã¯æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§è¡Œã„ã¾ã™

class DeepLearningWindow:
    """æ·±å±¤å­¦ç¿’åˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦"""
    
    def __init__(self, parent, data, variable_selection=None):
        self.parent = parent
        self.data = data
        self.variable_selection = variable_selection or {}
        self.window = None
    
    def show(self):
        """ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¡¨ç¤º"""
        self.window = tk.Toplevel(self.parent)
        self.window.title("ğŸ§  Deep Learning Analysis")
        self.window.geometry("800x600")
        
        main_frame = ctk.CTkFrame(self.window)
        main_frame.pack(fill="both", expand=True, padx=10, pady=10)
        
        # æ·±å±¤å­¦ç¿’ãƒ¡ãƒ‹ãƒ¥ãƒ¼
        ctk.CTkLabel(main_frame, text="ğŸ§  Deep Learning Models", font=("Arial", 16, "bold")).pack(pady=10)
        
        # å„ç¨®æ·±å±¤å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒœã‚¿ãƒ³
        models = [
            ("ğŸ” Autoencoder", self.run_autoencoder),
            ("ğŸ“ˆ LSTM Time Series", self.run_lstm),
            ("ğŸ¯ Advanced CNN", self.run_cnn),
            ("ğŸ”® Transformer", self.run_transformer)
        ]
        
        for name, command in models:
            btn = ctk.CTkButton(main_frame, text=name, command=command, width=200, height=40)
            btn.pack(pady=5)
        
        # çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
        self.result_text = ctk.CTkTextbox(main_frame, height=300)
        self.result_text.pack(fill="both", expand=True, padx=5, pady=10)
    
    def run_autoencoder(self):
        messagebox.showinfo("Info", "ğŸ” Autoencoder implementation coming soon!")
    
    def run_lstm(self):
        messagebox.showinfo("Info", "ğŸ“ˆ LSTM implementation coming soon!")
    
    def run_cnn(self):
        messagebox.showinfo("Info", "ğŸ¯ CNN implementation coming soon!")
    
    def run_transformer(self):
        messagebox.showinfo("Info", "ğŸ”® Transformer implementation coming soon!")

class VariableSelectionWindow:
    """å¤‰æ•°é¸æŠã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ï¼ˆçµ±åˆ¶å¤‰æ•°ãƒ»ç›®çš„å¤‰æ•°ãƒ»å‰°ä½™å¤‰æ•°ï¼‰"""
    
    def __init__(self, parent, data, callback=None):
        self.parent = parent
        self.data = data
        self.callback = callback
        self.columns = list(data.columns)
        
        # å¤‰æ•°åˆ†é¡
        self.control_variables = []  # çµ±åˆ¶å¤‰æ•°
        self.target_variables = []   # ç›®çš„å¤‰æ•°
        self.residual_variables = [] # å‰°ä½™å¤‰æ•°
        
        self.window = None
        
    def show(self):
        """å¤‰æ•°é¸æŠã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¡¨ç¤º"""
        self.window = ctk.CTkToplevel(self.parent)
        self.window.title("ğŸ¯ Variable Selection - å¤‰æ•°é¸æŠ")
        self.window.geometry("800x700")
        self.window.grab_set()  # ãƒ¢ãƒ¼ãƒ€ãƒ«ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦åŒ–
        
        # ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ 
        main_frame = ctk.CTkFrame(self.window)
        main_frame.pack(fill="both", expand=True, padx=20, pady=20)
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        title_label = ctk.CTkLabel(main_frame, text="ğŸ¯ å¤‰æ•°åˆ†é¡è¨­å®š", font=("Arial", 18, "bold"))
        title_label.pack(pady=(0, 20))
        
        # èª¬æ˜æ–‡
        info_frame = ctk.CTkFrame(main_frame)
        info_frame.pack(fill="x", pady=(0, 20))
        
        info_text = """
ğŸ“Š å¤‰æ•°åˆ†é¡ã«ã¤ã„ã¦:
â€¢ çµ±åˆ¶å¤‰æ•°: åˆ†æã§åˆ¶å¾¡ã—ãŸã„èª¬æ˜å¤‰æ•°ï¼ˆç‹¬ç«‹å¤‰æ•°ï¼‰
â€¢ ç›®çš„å¤‰æ•°: äºˆæ¸¬ãƒ»èª¬æ˜ã—ãŸã„å¾“å±å¤‰æ•°ï¼ˆã‚¢ã‚¦ãƒˆã‚«ãƒ ï¼‰
â€¢ å‰°ä½™å¤‰æ•°: åˆ†æã«å«ã‚ãªã„å¤‰æ•°ï¼ˆé™¤å¤–å¯¾è±¡ï¼‰

âš ï¸ æ³¨æ„: æ©Ÿæ¢°å­¦ç¿’ã§ã¯çµ±åˆ¶å¤‰æ•°ã‚’ç‰¹å¾´é‡ã€ç›®çš„å¤‰æ•°ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™
        """
        info_label = ctk.CTkLabel(info_frame, text=info_text, justify="left")
        info_label.pack(padx=10, pady=10)
        
        # 3åˆ—ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
        columns_frame = ctk.CTkFrame(main_frame)
        columns_frame.pack(fill="both", expand=True, pady=(0, 20))
        
        # åˆ©ç”¨å¯èƒ½ãªå¤‰æ•°ãƒªã‚¹ãƒˆ
        available_frame = ctk.CTkFrame(columns_frame)
        available_frame.pack(side="left", fill="both", expand=True, padx=(0, 5))
        
        ctk.CTkLabel(available_frame, text="ğŸ“‹ Available Variables", font=("Arial", 14, "bold")).pack(pady=5)
        self.available_listbox = tk.Listbox(available_frame, selectmode=tk.MULTIPLE, height=15)
        self.available_listbox.pack(fill="both", expand=True, padx=5, pady=5)
        
        for col in self.columns:
            self.available_listbox.insert(tk.END, col)
        
        # çµ±åˆ¶å¤‰æ•°ãƒªã‚¹ãƒˆ
        control_frame = ctk.CTkFrame(columns_frame)
        control_frame.pack(side="left", fill="both", expand=True, padx=5)
        
        ctk.CTkLabel(control_frame, text="ğŸ›ï¸ Control Variables\n(çµ±åˆ¶å¤‰æ•°)", font=("Arial", 14, "bold")).pack(pady=5)
        self.control_listbox = tk.Listbox(control_frame, height=15)
        self.control_listbox.pack(fill="both", expand=True, padx=5, pady=5)
        
        # ç›®çš„å¤‰æ•°ãƒªã‚¹ãƒˆ
        target_frame = ctk.CTkFrame(columns_frame)
        target_frame.pack(side="left", fill="both", expand=True, padx=5)
        
        ctk.CTkLabel(target_frame, text="ğŸ¯ Target Variables\n(ç›®çš„å¤‰æ•°)", font=("Arial", 14, "bold")).pack(pady=5)
        self.target_listbox = tk.Listbox(target_frame, height=15)
        self.target_listbox.pack(fill="both", expand=True, padx=5, pady=5)
        
        # å‰°ä½™å¤‰æ•°ãƒªã‚¹ãƒˆ
        residual_frame = ctk.CTkFrame(columns_frame)
        residual_frame.pack(side="left", fill="both", expand=True, padx=(5, 0))
        
        ctk.CTkLabel(residual_frame, text="ğŸ“¦ Residual Variables\n(å‰°ä½™å¤‰æ•°)", font=("Arial", 14, "bold")).pack(pady=5)
        self.residual_listbox = tk.Listbox(residual_frame, height=15)
        self.residual_listbox.pack(fill="both", expand=True, padx=5, pady=5)
        
        # æ“ä½œãƒœã‚¿ãƒ³
        button_frame = ctk.CTkFrame(main_frame)
        button_frame.pack(fill="x", pady=(0, 20))
        
        # å¤‰æ•°ç§»å‹•ãƒœã‚¿ãƒ³
        move_frame = ctk.CTkFrame(button_frame)
        move_frame.pack(pady=10)
        
        ctk.CTkButton(move_frame, text="â†’ Control", command=self._move_to_control, width=100).pack(side="left", padx=2)
        ctk.CTkButton(move_frame, text="â†’ Target", command=self._move_to_target, width=100).pack(side="left", padx=2)
        ctk.CTkButton(move_frame, text="â†’ Residual", command=self._move_to_residual, width=100).pack(side="left", padx=2)
        ctk.CTkButton(move_frame, text="â† Remove", command=self._remove_from_lists, width=100).pack(side="left", padx=2)
        
        # ãƒªã‚»ãƒƒãƒˆãƒ»è‡ªå‹•åˆ†é¡ãƒœã‚¿ãƒ³
        auto_frame = ctk.CTkFrame(button_frame)
        auto_frame.pack(pady=5)
        
        ctk.CTkButton(auto_frame, text="ğŸ”„ Reset All", command=self._reset_all, width=120).pack(side="left", padx=5)
        ctk.CTkButton(auto_frame, text="ğŸ¤– Auto Classify", command=self._auto_classify, width=120).pack(side="left", padx=5)
        ctk.CTkButton(auto_frame, text="ğŸ“Š Show Summary", command=self._show_summary, width=120).pack(side="left", padx=5)
        
        # ç¢ºå®šãƒ»ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³
        action_frame = ctk.CTkFrame(main_frame)
        action_frame.pack(fill="x")
        
        ctk.CTkButton(action_frame, text="âœ… Apply Selection", command=self._apply_selection, 
                     fg_color="green", width=150, height=40).pack(side="left", padx=10)
        ctk.CTkButton(action_frame, text="âŒ Cancel", command=self._cancel, 
                     fg_color="red", width=100, height=40).pack(side="right", padx=10)
    
    def _move_to_control(self):
        """çµ±åˆ¶å¤‰æ•°ã«ç§»å‹•"""
        selected = self.available_listbox.curselection()
        for i in reversed(selected):
            var = self.available_listbox.get(i)
            self.control_listbox.insert(tk.END, var)
            self.available_listbox.delete(i)
    
    def _move_to_target(self):
        """ç›®çš„å¤‰æ•°ã«ç§»å‹•"""
        selected = self.available_listbox.curselection()
        for i in reversed(selected):
            var = self.available_listbox.get(i)
            self.target_listbox.insert(tk.END, var)
            self.available_listbox.delete(i)
    
    def _move_to_residual(self):
        """å‰°ä½™å¤‰æ•°ã«ç§»å‹•"""
        selected = self.available_listbox.curselection()
        for i in reversed(selected):
            var = self.available_listbox.get(i)
            self.residual_listbox.insert(tk.END, var)
            self.available_listbox.delete(i)
    
    def _remove_from_lists(self):
        """ãƒªã‚¹ãƒˆã‹ã‚‰å¤‰æ•°ã‚’å‰Šé™¤ã—ã¦åˆ©ç”¨å¯èƒ½ãƒªã‚¹ãƒˆã«æˆ»ã™"""
        # çµ±åˆ¶å¤‰æ•°ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
        selected = self.control_listbox.curselection()
        for i in reversed(selected):
            var = self.control_listbox.get(i)
            self.available_listbox.insert(tk.END, var)
            self.control_listbox.delete(i)
        
        # ç›®çš„å¤‰æ•°ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
        selected = self.target_listbox.curselection()
        for i in reversed(selected):
            var = self.target_listbox.get(i)
            self.available_listbox.insert(tk.END, var)
            self.target_listbox.delete(i)
        
        # å‰°ä½™å¤‰æ•°ãƒªã‚¹ãƒˆã‹ã‚‰å‰Šé™¤
        selected = self.residual_listbox.curselection()
        for i in reversed(selected):
            var = self.residual_listbox.get(i)
            self.available_listbox.insert(tk.END, var)
            self.residual_listbox.delete(i)
    
    def _reset_all(self):
        """å…¨ã¦ãƒªã‚»ãƒƒãƒˆ"""
        self.available_listbox.delete(0, tk.END)
        self.control_listbox.delete(0, tk.END)
        self.target_listbox.delete(0, tk.END)
        self.residual_listbox.delete(0, tk.END)
        
        for col in self.columns:
            self.available_listbox.insert(tk.END, col)
    
    def _auto_classify(self):
        """è‡ªå‹•åˆ†é¡ï¼ˆãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼‰"""
        self._reset_all()
        
        # æ•°å€¤å‹å¤‰æ•°ã‚’çµ±åˆ¶å¤‰æ•°ã€æ–‡å­—åˆ—ãƒ»ã‚«ãƒ†ã‚´ãƒªå‹ã‚’å‰°ä½™å¤‰æ•°ã«åˆ†é¡
        numeric_cols = self.data.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = self.data.select_dtypes(include=['object', 'category']).columns.tolist()
        
        # 'id', 'index' ãªã©ã¯å‰°ä½™å¤‰æ•°ã«
        id_patterns = ['id', 'index', 'idx', 'key', 'ç•ªå·', 'no', 'num']
        
        self.available_listbox.delete(0, tk.END)
        
        for col in self.columns:
            col_lower = col.lower()
            if any(pattern in col_lower for pattern in id_patterns):
                self.residual_listbox.insert(tk.END, col)
            elif col in numeric_cols and col not in categorical_cols:
                if 'target' in col_lower or 'outcome' in col_lower or 'result' in col_lower:
                    self.target_listbox.insert(tk.END, col)
                else:
                    self.control_listbox.insert(tk.END, col)
            else:
                self.residual_listbox.insert(tk.END, col)
    
    def _show_summary(self):
        """å¤‰æ•°åˆ†é¡ã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        control_vars = [self.control_listbox.get(i) for i in range(self.control_listbox.size())]
        target_vars = [self.target_listbox.get(i) for i in range(self.target_listbox.size())]
        residual_vars = [self.residual_listbox.get(i) for i in range(self.residual_listbox.size())]
        
        summary = f"""
ğŸ“Š Variable Classification Summary
================================

ğŸ›ï¸ Control Variables ({len(control_vars)}):
{', '.join(control_vars) if control_vars else 'None'}

ğŸ¯ Target Variables ({len(target_vars)}):
{', '.join(target_vars) if target_vars else 'None'}

ğŸ“¦ Residual Variables ({len(residual_vars)}):
{', '.join(residual_vars) if residual_vars else 'None'}

ğŸ“ˆ Data Types:
{self.data.dtypes.to_string()}
        """
        
        messagebox.showinfo("Variable Summary", summary)
    
    def _apply_selection(self):
        """é¸æŠã‚’é©ç”¨"""
        self.control_variables = [self.control_listbox.get(i) for i in range(self.control_listbox.size())]
        self.target_variables = [self.target_listbox.get(i) for i in range(self.target_listbox.size())]
        self.residual_variables = [self.residual_listbox.get(i) for i in range(self.residual_listbox.size())]
        
        # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        if not self.control_variables and not self.target_variables:
            messagebox.showerror("Error", "Please select at least one control or target variable!")
            return
        
        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
        if self.callback:
            result = {
                'control_variables': self.control_variables,
                'target_variables': self.target_variables,
                'residual_variables': self.residual_variables,
                'data_subset': self._create_data_subset()
            }
            self.callback(result)
        
        self.window.destroy()
    
    def _create_data_subset(self):
        """é¸æŠã•ã‚ŒãŸå¤‰æ•°ã§ãƒ‡ãƒ¼ã‚¿ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
        selected_vars = self.control_variables + self.target_variables
        if selected_vars:
            return self.data[selected_vars].copy()
        return self.data.copy()
    
    def _cancel(self):
        """ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        self.window.destroy()

class AIAnalysisWindow:
    """AIçµ±è¨ˆåˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦"""
    
    def __init__(self, parent, data):
        self.parent = parent
        self.data = data
        self.window = None
        
    def show(self):
        """AIåˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¡¨ç¤º"""
        if not AI_INTEGRATION_AVAILABLE:
            messagebox.showerror("Error", "AIçµ±åˆæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
            return
            
        self.window = ctk.CTkToplevel(self.parent)
        self.window.title("ğŸ¤– AI Statistical Analysis - AIçµ±è¨ˆåˆ†æ")
        self.window.geometry("1000x800")
        self.window.grab_set()
        
        # ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ 
        main_frame = ctk.CTkFrame(self.window)
        main_frame.pack(fill="both", expand=True, padx=20, pady=20)
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        title_label = ctk.CTkLabel(main_frame, text="ğŸ¤– AI Statistical Analysis", font=("Arial", 18, "bold"))
        title_label.pack(pady=(0, 20))
        
        # ã‚¿ãƒ–ãƒ“ãƒ¥ãƒ¼
        tabview = ctk.CTkTabview(main_frame)
        tabview.pack(fill="both", expand=True)
        
        # è‡ªç„¶è¨€èªåˆ†æã‚¿ãƒ–
        nlp_tab = tabview.add("Natural Language")
        self._create_nlp_tab(nlp_tab)
        
        # ç”»åƒåˆ†æã‚¿ãƒ–
        image_tab = tabview.add("Image Analysis")
        self._create_image_tab(image_tab)
        
        # å±¥æ­´ã‚¿ãƒ–
        history_tab = tabview.add("Analysis History")
        self._create_history_tab(history_tab)
    
    def _create_nlp_tab(self, parent):
        """è‡ªç„¶è¨€èªåˆ†æã‚¿ãƒ–ä½œæˆ"""
        # èª¬æ˜æ–‡
        info_label = ctk.CTkLabel(parent, text="ğŸ—£ï¸ è‡ªç„¶è¨€èªã§çµ±è¨ˆåˆ†æã‚’æŒ‡ç¤ºã—ã¦ãã ã•ã„", font=("Arial", 14, "bold"))
        info_label.pack(pady=10)
        
        # å…¥åŠ›ãƒ•ãƒ¬ãƒ¼ãƒ 
        input_frame = ctk.CTkFrame(parent)
        input_frame.pack(fill="x", padx=10, pady=10)
        
        # ã‚¯ã‚¨ãƒªå…¥åŠ›
        ctk.CTkLabel(input_frame, text="åˆ†æè¦æ±‚:").pack(anchor="w", padx=10, pady=(10, 5))
        self.query_text = ctk.CTkTextbox(input_frame, height=100)
        self.query_text.pack(fill="x", padx=10, pady=(0, 10))
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªãƒœã‚¿ãƒ³
        sample_frame = ctk.CTkFrame(input_frame)
        sample_frame.pack(fill="x", padx=10, pady=(0, 10))
        
        samples = [
            "ãƒ‡ãƒ¼ã‚¿ã®ç›¸é–¢åˆ†æã‚’è¡Œã£ã¦",
            "ç·šå½¢å›å¸°åˆ†æã‚’ã—ã¦çµæœã‚’å¯è¦–åŒ–",
            "è¨˜è¿°çµ±è¨ˆã‚’è¡¨ç¤ºã—ã¦",
            "ç•°å¸¸å€¤ã®æ¤œå‡ºã¨é™¤å»",
            "ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æã‚’å®Ÿè¡Œ"
        ]
        
        for i, sample in enumerate(samples):
            btn = ctk.CTkButton(sample_frame, text=sample, width=180, height=30,
                               command=lambda s=sample: self.query_text.insert("1.0", s))
            btn.grid(row=i//3, column=i%3, padx=5, pady=5)
        
        # å®Ÿè¡Œãƒœã‚¿ãƒ³
        ctk.CTkButton(input_frame, text="ğŸš€ AI Analysis", command=self._run_nlp_analysis,
                     fg_color="green", width=200, height=40).pack(pady=10)
        
        # çµæœè¡¨ç¤º
        ctk.CTkLabel(parent, text="AI Response:", font=("Arial", 12, "bold")).pack(anchor="w", padx=10, pady=(20, 5))
        self.nlp_result_text = ctk.CTkTextbox(parent, height=300)
        self.nlp_result_text.pack(fill="both", expand=True, padx=10, pady=(0, 10))
        
        # ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œãƒœã‚¿ãƒ³
        ctk.CTkButton(parent, text="ğŸ”§ Execute Generated Code", command=self._execute_nlp_code,
                     fg_color="blue", width=200, height=35).pack(pady=10)
    
    def _create_image_tab(self, parent):
        """ç”»åƒåˆ†æã‚¿ãƒ–ä½œæˆ"""
        # èª¬æ˜æ–‡
        info_label = ctk.CTkLabel(parent, text="ğŸ“· ç”»åƒã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºãƒ»åˆ†æ", font=("Arial", 14, "bold"))
        info_label.pack(pady=10)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠãƒ•ãƒ¬ãƒ¼ãƒ 
        file_frame = ctk.CTkFrame(parent)
        file_frame.pack(fill="x", padx=10, pady=10)
        
        self.image_path_var = tk.StringVar()
        ctk.CTkLabel(file_frame, text="ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«:").pack(anchor="w", padx=10, pady=(10, 5))
        
        path_frame = ctk.CTkFrame(file_frame)
        path_frame.pack(fill="x", padx=10, pady=(0, 10))
        
        self.image_path_entry = ctk.CTkEntry(path_frame, textvariable=self.image_path_var, width=400)
        self.image_path_entry.pack(side="left", fill="x", expand=True, padx=(0, 10))
        
        ctk.CTkButton(path_frame, text="ğŸ“ Browse", command=self._browse_image, width=100).pack(side="right")
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
        ctk.CTkLabel(file_frame, text="è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³):").pack(anchor="w", padx=10, pady=(10, 5))
        self.context_entry = ctk.CTkEntry(file_frame, placeholder_text="ä¾‹: ã“ã®è¡¨ã¯å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã§ã™")
        self.context_entry.pack(fill="x", padx=10, pady=(0, 10))
        
        # å®Ÿè¡Œãƒœã‚¿ãƒ³
        ctk.CTkButton(file_frame, text="ğŸ” Analyze Image", command=self._run_image_analysis,
                     fg_color="orange", width=200, height=40).pack(pady=10)
        
        # çµæœè¡¨ç¤º
        ctk.CTkLabel(parent, text="Image Analysis Result:", font=("Arial", 12, "bold")).pack(anchor="w", padx=10, pady=(20, 5))
        self.image_result_text = ctk.CTkTextbox(parent, height=300)
        self.image_result_text.pack(fill="both", expand=True, padx=10, pady=(0, 10))
        
        # ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œãƒœã‚¿ãƒ³
        ctk.CTkButton(parent, text="ğŸ”§ Execute Generated Code", command=self._execute_image_code,
                     fg_color="blue", width=200, height=35).pack(pady=10)
    
    def _create_history_tab(self, parent):
        """å±¥æ­´ã‚¿ãƒ–ä½œæˆ"""
        ctk.CTkLabel(parent, text="ğŸ“š Analysis History", font=("Arial", 14, "bold")).pack(pady=10)
        
        # å±¥æ­´ãƒªã‚¹ãƒˆ
        self.history_listbox = tk.Listbox(parent, height=20)
        self.history_listbox.pack(fill="both", expand=True, padx=10, pady=10)
        
        # å±¥æ­´æ“ä½œãƒœã‚¿ãƒ³
        history_btn_frame = ctk.CTkFrame(parent)
        history_btn_frame.pack(fill="x", padx=10, pady=10)
        
        ctk.CTkButton(history_btn_frame, text="ğŸ”„ Refresh", command=self._refresh_history, width=100).pack(side="left", padx=5)
        ctk.CTkButton(history_btn_frame, text="ğŸ“¤ Export", command=self._export_history, width=100).pack(side="left", padx=5)
        ctk.CTkButton(history_btn_frame, text="ğŸ—‘ï¸ Clear", command=self._clear_history, width=100).pack(side="left", padx=5)
    
    def _browse_image(self):
        """ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ"""
        file_path = filedialog.askopenfilename(
            title="Select Image File",
            filetypes=[
                ("Image files", "*.png *.jpg *.jpeg *.gif *.bmp *.tiff *.webp"),
                ("All files", "*.*")
            ]
        )
        if file_path:
            self.image_path_var.set(file_path)
    
    def _run_nlp_analysis(self):
        """è‡ªç„¶è¨€èªåˆ†æå®Ÿè¡Œ"""
        query = self.query_text.get("1.0", "end-1c").strip()
        if not query:
            messagebox.showwarning("Warning", "åˆ†æè¦æ±‚ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return
        
        self.nlp_result_text.delete("1.0", "end")
        self.nlp_result_text.insert("1.0", "ğŸ¤– AIåˆ†æä¸­... ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
        
        # éåŒæœŸå®Ÿè¡Œ
        import threading
        thread = threading.Thread(target=self._nlp_analysis_thread, args=(query,))
        thread.daemon = True
        thread.start()
    
    def _nlp_analysis_thread(self, query):
        """è‡ªç„¶è¨€èªåˆ†æã‚¹ãƒ¬ãƒƒãƒ‰"""
        try:
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            result = loop.run_until_complete(ai_analyzer.analyze_natural_language_query(query, self.data))
            
            # UIæ›´æ–°ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œï¼‰
            self.window.after(0, lambda: self._update_nlp_result(result))
            
        except Exception as e:
            error_msg = f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}"
            self.window.after(0, lambda: self.nlp_result_text.delete("1.0", "end"))
            self.window.after(0, lambda: self.nlp_result_text.insert("1.0", error_msg))
    
    def _update_nlp_result(self, result):
        """è‡ªç„¶è¨€èªåˆ†æçµæœæ›´æ–°"""
        self.nlp_result_text.delete("1.0", "end")
        
        if result["success"]:
            display_text = f"""ğŸ¤– AI Provider: {result.get('provider', 'Unknown')} ({result.get('model', 'Unknown')})

ğŸ“ AI Response:
{result['ai_response']}

ğŸ Generated Python Code:
{result['python_code']}
"""
            self.nlp_result_text.insert("1.0", display_text)
            self.last_nlp_code = result['python_code']
        else:
            self.nlp_result_text.insert("1.0", f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
    
    def _run_image_analysis(self):
        """ç”»åƒåˆ†æå®Ÿè¡Œ"""
        image_path = self.image_path_var.get().strip()
        if not image_path:
            messagebox.showwarning("Warning", "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
            return
        
        if not Path(image_path).exists():
            messagebox.showerror("Error", "æŒ‡å®šã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        context = self.context_entry.get().strip()
        
        self.image_result_text.delete("1.0", "end")
        self.image_result_text.insert("1.0", "ğŸ” ç”»åƒåˆ†æä¸­... ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„...")
        
        # éåŒæœŸå®Ÿè¡Œ
        import threading
        thread = threading.Thread(target=self._image_analysis_thread, args=(image_path, context))
        thread.daemon = True
        thread.start()
    
    def _image_analysis_thread(self, image_path, context):
        """ç”»åƒåˆ†æã‚¹ãƒ¬ãƒƒãƒ‰"""
        try:
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            result = loop.run_until_complete(ai_analyzer.analyze_image_data(image_path, context))
            
            # UIæ›´æ–°ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œï¼‰
            self.window.after(0, lambda: self._update_image_result(result))
            
        except Exception as e:
            error_msg = f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}"
            self.window.after(0, lambda: self.image_result_text.delete("1.0", "end"))
            self.window.after(0, lambda: self.image_result_text.insert("1.0", error_msg))
    
    def _update_image_result(self, result):
        """ç”»åƒåˆ†æçµæœæ›´æ–°"""
        self.image_result_text.delete("1.0", "end")
        
        if result["success"]:
            display_text = f"""ğŸ¤– AI Provider: {result.get('provider', 'Unknown')} ({result.get('model', 'Unknown')})

ğŸ“ AI Response:
{result['ai_response']}

ğŸ”¤ OCR Text:
{result.get('ocr_text', 'ãªã—')}

ğŸ Generated Python Code:
{result['python_code']}
"""
            self.image_result_text.insert("1.0", display_text)
            self.last_image_code = result['python_code']
        else:
            self.image_result_text.insert("1.0", f"âŒ ã‚¨ãƒ©ãƒ¼: {result['error']}")
    
    def _execute_nlp_code(self):
        """è‡ªç„¶è¨€èªåˆ†æã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ"""
        if hasattr(self, 'last_nlp_code') and self.last_nlp_code:
            self._execute_code(self.last_nlp_code)
        else:
            messagebox.showwarning("Warning", "å®Ÿè¡Œã™ã‚‹ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
    
    def _execute_image_code(self):
        """ç”»åƒåˆ†æã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ"""
        if hasattr(self, 'last_image_code') and self.last_image_code:
            self._execute_code(self.last_image_code)
        else:
            messagebox.showwarning("Warning", "å®Ÿè¡Œã™ã‚‹ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“")
    
    def _execute_code(self, code):
        """ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ"""
        try:
            result = ai_analyzer.execute_generated_code(code, self.data)
            
            if result["success"]:
                messagebox.showinfo("Success", "ã‚³ãƒ¼ãƒ‰ãŒæ­£å¸¸ã«å®Ÿè¡Œã•ã‚Œã¾ã—ãŸï¼")
            else:
                messagebox.showerror("Execution Error", f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼:\n{result['error']}")
        except Exception as e:
            messagebox.showerror("Error", f"å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:\n{str(e)}")
    
    def _refresh_history(self):
        """å±¥æ­´æ›´æ–°"""
        self.history_listbox.delete(0, tk.END)
        for i, record in enumerate(ai_analyzer.analysis_history):
            timestamp = record.get('timestamp', 'Unknown')
            query = record.get('query', 'No query')[:50]
            self.history_listbox.insert(tk.END, f"{i+1}. [{timestamp}] {query}...")
    
    def _export_history(self):
        """å±¥æ­´ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        if not ai_analyzer.analysis_history:
            messagebox.showinfo("Info", "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        file_path = filedialog.asksaveasfilename(
            title="Export Analysis History",
            defaultextension=".json",
            filetypes=[("JSON files", "*.json"), ("All files", "*.*")]
        )
        
        if file_path:
            try:
                import json
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(ai_analyzer.analysis_history, f, ensure_ascii=False, indent=2, default=str)
                messagebox.showinfo("Success", f"å±¥æ­´ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ:\n{file_path}")
            except Exception as e:
                messagebox.showerror("Error", f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼:\n{str(e)}")
    
    def _clear_history(self):
        """å±¥æ­´ã‚¯ãƒªã‚¢"""
        if messagebox.askyesno("Confirm", "ã™ã¹ã¦ã®å±¥æ­´ã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ"):
            ai_analyzer.analysis_history.clear()
            self.history_listbox.delete(0, tk.END)
            messagebox.showinfo("Success", "å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")

class StatisticalAnalysisGUI:
    """ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«çµ±è¨ˆè§£æGUI"""
    
    def __init__(self):
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†åˆæœŸåŒ–
        self.session_manager = SessionManager(self)
        
        # ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½åˆæœŸåŒ–
        self.professional_features = PROFESSIONAL_FEATURES_AVAILABLE
        self.advanced_features = ADVANCED_FEATURES_AVAILABLE
        
        # ã‚¹ã‚¿ãƒ–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        self.advanced_analyzer = None
        self.parallel_processor = None
        self.memory_manager = None
        self.survival_analyzer = None
        self.bayesian_analyzer = None
        self.ml_automator = None
        
        if PROFESSIONAL_FEATURES_AVAILABLE:
            try:
                from professional_utils import professional_logger, performance_monitor
                from professional_reports import report_generator
                print("âœ… ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
                self.professional_features = True
            except ImportError as e:
                print(f"âš ï¸ ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                self.professional_features = False
        
        # ãƒ‡ãƒ¼ã‚¿ç®¡ç†
        self.current_data = None
        self.analysis_results = {}
        self.user_settings = {}
        
        # å¤‰æ•°é¸æŠçŠ¶æ…‹
        self.control_variables = []  # çµ±åˆ¶å¤‰æ•°
        self.target_variables = []   # ç›®çš„å¤‰æ•°
        self.residual_variables = [] # å‰°ä½™å¤‰æ•°
        self.variable_selection_applied = False
        
        # é«˜åº¦æ©Ÿèƒ½ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        self.visualizer = AdvancedVisualizer()
        self.preprocessor = DataPreprocessor()
        
        # GUIåˆæœŸåŒ–
        self._initialize_gui()
        
        # å¾©æ—§ãƒã‚§ãƒƒã‚¯
        self._check_recovery()
    
    def _initialize_gui(self):
        """GUIåˆæœŸåŒ–"""
        self.root = ctk.CTk()
        self.root.title("ğŸ”¬ Professional Statistical Analysis Software")
        self.root.geometry("1400x900")
        
        # ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼
        self._create_menu()
        
        # ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ 
        self._create_main_frame()
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼
        self._create_status_bar()
        
        # åˆæœŸçŠ¶æ…‹è¡¨ç¤º
        self._update_status(f"Ready | Session: {self.session_manager.session_id[:8]}...")
    
    def _create_menu(self):
        """ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ä½œæˆ"""
        menubar = tk.Menu(self.root)
        self.root.config(menu=menubar)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¡ãƒ‹ãƒ¥ãƒ¼
        file_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="File", menu=file_menu)
        file_menu.add_command(label="Open Data...", command=self.load_data)
        file_menu.add_command(label="Save Session", command=self.save_session)
        file_menu.add_separator()
        file_menu.add_command(label="Exit", command=self.root.quit)
        
        # è§£æãƒ¡ãƒ‹ãƒ¥ãƒ¼
        analysis_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Analysis", menu=analysis_menu)
        analysis_menu.add_command(label="Variable Selection", command=self.variable_selection)
        analysis_menu.add_separator()
        analysis_menu.add_command(label="ğŸ¤– AI Analysis", command=self.ai_analysis)
        analysis_menu.add_separator()
        analysis_menu.add_command(label="Descriptive Statistics", command=self.descriptive_stats)
        analysis_menu.add_command(label="Hypothesis Testing", command=self.hypothesis_testing)
        analysis_menu.add_command(label="Regression Analysis", command=self.regression_analysis)
        analysis_menu.add_command(label="Machine Learning", command=self.machine_learning)
        analysis_menu.add_command(label="Deep Learning", command=self.deep_learning)
        
        # é«˜åº¦è§£æãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼ˆãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        if hasattr(self, 'advanced_features') and self.advanced_features:
            analysis_menu.add_separator()
            advanced_menu = tk.Menu(analysis_menu, tearoff=0)
            analysis_menu.add_cascade(label="ğŸ§  Advanced Analysis", menu=advanced_menu)
            advanced_menu.add_command(label="ğŸ”¬ Multivariate Analysis", command=self.multivariate_analysis)
            advanced_menu.add_command(label="ğŸ“ˆ Time Series Analysis", command=self.time_series_analysis)
            advanced_menu.add_command(label="â±ï¸ Survival Analysis", command=self.survival_analysis)
            advanced_menu.add_command(label="ğŸ² Bayesian Analysis", command=self.bayesian_analysis)
            advanced_menu.add_command(label="ğŸ“Š Comprehensive EDA", command=self.comprehensive_eda)
        
        # å¯è¦–åŒ–ãƒ¡ãƒ‹ãƒ¥ãƒ¼
        viz_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Visualization", menu=viz_menu)
        viz_menu.add_command(label="ğŸ“Š Correlation Heatmap", command=self.create_correlation_heatmap)
        viz_menu.add_command(label="ğŸ” Scatter Matrix", command=self.create_scatter_matrix)
        viz_menu.add_command(label="ğŸ“ˆ Distribution Plots", command=self.create_distribution_plots)
        viz_menu.add_command(label="ğŸ“¦ Box Plots", command=self.create_box_plots)
        viz_menu.add_command(label="â° Time Series Plot", command=self.create_time_series_plot)
        viz_menu.add_separator()
        viz_menu.add_command(label="ğŸ¯ Feature Importance", command=self.create_feature_importance_plot)
        viz_menu.add_command(label="ğŸ“Š ROC Curve", command=self.create_roc_curve)
        
        # ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¡ãƒ‹ãƒ¥ãƒ¼
        data_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Data Processing", menu=data_menu)
        data_menu.add_command(label="ğŸ” Detect Outliers", command=self.detect_outliers)
        data_menu.add_command(label="ğŸ—‘ï¸ Remove Outliers", command=self.remove_outliers)
        data_menu.add_separator()
        data_menu.add_command(label="ğŸ’Š Handle Missing Values", command=self.handle_missing_values)
        data_menu.add_command(label="âš™ï¸ Transform Data", command=self.transform_data)
        data_menu.add_command(label="ğŸ”§ Feature Engineering", command=self.feature_engineering)
        data_menu.add_command(label="ğŸ¯ Feature Selection", command=self.feature_selection)
        
        # ãƒ„ãƒ¼ãƒ«ãƒ¡ãƒ‹ãƒ¥ãƒ¼
        tools_menu = tk.Menu(menubar, tearoff=0)
        menubar.add_cascade(label="Tools", menu=tools_menu)
        tools_menu.add_command(label="Data Quality Check", command=self.data_quality_check)
        tools_menu.add_separator()
        if PROFESSIONAL_FEATURES_AVAILABLE:
            tools_menu.add_command(label="ğŸ“‹ Generate Report", command=self.generate_professional_report)
            tools_menu.add_command(label="ğŸ“Š Performance Report", command=self.show_performance_report)
            tools_menu.add_separator()
        tools_menu.add_command(label="GPU Status", command=self.show_gpu_status)
        tools_menu.add_command(label="Memory Usage", command=self.show_memory_usage)
    
    def _create_main_frame(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ"""
        # ã‚µã‚¤ãƒ‰ãƒ‘ãƒãƒ«
        self.sidebar = ctk.CTkFrame(self.root, width=300)
        self.sidebar.pack(side="left", fill="y", padx=10, pady=10)
        
        # ãƒ‡ãƒ¼ã‚¿æƒ…å ±ãƒ‘ãƒãƒ«
        self.data_info_frame = ctk.CTkFrame(self.sidebar)
        self.data_info_frame.pack(fill="x", padx=5, pady=5)
        
        self.data_info_label = ctk.CTkLabel(self.data_info_frame, text="ğŸ“Š Data Information")
        self.data_info_label.pack(pady=5)
        
        self.data_text = ctk.CTkTextbox(self.data_info_frame, height=150)
        self.data_text.pack(fill="x", padx=5, pady=5)
        
        # æ“ä½œãƒ‘ãƒãƒ«
        self.control_frame = ctk.CTkFrame(self.sidebar)
        self.control_frame.pack(fill="x", padx=5, pady=5)
        
        # ãƒœã‚¿ãƒ³é…ç½®
        self.load_btn = ctk.CTkButton(self.control_frame, text="ğŸ“ Load Data", command=self.load_data)
        self.load_btn.pack(fill="x", padx=5, pady=2)
        
        self.var_select_btn = ctk.CTkButton(self.control_frame, text="ğŸ¯ Variable Selection", command=self.variable_selection)
        self.var_select_btn.pack(fill="x", padx=5, pady=2)
        
        self.ai_btn = ctk.CTkButton(self.control_frame, text="ğŸ¤– AI Analysis", command=self.ai_analysis, fg_color="purple")
        self.ai_btn.pack(fill="x", padx=5, pady=2)
        
        self.desc_btn = ctk.CTkButton(self.control_frame, text="ğŸ“ˆ Descriptive Stats", command=self.descriptive_stats)
        self.desc_btn.pack(fill="x", padx=5, pady=2)
        
        self.test_btn = ctk.CTkButton(self.control_frame, text="ğŸ”¬ Hypothesis Test", command=self.hypothesis_testing)
        self.test_btn.pack(fill="x", padx=5, pady=2)
        
        self.reg_btn = ctk.CTkButton(self.control_frame, text="ğŸ“Š Regression", command=self.regression_analysis)
        self.reg_btn.pack(fill="x", padx=5, pady=2)
        
        self.ml_btn = ctk.CTkButton(self.control_frame, text="ğŸ¤– Machine Learning", command=self.machine_learning)
        self.ml_btn.pack(fill="x", padx=5, pady=2)
        
        self.dl_btn = ctk.CTkButton(self.control_frame, text="ğŸ§  Deep Learning", command=self.deep_learning)
        self.dl_btn.pack(fill="x", padx=5, pady=2)
        
        # æ–°æ©Ÿèƒ½ãƒœã‚¿ãƒ³
        self.viz_btn = ctk.CTkButton(self.control_frame, text="ğŸ“Š Visualization", command=self.visualization_menu, fg_color="orange")
        self.viz_btn.pack(fill="x", padx=5, pady=2)
        
        self.preprocess_btn = ctk.CTkButton(self.control_frame, text="âš™ï¸ Data Processing", command=self.preprocessing_menu, fg_color="teal")
        self.preprocess_btn.pack(fill="x", padx=5, pady=2)
        
        # ãƒ¡ã‚¤ãƒ³ä½œæ¥­ã‚¨ãƒªã‚¢
        self.main_frame = ctk.CTkFrame(self.root)
        self.main_frame.pack(side="right", fill="both", expand=True, padx=10, pady=10)
        
        # çµæœè¡¨ç¤ºã‚¨ãƒªã‚¢
        self.result_text = ctk.CTkTextbox(self.main_frame, font=("Consolas", 12))
        self.result_text.pack(fill="both", expand=True, padx=5, pady=5)
        
        # åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        welcome_msg = f"""
ğŸ”¬ Professional Statistical Analysis Software
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ›¡ï¸ Session ID: {self.session_manager.session_id}
âš¡ GPU Status: {'âœ… Available' if CUDA_AVAILABLE else 'âŒ Not Available'}
ğŸ¯ GPU Device: {GPU_NAME}
ğŸ’¾ Auto-save: Every 5 minutes
ğŸ”„ Backup: Automatic rotation (10 files)

ğŸ“‹ Quick Start:
1. Load your dataset using 'Load Data' button
2. Explore with 'Descriptive Stats'
3. Run hypothesis tests or regression analysis
4. Apply machine learning algorithms
5. Export results and visualizations

Ready for professional statistical analysis! ğŸš€
        """
        self.result_text.insert("1.0", welcome_msg)
    
    def _create_status_bar(self):
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼ä½œæˆ"""
        self.status_bar = ctk.CTkFrame(self.root, height=30)
        self.status_bar.pack(side="bottom", fill="x", padx=10, pady=5)
        
        self.status_label = ctk.CTkLabel(self.status_bar, text="Ready")
        self.status_label.pack(side="left", padx=10)
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¡¨ç¤º
        self.memory_label = ctk.CTkLabel(self.status_bar, text="Memory: 0 MB")
        self.memory_label.pack(side="right", padx=10)
        
        # ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚¿ã‚¤ãƒãƒ¼
        self._update_memory_usage()
    
    def _update_memory_usage(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ›´æ–°"""
        try:
            memory_mb = psutil.Process().memory_info().rss / 1024 / 1024
            self.memory_label.configure(text=f"Memory: {memory_mb:.1f} MB")
        except:
            pass
        
        # 30ç§’å¾Œã«å†å®Ÿè¡Œ
        self.root.after(30000, self._update_memory_usage)
    
    def _update_status(self, message):
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°"""
        self.status_label.configure(text=message)
    
    def _check_recovery(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©æ—§ãƒã‚§ãƒƒã‚¯"""
        latest_session = self.session_manager.load_latest_session()
        if latest_session:
            result = messagebox.askyesno(
                "Session Recovery", 
                "Previous session found. Do you want to restore it?"
            )
            if result:
                self._restore_session(latest_session)
    
    def _restore_session(self, session_data):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©æ—§"""
        try:
            if session_data.get('data') is not None:
                self.current_data = pd.DataFrame(session_data['data'])
                self._update_data_info()
            
            self.analysis_results = session_data.get('analysis_results', {})
            self.user_settings = session_data.get('settings', {})
            
            self._update_status("Session restored successfully")
            self.result_text.insert("end", "\n\nâœ… Session restored from previous backup\n")
            
        except Exception as e:
            messagebox.showerror("Recovery Error", f"Failed to restore session: {e}")
    
    def load_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        file_path = filedialog.askopenfilename(
            title="Select Data File",
            filetypes=[
                ("CSV files", "*.csv"),
                ("Excel files", "*.xlsx;*.xls"),
                ("JSON files", "*.json"),
                ("All files", "*.*")
            ]
        )
        
        if not file_path:
            return
        
        try:
            self._update_status("Loading data...")
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼è¡¨ç¤º
            progress_window = tk.Toplevel(self.root)
            progress_window.title("Loading Data")
            progress_window.geometry("400x100")
            
            progress_bar = ttk.Progressbar(progress_window, mode='indeterminate')
            progress_bar.pack(pady=20)
            progress_bar.start()
            
            # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã«ã‚ˆã‚‹èª­ã¿è¾¼ã¿
            file_ext = Path(file_path).suffix.lower()
            
            if file_ext == '.csv':
                self.current_data = pd.read_csv(file_path)
            elif file_ext in ['.xlsx', '.xls']:
                self.current_data = pd.read_excel(file_path)
            elif file_ext == '.json':
                self.current_data = pd.read_json(file_path)
            else:
                raise ValueError(f"Unsupported file format: {file_ext}")
            
            progress_window.destroy()
            
            self._update_data_info()
            self._update_status(f"Data loaded: {len(self.current_data)} rows")
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜
            self.session_manager.save_session()
            
        except Exception as e:
            if 'progress_window' in locals():
                progress_window.destroy()
            messagebox.showerror("Error", f"Failed to load data: {e}")
            self._update_status("Data loading failed")
    
    def _update_data_info(self):
        """ãƒ‡ãƒ¼ã‚¿æƒ…å ±æ›´æ–°"""
        if self.current_data is None:
            self.data_text.delete("1.0", "end")
            return
        
        info_text = f"""Shape: {self.current_data.shape[0]} rows Ã— {self.current_data.shape[1]} columns

Columns:
{chr(10).join(f"â€¢ {col} ({self.current_data[col].dtype})" for col in self.current_data.columns[:10])}
{"..." if len(self.current_data.columns) > 10 else ""}

Missing Values: {self.current_data.isnull().sum().sum()}
Memory Usage: {self.current_data.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB"""
        
        # å¤‰æ•°é¸æŠçŠ¶æ…‹ã‚’è¿½åŠ 
        if self.variable_selection_applied:
            info_text += f"""

ğŸ¯ Variable Selection:
Control: {len(self.control_variables)} vars
Target: {len(self.target_variables)} vars  
Residual: {len(self.residual_variables)} vars"""
        
        self.data_text.delete("1.0", "end")
        self.data_text.insert("1.0", info_text)
    
    def descriptive_stats(self):
        """è¨˜è¿°çµ±è¨ˆ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            self._update_status("Computing descriptive statistics...")
            
            numeric_cols = self.current_data.select_dtypes(include=[np.number]).columns
            
            if len(numeric_cols) == 0:
                messagebox.showwarning("Warning", "No numeric columns found")
                return
            
            # åŸºæœ¬çµ±è¨ˆé‡
            desc_stats = self.current_data[numeric_cols].describe()
            
            # æ­ªåº¦ãƒ»å°–åº¦
            skewness = self.current_data[numeric_cols].skew()
            kurtosis = self.current_data[numeric_cols].kurtosis()
            
            # çµæœè¡¨ç¤º
            result = f"""
ğŸ“Š DESCRIPTIVE STATISTICS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Basic Statistics:
{desc_stats.round(4)}

Distribution Shape:
Skewness:
{skewness.round(4)}

Kurtosis:
{kurtosis.round(4)}

ğŸ” Data Quality Summary:
â€¢ Total observations: {len(self.current_data)}
â€¢ Numeric variables: {len(numeric_cols)}
â€¢ Complete cases: {self.current_data.dropna().shape[0]}
â€¢ Missing rate: {(self.current_data.isnull().sum().sum() / (len(self.current_data) * len(self.current_data.columns)) * 100):.1f}%
            """
            
            self.result_text.delete("1.0", "end")
            self.result_text.insert("1.0", result)
            
            # çµæœä¿å­˜
            self.analysis_results['descriptive_stats'] = {
                'basic_stats': desc_stats.to_dict(),
                'skewness': skewness.to_dict(),
                'kurtosis': kurtosis.to_dict()
            }
            
            self._update_status("Descriptive statistics completed")
            
        except Exception as e:
            messagebox.showerror("Error", f"Analysis failed: {e}")
            self._update_status("Analysis failed")
    
    def hypothesis_testing(self):
        """ä»®èª¬æ¤œå®š"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        # ä»®èª¬æ¤œå®šé¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
        test_window = ctk.CTkToplevel(self.root)
        test_window.title("ğŸ”¬ ä»®èª¬æ¤œå®š - Hypothesis Testing")
        test_window.geometry("500x600")
        test_window.transient(self.root)
        test_window.grab_set()
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        title_label = ctk.CTkLabel(test_window, text="ğŸ”¬ ä»®èª¬æ¤œå®šé¸æŠ", font=("Arial", 18, "bold"))
        title_label.pack(pady=20)
        
        # æ¤œå®šé¸æŠãƒ•ãƒ¬ãƒ¼ãƒ 
        test_frame = ctk.CTkFrame(test_window)
        test_frame.pack(fill="x", padx=20, pady=10)
        
        ctk.CTkLabel(test_frame, text="æ¤œå®šæ‰‹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„:", font=("Arial", 14, "bold")).pack(pady=10)
        
        test_var = tk.StringVar(value="ttest_ind")
        
        # ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§æ¤œå®šé¸æŠ
        tests = [
            ("ttest_ind", "ğŸ”„ å¯¾å¿œãªã—tæ¤œå®š (Independent t-test)"),
            ("ttest_rel", "ğŸ”— å¯¾å¿œã‚ã‚Štæ¤œå®š (Paired t-test)"),
            ("ftest", "ğŸ“Š Fæ¤œå®š (F-test for equal variances)"),
            ("anova", "ğŸ¯ ä¸€å…ƒé…ç½®åˆ†æ•£åˆ†æ (One-way ANOVA)"),
            ("normality", "ğŸ“ˆ æ­£è¦æ€§æ¤œå®š (Normality tests)"),
            ("multiple_ttest", "ğŸ” å¤šé‡tæ¤œå®šï¼ˆè£œæ­£ä»˜ãï¼‰(Multiple t-tests with correction)"),
            ("sphericity_test", "ğŸŒ çƒé¢æ€§æ¤œå®š (Sphericity test)")
        ]
        
        for value, text in tests:
            ctk.CTkRadioButton(test_frame, text=text, variable=test_var, value=value).pack(anchor="w", pady=5)
        
        # ãƒœã‚¿ãƒ³ãƒ•ãƒ¬ãƒ¼ãƒ 
        button_frame = ctk.CTkFrame(test_window)
        button_frame.pack(fill="x", padx=20, pady=20)
        
        def run_selected_test():
            test_type = test_var.get()
            test_window.destroy()
            
            if test_type == "ttest_ind":
                self._run_independent_ttest()
            elif test_type == "ttest_rel":
                self._run_paired_ttest()
            elif test_type == "ftest":
                self._run_ftest()
            elif test_type == "anova":
                self._run_anova()
            elif test_type == "normality":
                self._run_normality_tests()
            elif test_type == "multiple_ttest":
                self._run_multiple_ttest()
            elif test_type == "sphericity_test":
                self._run_sphericity_test()
        
        ctk.CTkButton(button_frame, text="âœ… å®Ÿè¡Œ", command=run_selected_test, 
                     fg_color="green", width=120, height=40).pack(side="left", padx=10)
        ctk.CTkButton(button_frame, text="âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", command=test_window.destroy, 
                     fg_color="red", width=120, height=40).pack(side="right", padx=10)
    
    def _calculate_cohens_d(self, group1, group2):
        """Cohen's dåŠ¹æœé‡è¨ˆç®—"""
        n1, n2 = len(group1), len(group2)
        
        # ãƒ—ãƒ¼ãƒ«ã•ã‚ŒãŸæ¨™æº–åå·®
        pooled_std = np.sqrt(((n1 - 1) * np.var(group1, ddof=1) + (n2 - 1) * np.var(group2, ddof=1)) / (n1 + n2 - 2))
        
        # Cohen's d
        d = (np.mean(group1) - np.mean(group2)) / pooled_std
        
        # åŠ¹æœé‡ã®è§£é‡ˆ
        if abs(d) < 0.2:
            interpretation = "å°ã•ã„åŠ¹æœé‡ (Small effect)"
        elif abs(d) < 0.5:
            interpretation = "ä¸­ç¨‹åº¦ã®åŠ¹æœé‡ (Medium effect)"
        elif abs(d) < 0.8:
            interpretation = "å¤§ãã„åŠ¹æœé‡ (Large effect)"
        else:
            interpretation = "éå¸¸ã«å¤§ãã„åŠ¹æœé‡ (Very large effect)"
        
        return d, interpretation
    
    def _run_independent_ttest(self):
        """å¯¾å¿œãªã—tæ¤œå®šå®Ÿè¡Œ"""
        try:
            numeric_cols = self.current_data.select_dtypes(include=[np.number]).columns.tolist()
            categorical_cols = self.current_data.select_dtypes(include=['object']).columns.tolist()
            
            if len(numeric_cols) == 0 or len(categorical_cols) == 0:
                messagebox.showwarning("Warning", "æ•°å€¤åˆ—ã¨ã‚«ãƒ†ã‚´ãƒªåˆ—ã®ä¸¡æ–¹ãŒå¿…è¦ã§ã™")
                return
            
            # å¤‰æ•°é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            dialog = ctk.CTkToplevel(self.root)
            dialog.title("å¯¾å¿œãªã—tæ¤œå®š - å¤‰æ•°é¸æŠ")
            dialog.geometry("400x300")
            dialog.transient(self.root)
            dialog.grab_set()
            
            ctk.CTkLabel(dialog, text="å¯¾å¿œãªã—tæ¤œå®š", font=("Arial", 16, "bold")).pack(pady=10)
            
            # å¾“å±å¤‰æ•°é¸æŠ
            dep_frame = ctk.CTkFrame(dialog)
            dep_frame.pack(fill="x", padx=20, pady=5)
            ctk.CTkLabel(dep_frame, text="å¾“å±å¤‰æ•° (æ•°å€¤):").pack(side="left", padx=5)
            dep_var = ctk.CTkComboBox(dep_frame, values=numeric_cols)
            dep_var.pack(side="right", padx=5)
            
            # ç‹¬ç«‹å¤‰æ•°é¸æŠ
            ind_frame = ctk.CTkFrame(dialog)
            ind_frame.pack(fill="x", padx=20, pady=5)
            ctk.CTkLabel(ind_frame, text="ç‹¬ç«‹å¤‰æ•° (ã‚«ãƒ†ã‚´ãƒª):").pack(side="left", padx=5)
            ind_var = ctk.CTkComboBox(ind_frame, values=categorical_cols)
            ind_var.pack(side="right", padx=5)
            
            # ç­‰åˆ†æ•£æ€§ä»®å®š
            equal_var_frame = ctk.CTkFrame(dialog)
            equal_var_frame.pack(fill="x", padx=20, pady=5)
            equal_var = tk.BooleanVar(value=True)
            ctk.CTkCheckBox(equal_var_frame, text="ç­‰åˆ†æ•£æ€§ã‚’ä»®å®šã™ã‚‹", variable=equal_var).pack(pady=10)
            
            def run_test():
                dep_col = dep_var.get()
                ind_col = ind_var.get()
                
                if not dep_col or not ind_col:
                    messagebox.showwarning("Warning", "ä¸¡æ–¹ã®å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
                    return
                
                dialog.destroy()
                
                # ãƒ‡ãƒ¼ã‚¿æº–å‚™
                groups = self.current_data.groupby(ind_col)[dep_col].apply(lambda x: x.dropna()).to_dict()
                group_names = list(groups.keys())
                
                if len(group_names) != 2:
                    messagebox.showerror("Error", "ç‹¬ç«‹å¤‰æ•°ã¯2ã¤ã®ã‚«ãƒ†ã‚´ãƒªã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™")
                    return
                
                group1 = np.array(groups[group_names[0]])
                group2 = np.array(groups[group_names[1]])
                
                # tæ¤œå®šå®Ÿè¡Œ
                t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=equal_var.get())
                
                # Cohen's dè¨ˆç®—
                cohens_d, d_interpretation = self._calculate_cohens_d(group1, group2)
                
                # Leveneæ¤œå®šï¼ˆç­‰åˆ†æ•£æ€§ï¼‰
                levene_stat, levene_p = stats.levene(group1, group2)
                
                # çµæœè¡¨ç¤º
                result_text = f"""
ğŸ”„ å¯¾å¿œãªã—tæ¤œå®šçµæœ (Independent t-test)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š å¤‰æ•°è¨­å®š:
å¾“å±å¤‰æ•°: {dep_col}
ç‹¬ç«‹å¤‰æ•°: {ind_col}
ç­‰åˆ†æ•£æ€§ä»®å®š: {'ã‚ã‚Š' if equal_var.get() else 'ãªã—'}

ğŸ“ˆ è¨˜è¿°çµ±è¨ˆ:
{group_names[0]} (n={len(group1)}):
  å¹³å‡ = {np.mean(group1):.4f}, æ¨™æº–åå·® = {np.std(group1, ddof=1):.4f}
{group_names[1]} (n={len(group2)}):
  å¹³å‡ = {np.mean(group2):.4f}, æ¨™æº–åå·® = {np.std(group2, ddof=1):.4f}

ğŸ” ç­‰åˆ†æ•£æ€§æ¤œå®š (Levene):
çµ±è¨ˆé‡ = {levene_stat:.4f}, på€¤ = {levene_p:.6f}
â†’ ç­‰åˆ†æ•£æ€§: {'ä»®å®šå¯èƒ½' if levene_p > 0.05 else 'ä»®å®šå›°é›£'}

ğŸ”¬ tæ¤œå®šçµæœ:
tçµ±è¨ˆé‡ = {t_stat:.4f}
på€¤ = {p_value:.6f}
è‡ªç”±åº¦ = {len(group1) + len(group2) - 2}

ğŸ“Š åŠ¹æœé‡ (Cohen's d):
d = {cohens_d:.4f}
è§£é‡ˆ: {d_interpretation}

âœ… çµè«– (Î± = 0.05):
{'æœ‰æ„å·®ã‚ã‚Š' if p_value < 0.05 else 'æœ‰æ„å·®ãªã—'}
å¹³å‡å·® = {np.mean(group1) - np.mean(group2):.4f}
95%ä¿¡é ¼åŒºé–“: {stats.t.interval(0.95, len(group1) + len(group2) - 2, 
                              loc=np.mean(group1) - np.mean(group2), 
                              scale=stats.sem(group1) + stats.sem(group2))}
                """
                
                self.result_text.delete("1.0", "end")
                self.result_text.insert("1.0", result_text)
                
                # çµæœä¿å­˜
                self.analysis_results['independent_ttest'] = {
                    'dependent_var': dep_col,
                    'independent_var': ind_col,
                    't_statistic': t_stat,
                    'p_value': p_value,
                    'cohens_d': cohens_d,
                    'group_means': [np.mean(group1), np.mean(group2)],
                    'group_names': group_names
                }
                
                self._update_status("å¯¾å¿œãªã—tæ¤œå®šå®Œäº†")
            
            ctk.CTkButton(dialog, text="å®Ÿè¡Œ", command=run_test).pack(pady=20)
            
        except Exception as e:
            messagebox.showerror("Error", f"å¯¾å¿œãªã—tæ¤œå®šã‚¨ãƒ©ãƒ¼: {e}")
    
    def _run_paired_ttest(self):
        """å¯¾å¿œã‚ã‚Štæ¤œå®šå®Ÿè¡Œ"""
        try:
            numeric_cols = self.current_data.select_dtypes(include=[np.number]).columns.tolist()
            
            if len(numeric_cols) < 2:
                messagebox.showwarning("Warning", "å¯¾å¿œã‚ã‚Štæ¤œå®šã«ã¯2ã¤ä»¥ä¸Šã®æ•°å€¤åˆ—ãŒå¿…è¦ã§ã™")
                return
            
            # å¤‰æ•°é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            dialog = ctk.CTkToplevel(self.root)
            dialog.title("å¯¾å¿œã‚ã‚Štæ¤œå®š - å¤‰æ•°é¸æŠ")
            dialog.geometry("400x250")
            dialog.transient(self.root)
            dialog.grab_set()
            
            ctk.CTkLabel(dialog, text="å¯¾å¿œã‚ã‚Štæ¤œå®š", font=("Arial", 16, "bold")).pack(pady=10)
            
            # ç¬¬1å¤‰æ•°é¸æŠ
            var1_frame = ctk.CTkFrame(dialog)
            var1_frame.pack(fill="x", padx=20, pady=5)
            ctk.CTkLabel(var1_frame, text="ç¬¬1å¤‰æ•°:").pack(side="left", padx=5)
            var1 = ctk.CTkComboBox(var1_frame, values=numeric_cols)
            var1.pack(side="right", padx=5)
            
            # ç¬¬2å¤‰æ•°é¸æŠ
            var2_frame = ctk.CTkFrame(dialog)
            var2_frame.pack(fill="x", padx=20, pady=5)
            ctk.CTkLabel(var2_frame, text="ç¬¬2å¤‰æ•°:").pack(side="left", padx=5)
            var2 = ctk.CTkComboBox(var2_frame, values=numeric_cols)
            var2.pack(side="right", padx=5)
            
            def run_test():
                var1_col = var1.get()
                var2_col = var2.get()
                
                if not var1_col or not var2_col:
                    messagebox.showwarning("Warning", "ä¸¡æ–¹ã®å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
                    return
                
                if var1_col == var2_col:
                    messagebox.showwarning("Warning", "ç•°ãªã‚‹å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
                    return
                
                dialog.destroy()
                
                # ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆæ¬ æå€¤ã‚’é™¤å¤–ï¼‰
                data_pairs = self.current_data[[var1_col, var2_col]].dropna()
                group1 = data_pairs[var1_col].values
                group2 = data_pairs[var2_col].values
                
                if len(group1) < 3:
                    messagebox.showerror("Error", "æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½3ãƒšã‚¢å¿…è¦ï¼‰")
                    return
                
                # å¯¾å¿œã‚ã‚Štæ¤œå®šå®Ÿè¡Œ
                t_stat, p_value = stats.ttest_rel(group1, group2)
                
                # Cohen's dè¨ˆç®—ï¼ˆå¯¾å¿œã‚ã‚Šã®å ´åˆï¼‰
                diff = group1 - group2
                cohens_d = np.mean(diff) / np.std(diff, ddof=1)
                
                # åŠ¹æœé‡è§£é‡ˆ
                if abs(cohens_d) < 0.2:
                    d_interpretation = "å°ã•ã„åŠ¹æœé‡ (Small effect)"
                elif abs(cohens_d) < 0.5:
                    d_interpretation = "ä¸­ç¨‹åº¦ã®åŠ¹æœé‡ (Medium effect)"
                elif abs(cohens_d) < 0.8:
                    d_interpretation = "å¤§ãã„åŠ¹æœé‡ (Large effect)"
                else:
                    d_interpretation = "éå¸¸ã«å¤§ãã„åŠ¹æœé‡ (Very large effect)"
                
                # æ­£è¦æ€§æ¤œå®šï¼ˆå·®åˆ†ã«ã¤ã„ã¦ï¼‰
                shapiro_stat, shapiro_p = stats.shapiro(diff)
                
                # çµæœè¡¨ç¤º
                result_text = f"""
ğŸ”— å¯¾å¿œã‚ã‚Štæ¤œå®šçµæœ (Paired t-test)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š å¤‰æ•°è¨­å®š:
ç¬¬1å¤‰æ•°: {var1_col}
ç¬¬2å¤‰æ•°: {var2_col}
æœ‰åŠ¹ãƒšã‚¢æ•°: {len(group1)}

ğŸ“ˆ è¨˜è¿°çµ±è¨ˆ:
{var1_col}: å¹³å‡ = {np.mean(group1):.4f}, æ¨™æº–åå·® = {np.std(group1, ddof=1):.4f}
{var2_col}: å¹³å‡ = {np.mean(group2):.4f}, æ¨™æº–åå·® = {np.std(group2, ddof=1):.4f}

å·®åˆ† ({var1_col} - {var2_col}):
å¹³å‡å·® = {np.mean(diff):.4f}
å·®ã®æ¨™æº–åå·® = {np.std(diff, ddof=1):.4f}

ğŸ” æ­£è¦æ€§æ¤œå®š (å·®åˆ†ã®Shapiro-Wilk):
çµ±è¨ˆé‡ = {shapiro_stat:.4f}, på€¤ = {shapiro_p:.6f}
â†’ æ­£è¦æ€§: {'ä»®å®šå¯èƒ½' if shapiro_p > 0.05 else 'ä»®å®šå›°é›£'}

ğŸ”¬ å¯¾å¿œã‚ã‚Štæ¤œå®šçµæœ:
tçµ±è¨ˆé‡ = {t_stat:.4f}
på€¤ = {p_value:.6f}
è‡ªç”±åº¦ = {len(group1) - 1}

ğŸ“Š åŠ¹æœé‡ (Cohen's d):
d = {cohens_d:.4f}
è§£é‡ˆ: {d_interpretation}

âœ… çµè«– (Î± = 0.05):
{'æœ‰æ„å·®ã‚ã‚Š' if p_value < 0.05 else 'æœ‰æ„å·®ãªã—'}
95%ä¿¡é ¼åŒºé–“: {stats.t.interval(0.95, len(group1) - 1, 
                              loc=np.mean(diff), 
                              scale=stats.sem(diff))}
                """
                
                self.result_text.delete("1.0", "end")
                self.result_text.insert("1.0", result_text)
                
                # çµæœä¿å­˜
                self.analysis_results['paired_ttest'] = {
                    'var1': var1_col,
                    'var2': var2_col,
                    't_statistic': t_stat,
                    'p_value': p_value,
                    'cohens_d': cohens_d,
                    'mean_difference': np.mean(diff),
                    'n_pairs': len(group1)
                }
                
                self._update_status("å¯¾å¿œã‚ã‚Štæ¤œå®šå®Œäº†")
            
            ctk.CTkButton(dialog, text="å®Ÿè¡Œ", command=run_test).pack(pady=20)
            
        except Exception as e:
            messagebox.showerror("Error", f"å¯¾å¿œã‚ã‚Štæ¤œå®šã‚¨ãƒ©ãƒ¼: {e}")
    
    def _run_ftest(self):
        """Fæ¤œå®šï¼ˆç­‰åˆ†æ•£æ€§æ¤œå®šï¼‰å®Ÿè¡Œ"""
        try:
            numeric_cols = self.current_data.select_dtypes(include=[np.number]).columns.tolist()
            categorical_cols = self.current_data.select_dtypes(include=['object']).columns.tolist()
            
            if len(numeric_cols) == 0:
                messagebox.showwarning("Warning", "æ•°å€¤åˆ—ãŒå¿…è¦ã§ã™")
                return
            
            # å¤‰æ•°é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            dialog = ctk.CTkToplevel(self.root)
            dialog.title("Fæ¤œå®š - å¤‰æ•°é¸æŠ")
            dialog.geometry("400x300")
            dialog.transient(self.root)
            dialog.grab_set()
            
            ctk.CTkLabel(dialog, text="Fæ¤œå®šï¼ˆç­‰åˆ†æ•£æ€§æ¤œå®šï¼‰", font=("Arial", 16, "bold")).pack(pady=10)
            
            # å¾“å±å¤‰æ•°é¸æŠ
            dep_frame = ctk.CTkFrame(dialog)
            dep_frame.pack(fill="x", padx=20, pady=5)
            ctk.CTkLabel(dep_frame, text="æ¤œå®šå¯¾è±¡å¤‰æ•°:").pack(side="left", padx=5)
            dep_var = ctk.CTkComboBox(dep_frame, values=numeric_cols)
            dep_var.pack(side="right", padx=5)
            
            # ã‚°ãƒ«ãƒ¼ãƒ—å¤‰æ•°é¸æŠï¼ˆã‚ã‚‹å ´åˆï¼‰
            if categorical_cols:
                group_frame = ctk.CTkFrame(dialog)
                group_frame.pack(fill="x", padx=20, pady=5)
                ctk.CTkLabel(group_frame, text="ã‚°ãƒ«ãƒ¼ãƒ—å¤‰æ•° (ã‚ªãƒ—ã‚·ãƒ§ãƒ³):").pack(side="left", padx=5)
                group_var = ctk.CTkComboBox(group_frame, values=["ãªã—"] + categorical_cols)
                group_var.pack(side="right", padx=5)
                group_var.set("ãªã—")
            else:
                group_var = None
            
            # ç¬¬2å¤‰æ•°é¸æŠï¼ˆã‚°ãƒ«ãƒ¼ãƒ—ãªã—ã®å ´åˆï¼‰
            var2_frame = ctk.CTkFrame(dialog)
            var2_frame.pack(fill="x", padx=20, pady=5)
            ctk.CTkLabel(var2_frame, text="æ¯”è¼ƒå¤‰æ•° (ã‚°ãƒ«ãƒ¼ãƒ—ãªã—ã®å ´åˆ):").pack(side="left", padx=5)
            var2 = ctk.CTkComboBox(var2_frame, values=["ãªã—"] + numeric_cols)
            var2.pack(side="right", padx=5)
            var2.set("ãªã—")
            
            def run_test():
                dep_col = dep_var.get()
                group_col = group_var.get() if group_var else "ãªã—"
                var2_col = var2.get()
                
                if not dep_col:
                    messagebox.showwarning("Warning", "æ¤œå®šå¯¾è±¡å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
                    return
                
                dialog.destroy()
                
                if group_col != "ãªã—":
                    # ã‚°ãƒ«ãƒ¼ãƒ—å¤‰æ•°ãŒã‚ã‚‹å ´åˆ
                    groups = self.current_data.groupby(group_col)[dep_col].apply(lambda x: x.dropna()).to_dict()
                    group_names = list(groups.keys())
                    
                    if len(group_names) < 2:
                        messagebox.showerror("Error", "2ã¤ä»¥ä¸Šã®ã‚°ãƒ«ãƒ¼ãƒ—ãŒå¿…è¦ã§ã™")
                        return
                    
                    # å„ãƒšã‚¢ã§Fæ¤œå®šå®Ÿè¡Œ
                    results = []
                    for i in range(len(group_names)):
                        for j in range(i+1, len(group_names)):
                            g1 = np.array(groups[group_names[i]])
                            g2 = np.array(groups[group_names[j]])
                            
                            # Fçµ±è¨ˆé‡è¨ˆç®—
                            var1, var2 = np.var(g1, ddof=1), np.var(g2, ddof=1)
                            f_stat = var1 / var2 if var1 >= var2 else var2 / var1
                            df1 = len(g1) - 1
                            df2 = len(g2) - 1
                            p_value = 2 * (1 - stats.f.cdf(f_stat, df1, df2))
                            
                            results.append({
                                'group1': group_names[i],
                                'group2': group_names[j],
                                'f_statistic': f_stat,
                                'p_value': p_value,
                                'var1': var1,
                                'var2': var2,
                                'n1': len(g1),
                                'n2': len(g2)
                            })
                    
                    # çµæœè¡¨ç¤º
                    result_text = f"""
ğŸ“Š Fæ¤œå®šçµæœï¼ˆç­‰åˆ†æ•£æ€§æ¤œå®šï¼‰
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š å¤‰æ•°: {dep_col}
ã‚°ãƒ«ãƒ¼ãƒ—å¤‰æ•°: {group_col}

"""
                    for result in results:
                        result_text += f"""
ğŸ” {result['group1']} vs {result['group2']}:
  åˆ†æ•£1 = {result['var1']:.6f} (n={result['n1']})
  åˆ†æ•£2 = {result['var2']:.6f} (n={result['n2']})
  Fçµ±è¨ˆé‡ = {result['f_statistic']:.4f}
  på€¤ = {result['p_value']:.6f}
  â†’ {'ç­‰åˆ†æ•£æ€§ä»®å®šå¯èƒ½' if result['p_value'] > 0.05 else 'ç­‰åˆ†æ•£æ€§ä»®å®šå›°é›£'}

"""
                    
                elif var2_col != "ãªã—":
                    # 2å¤‰æ•°é–“ã®Fæ¤œå®š
                    data1 = self.current_data[dep_col].dropna()
                    data2 = self.current_data[var2_col].dropna()
                    
                    var1, var2 = np.var(data1, ddof=1), np.var(data2, ddof=1)
                    f_stat = var1 / var2 if var1 >= var2 else var2 / var1
                    df1 = len(data1) - 1
                    df2 = len(data2) - 1
                    p_value = 2 * (1 - stats.f.cdf(f_stat, df1, df2))
                    
                    result_text = f"""
ğŸ“Š Fæ¤œå®šçµæœï¼ˆç­‰åˆ†æ•£æ€§æ¤œå®šï¼‰
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š å¤‰æ•°1: {dep_col} (n={len(data1)})
å¤‰æ•°2: {var2_col} (n={len(data2)})

ğŸ“ˆ åˆ†æ•£:
{dep_col}: {var1:.6f}
{var2_col}: {var2:.6f}

ğŸ”¬ Fæ¤œå®šçµæœ:
Fçµ±è¨ˆé‡ = {f_stat:.4f}
è‡ªç”±åº¦ = ({df1}, {df2})
på€¤ = {p_value:.6f}

âœ… çµè«– (Î± = 0.05):
{'ç­‰åˆ†æ•£æ€§ä»®å®šå¯èƒ½' if p_value > 0.05 else 'ç­‰åˆ†æ•£æ€§ä»®å®šå›°é›£'}
åˆ†æ•£æ¯” = {var1/var2:.4f}
                    """
                    
                    results = [{
                        'var1': dep_col,
                        'var2': var2_col,
                        'f_statistic': f_stat,
                        'p_value': p_value,
                        'variance1': var1,
                        'variance2': var2
                    }]
                    
                else:
                    messagebox.showwarning("Warning", "ã‚°ãƒ«ãƒ¼ãƒ—å¤‰æ•°ã¾ãŸã¯æ¯”è¼ƒå¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
                    return
                
                self.result_text.delete("1.0", "end")
                self.result_text.insert("1.0", result_text)
                
                # çµæœä¿å­˜
                self.analysis_results['f_test'] = results
                self._update_status("Fæ¤œå®šå®Œäº†")
            
            ctk.CTkButton(dialog, text="å®Ÿè¡Œ", command=run_test).pack(pady=20)
            
        except Exception as e:
            messagebox.showerror("Error", f"Fæ¤œå®šã‚¨ãƒ©ãƒ¼: {e}")
    
    def _run_anova(self):
        """ä¸€å…ƒé…ç½®åˆ†æ•£åˆ†æå®Ÿè¡Œ"""
        try:
            numeric_cols = self.current_data.select_dtypes(include=[np.number]).columns.tolist()
            categorical_cols = self.current_data.select_dtypes(include=['object']).columns.tolist()
            
            if len(numeric_cols) == 0 or len(categorical_cols) == 0:
                messagebox.showwarning("Warning", "æ•°å€¤åˆ—ã¨ã‚«ãƒ†ã‚´ãƒªåˆ—ã®ä¸¡æ–¹ãŒå¿…è¦ã§ã™")
                return
            
            # å¤‰æ•°é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            dialog = ctk.CTkToplevel(self.root)
            dialog.title("ä¸€å…ƒé…ç½®åˆ†æ•£åˆ†æ - å¤‰æ•°é¸æŠ")
            dialog.geometry("400x350")
            dialog.transient(self.root)
            dialog.grab_set()
            
            ctk.CTkLabel(dialog, text="ä¸€å…ƒé…ç½®åˆ†æ•£åˆ†æ (One-way ANOVA)", font=("Arial", 16, "bold")).pack(pady=10)
            
            # å¾“å±å¤‰æ•°é¸æŠ
            dep_frame = ctk.CTkFrame(dialog)
            dep_frame.pack(fill="x", padx=20, pady=5)
            ctk.CTkLabel(dep_frame, text="å¾“å±å¤‰æ•° (æ•°å€¤):").pack(side="left", padx=5)
            dep_var = ctk.CTkComboBox(dep_frame, values=numeric_cols)
            dep_var.pack(side="right", padx=5)
            
            # ç‹¬ç«‹å¤‰æ•°é¸æŠ
            ind_frame = ctk.CTkFrame(dialog)
            ind_frame.pack(fill="x", padx=20, pady=5)
            ctk.CTkLabel(ind_frame, text="ç‹¬ç«‹å¤‰æ•° (ã‚«ãƒ†ã‚´ãƒª):").pack(side="left", padx=5)
            ind_var = ctk.CTkComboBox(ind_frame, values=categorical_cols)
            ind_var.pack(side="right", padx=5)
            
            # äº‹å¾Œæ¤œå®šã‚ªãƒ—ã‚·ãƒ§ãƒ³
            posthoc_frame = ctk.CTkFrame(dialog)
            posthoc_frame.pack(fill="x", padx=20, pady=5)
            posthoc_var = tk.BooleanVar(value=True)
            ctk.CTkCheckBox(posthoc_frame, text="äº‹å¾Œæ¤œå®šï¼ˆTukey HSDï¼‰ã‚’å®Ÿè¡Œ", variable=posthoc_var).pack(pady=10)
            
            def run_test():
                dep_col = dep_var.get()
                ind_col = ind_var.get()
                
                if not dep_col or not ind_col:
                    messagebox.showwarning("Warning", "ä¸¡æ–¹ã®å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
                    return
                
                dialog.destroy()
                
                # ãƒ‡ãƒ¼ã‚¿æº–å‚™
                data_clean = self.current_data[[dep_col, ind_col]].dropna()
                groups = data_clean.groupby(ind_col)[dep_col].apply(list).to_dict()
                group_names = list(groups.keys())
                
                if len(group_names) < 2:
                    messagebox.showerror("Error", "2ã¤ä»¥ä¸Šã®ã‚°ãƒ«ãƒ¼ãƒ—ãŒå¿…è¦ã§ã™")
                    return
                
                # ANOVAå®Ÿè¡Œ
                f_stat, p_value = stats.f_oneway(*groups.values())
                
                # å„ã‚°ãƒ«ãƒ¼ãƒ—ã®çµ±è¨ˆé‡
                group_stats = {}
                for name, data in groups.items():
                    group_stats[name] = {
                        'n': len(data),
                        'mean': np.mean(data),
                        'std': np.std(data, ddof=1),
                        'var': np.var(data, ddof=1)
                    }
                
                # åŠ¹æœé‡ï¼ˆeta squaredï¼‰è¨ˆç®—
                ss_between = sum([len(groups[name]) * (group_stats[name]['mean'] - np.mean(data_clean[dep_col]))**2 
                                 for name in group_names])
                ss_total = sum([(x - np.mean(data_clean[dep_col]))**2 for x in data_clean[dep_col]])
                eta_squared = ss_between / ss_total
                
                # eta squaredè§£é‡ˆ
                if eta_squared < 0.01:
                    eta_interpretation = "å°ã•ã„åŠ¹æœé‡ (Small effect)"
                elif eta_squared < 0.06:
                    eta_interpretation = "ä¸­ç¨‹åº¦ã®åŠ¹æœé‡ (Medium effect)"
                elif eta_squared < 0.14:
                    eta_interpretation = "å¤§ãã„åŠ¹æœé‡ (Large effect)"
                else:
                    eta_interpretation = "éå¸¸ã«å¤§ãã„åŠ¹æœé‡ (Very large effect)"
                
                # çµæœè¡¨ç¤º
                result_text = f"""
ğŸ¯ ä¸€å…ƒé…ç½®åˆ†æ•£åˆ†æçµæœ (One-way ANOVA)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š å¤‰æ•°è¨­å®š:
å¾“å±å¤‰æ•°: {dep_col}
ç‹¬ç«‹å¤‰æ•°: {ind_col}
ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(data_clean)}

ğŸ“ˆ å„ã‚°ãƒ«ãƒ¼ãƒ—ã®è¨˜è¿°çµ±è¨ˆ:
"""
                
                for name, stats_dict in group_stats.items():
                    result_text += f"""
{name} (n={stats_dict['n']}):
  å¹³å‡ = {stats_dict['mean']:.4f}
  æ¨™æº–åå·® = {stats_dict['std']:.4f}
"""
                
                # ç­‰åˆ†æ•£æ€§æ¤œå®šï¼ˆLeveneæ¤œå®šï¼‰
                levene_stat, levene_p = stats.levene(*groups.values())
                
                result_text += f"""
ğŸ” ç­‰åˆ†æ•£æ€§æ¤œå®š (Levene):
çµ±è¨ˆé‡ = {levene_stat:.4f}, på€¤ = {levene_p:.6f}
â†’ ç­‰åˆ†æ•£æ€§: {'ä»®å®šå¯èƒ½' if levene_p > 0.05 else 'ä»®å®šå›°é›£'}

ğŸ”¬ ANOVAçµæœ:
Fçµ±è¨ˆé‡ = {f_stat:.4f}
på€¤ = {p_value:.6f}
è‡ªç”±åº¦ = ({len(group_names)-1}, {len(data_clean)-len(group_names)})

ğŸ“Š åŠ¹æœé‡ (Î·Â²):
Î·Â² = {eta_squared:.4f}
è§£é‡ˆ: {eta_interpretation}

âœ… çµè«– (Î± = 0.05):
{'æœ‰æ„å·®ã‚ã‚Š' if p_value < 0.05 else 'æœ‰æ„å·®ãªã—'}
"""
                
                # äº‹å¾Œæ¤œå®šï¼ˆTukey HSDï¼‰
                if posthoc_var.get() and p_value < 0.05:
                    try:
                        from scipy.stats import tukey_hsd
                        tukey_result = tukey_hsd(*groups.values())
                        
                        result_text += f"""

ğŸ” äº‹å¾Œæ¤œå®š (Tukey HSD):
"""
                        for i, name1 in enumerate(group_names):
                            for j, name2 in enumerate(group_names):
                                if i < j:
                                    pval = tukey_result.pvalue[i, j]
                                    result_text += f"{name1} vs {name2}: p = {pval:.6f} {'*' if pval < 0.05 else ''}\n"
                    
                    except ImportError:
                        result_text += "\nâš ï¸ äº‹å¾Œæ¤œå®šã«ã¯scipy 1.7.0ä»¥ä¸ŠãŒå¿…è¦ã§ã™"
                
                self.result_text.delete("1.0", "end")
                self.result_text.insert("1.0", result_text)
                
                # çµæœä¿å­˜
                self.analysis_results['anova'] = {
                    'dependent_var': dep_col,
                    'independent_var': ind_col,
                    'f_statistic': f_stat,
                    'p_value': p_value,
                    'eta_squared': eta_squared,
                    'group_stats': group_stats
                }
                
                self._update_status("ä¸€å…ƒé…ç½®åˆ†æ•£åˆ†æå®Œäº†")
            
            ctk.CTkButton(dialog, text="å®Ÿè¡Œ", command=run_test).pack(pady=20)
            
        except Exception as e:
            messagebox.showerror("Error", f"ANOVAåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
    
    def _run_normality_tests(self):
        """æ­£è¦æ€§æ¤œå®šå®Ÿè¡Œ"""
        try:
            numeric_cols = self.current_data.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) == 0:
                messagebox.showwarning("Warning", "No numeric columns found")
                return
            
            self._update_status("Running normality tests...")
            
            results = []
            for col in numeric_cols[:10]:  # æœ€åˆã®10åˆ—
                data = self.current_data[col].dropna()
                if len(data) < 3:
                    continue
                
                # Shapiro-Wilkæ­£è¦æ€§æ¤œå®š
                shapiro_stat, shapiro_p = stats.shapiro(data)
                
                # Kolmogorov-Smirnovæ¤œå®š
                ks_stat, ks_p = stats.kstest(data, 'norm', args=(np.mean(data), np.std(data)))
                
                # Anderson-Darlingæ¤œå®š
                ad_result = stats.anderson(data, dist='norm')
                
                results.append({
                    'Variable': col,
                    'N': len(data),
                    'Shapiro_stat': shapiro_stat,
                    'Shapiro_p': shapiro_p,
                    'KS_stat': ks_stat,
                    'KS_p': ks_p,
                    'AD_stat': ad_result.statistic,
                    'Mean': np.mean(data),
                    'Std': np.std(data, ddof=1),
                    'Skewness': stats.skew(data),
                    'Kurtosis': stats.kurtosis(data)
                })
            
            # çµæœè¡¨ç¤º
            result_text = "\nğŸ“ˆ æ­£è¦æ€§æ¤œå®šçµæœ (Normality Tests)\n"
            result_text += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
            
            for res in results:
                result_text += f"""
ğŸ“Š å¤‰æ•°: {res['Variable']} (n={res['N']})
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ˆ è¨˜è¿°çµ±è¨ˆ:
å¹³å‡ = {res['Mean']:.4f}, æ¨™æº–åå·® = {res['Std']:.4f}
æ­ªåº¦ = {res['Skewness']:.4f}, å°–åº¦ = {res['Kurtosis']:.4f}

ğŸ”¬ æ­£è¦æ€§æ¤œå®š:
Shapiro-Wilk: çµ±è¨ˆé‡ = {res['Shapiro_stat']:.4f}, på€¤ = {res['Shapiro_p']:.6f}
â†’ {'æ­£è¦åˆ†å¸ƒ' if res['Shapiro_p'] > 0.05 else 'éæ­£è¦åˆ†å¸ƒ'}

Kolmogorov-Smirnov: çµ±è¨ˆé‡ = {res['KS_stat']:.4f}, på€¤ = {res['KS_p']:.6f}
â†’ {'æ­£è¦åˆ†å¸ƒ' if res['KS_p'] > 0.05 else 'éæ­£è¦åˆ†å¸ƒ'}

Anderson-Darling: çµ±è¨ˆé‡ = {res['AD_stat']:.4f}

"""
            
            self.result_text.delete("1.0", "end")
            self.result_text.insert("1.0", result_text)
            
            self.analysis_results['normality_tests'] = results
            self._update_status("æ­£è¦æ€§æ¤œå®šå®Œäº†")
            
        except Exception as e:
            messagebox.showerror("Error", f"æ­£è¦æ€§æ¤œå®šã‚¨ãƒ©ãƒ¼: {e}")
    
    def _run_multiple_ttest(self):
        """å¤šé‡tæ¤œå®šï¼ˆè£œæ­£ä»˜ãï¼‰å®Ÿè¡Œ"""
        try:
            numeric_cols = self.current_data.select_dtypes(include=[np.number]).columns.tolist()
            
            if len(numeric_cols) < 2:
                messagebox.showwarning("Warning", "å¤šé‡tæ¤œå®šã«ã¯2ã¤ä»¥ä¸Šã®æ•°å€¤åˆ—ãŒå¿…è¦ã§ã™")
                return
            
            # å¤‰æ•°é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            dialog = ctk.CTkToplevel(self.root)
            dialog.title("å¤šé‡tæ¤œå®š - å¤‰æ•°é¸æŠ")
            dialog.geometry("500x400")
            dialog.transient(self.root)
            dialog.grab_set()
            
            ctk.CTkLabel(dialog, text="å¤šé‡tæ¤œå®šï¼ˆè£œæ­£ä»˜ãï¼‰", font=("Arial", 16, "bold")).pack(pady=10)
            
            # å¤‰æ•°é¸æŠãƒ•ãƒ¬ãƒ¼ãƒ 
            var_frame = ctk.CTkFrame(dialog)
            var_frame.pack(fill="x", padx=20, pady=10)
            ctk.CTkLabel(var_frame, text="æ¯”è¼ƒã™ã‚‹å¤‰æ•°ã‚’é¸æŠ:", font=("Arial", 12)).pack(pady=5)
            
            # å¤‰æ•°é¸æŠç”¨ãƒªã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹
            selected_vars = []
            var_checkboxes = {}
            
            scrollable_frame = ctk.CTkScrollableFrame(var_frame, height=150)
            scrollable_frame.pack(fill="both", expand=True, padx=10, pady=5)
            
            for col in numeric_cols:
                var = tk.BooleanVar()
                checkbox = ctk.CTkCheckBox(scrollable_frame, text=col, variable=var)
                checkbox.pack(anchor="w", pady=2)
                var_checkboxes[col] = var
            
            # è£œæ­£æ–¹æ³•é¸æŠ
            correction_frame = ctk.CTkFrame(dialog)
            correction_frame.pack(fill="x", padx=20, pady=10)
            ctk.CTkLabel(correction_frame, text="å¤šé‡æ¯”è¼ƒè£œæ­£æ–¹æ³•:", font=("Arial", 12)).pack(pady=5)
            
            correction_var = tk.StringVar(value="bonferroni")
            corrections = [
                ("bonferroni", "Bonferroniè£œæ­£"),
                ("holm", "Holm-Bonferroniè£œæ­£"),
                ("fdr_bh", "FDR (Benjamini-Hochberg)"),
                ("sidak", "Å idÃ¡kè£œæ­£"),
                ("none", "è£œæ­£ãªã—")
            ]
            
            for value, text in corrections:
                ctk.CTkRadioButton(correction_frame, text=text, variable=correction_var, value=value).pack(anchor="w", pady=2)
            
            def run_test():
                # é¸æŠã•ã‚ŒãŸå¤‰æ•°ã‚’å–å¾—
                selected_cols = [col for col, var in var_checkboxes.items() if var.get()]
                
                if len(selected_cols) < 2:
                    messagebox.showwarning("Warning", "å°‘ãªãã¨ã‚‚2ã¤ã®å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
                    return
                
                correction_method = correction_var.get()
                dialog.destroy()
                
                # å…¨çµ„ã¿åˆã‚ã›ã§tæ¤œå®šå®Ÿè¡Œ
                from itertools import combinations
                import pandas as pd
                
                results = []
                p_values = []
                comparisons = []
                
                for col1, col2 in combinations(selected_cols, 2):
                    data1 = self.current_data[col1].dropna()
                    data2 = self.current_data[col2].dropna()
                    
                    if len(data1) < 3 or len(data2) < 3:
                        continue
                    
                    # å¯¾å¿œã‚ã‚Štæ¤œå®š
                    # ãƒ‡ãƒ¼ã‚¿ã®é•·ã•ã‚’åˆã‚ã›ã‚‹
                    min_len = min(len(data1), len(data2))
                    data1_trimmed = data1.iloc[:min_len]
                    data2_trimmed = data2.iloc[:min_len]
                    
                    t_stat, p_val = stats.ttest_rel(data1_trimmed, data2_trimmed)
                    cohens_d = (np.mean(data1_trimmed) - np.mean(data2_trimmed)) / np.std(data1_trimmed - data2_trimmed, ddof=1)
                    
                    results.append({
                        'comparison': f"{col1} vs {col2}",
                        'col1': col1,
                        'col2': col2,
                        't_statistic': t_stat,
                        'p_value_raw': p_val,
                        'cohens_d': cohens_d,
                        'mean1': np.mean(data1_trimmed),
                        'mean2': np.mean(data2_trimmed),
                        'n': min_len
                    })
                    p_values.append(p_val)
                    comparisons.append(f"{col1} vs {col2}")
                
                if not results:
                    messagebox.showerror("Error", "æœ‰åŠ¹ãªæ¯”è¼ƒãŒã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    return
                
                # å¤šé‡æ¯”è¼ƒè£œæ­£é©ç”¨
                p_values_array = np.array(p_values)
                
                if correction_method == "bonferroni":
                    p_corrected = p_values_array * len(p_values)
                    p_corrected = np.minimum(p_corrected, 1.0)
                elif correction_method == "holm":
                    # Holm-Bonferroniè£œæ­£
                    sorted_indices = np.argsort(p_values_array)
                    p_corrected = np.zeros_like(p_values_array)
                    for i, idx in enumerate(sorted_indices):
                        p_corrected[idx] = min(1.0, p_values_array[idx] * (len(p_values) - i))
                elif correction_method == "fdr_bh":
                    # Benjamini-Hochberg FDRè£œæ­£
                    sorted_indices = np.argsort(p_values_array)
                    p_corrected = np.zeros_like(p_values_array)
                    for i, idx in enumerate(sorted_indices):
                        p_corrected[idx] = min(1.0, p_values_array[idx] * len(p_values) / (i + 1))
                elif correction_method == "sidak":
                    # Å idÃ¡kè£œæ­£
                    p_corrected = 1 - (1 - p_values_array) ** len(p_values)
                else:  # "none"
                    p_corrected = p_values_array
                
                # çµæœã«è£œæ­£æ¸ˆã¿på€¤ã‚’è¿½åŠ 
                for i, result in enumerate(results):
                    result['p_value_corrected'] = p_corrected[i]
                    result['significant'] = p_corrected[i] < 0.05
                
                # çµæœè¡¨ç¤º
                correction_names = {
                    "bonferroni": "Bonferroniè£œæ­£",
                    "holm": "Holm-Bonferroniè£œæ­£", 
                    "fdr_bh": "FDR (Benjamini-Hochberg)",
                    "sidak": "Å idÃ¡kè£œæ­£",
                    "none": "è£œæ­£ãªã—"
                }
                
                result_text = f"""
ğŸ” å¤šé‡tæ¤œå®šçµæœ (Multiple t-tests with correction)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š è§£æè¨­å®š:
æ¯”è¼ƒæ•°: {len(results)}
è£œæ­£æ–¹æ³•: {correction_names[correction_method]}
æœ‰æ„æ°´æº–: Î± = 0.05

ğŸ“ˆ è©³ç´°çµæœ:
"""
                
                for i, result in enumerate(results, 1):
                    significance_marker = "âœ…" if result['significant'] else "âŒ"
                    effect_size = "å¤§" if abs(result['cohens_d']) > 0.8 else "ä¸­" if abs(result['cohens_d']) > 0.5 else "å°"
                    
                    result_text += f"""
{i}. {result['comparison']} {significance_marker}
   tçµ±è¨ˆé‡ = {result['t_statistic']:.4f}
   på€¤ï¼ˆç”Ÿï¼‰= {result['p_value_raw']:.6f}
   på€¤ï¼ˆè£œæ­£å¾Œï¼‰= {result['p_value_corrected']:.6f}
   Cohen's d = {result['cohens_d']:.4f} ({effect_size})
   å¹³å‡å·® = {result['mean1'] - result['mean2']:.4f}
   ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º = {result['n']}
"""
                
                significant_count = sum(1 for r in results if r['significant'])
                result_text += f"""
âœ… çµè«–:
æœ‰æ„å·®ã®ã‚ã‚‹æ¯”è¼ƒ: {significant_count}/{len(results)}
Family-wise Error Rateåˆ¶å¾¡: {'ã‚ã‚Š' if correction_method != 'none' else 'ãªã—'}
"""
                
                self.result_text.delete("1.0", "end")
                self.result_text.insert("1.0", result_text)
                
                # çµæœä¿å­˜
                self.analysis_results['multiple_ttest'] = {
                    'correction_method': correction_method,
                    'comparisons': results,
                    'significant_comparisons': significant_count,
                    'total_comparisons': len(results)
                }
                
                self._update_status("å¤šé‡tæ¤œå®šå®Œäº†")
            
            ctk.CTkButton(dialog, text="å®Ÿè¡Œ", command=run_test).pack(pady=20)
            
        except Exception as e:
            messagebox.showerror("Error", f"å¤šé‡tæ¤œå®šã‚¨ãƒ©ãƒ¼: {e}")
    
    def _run_sphericity_test(self):
        """çƒé¢æ€§æ¤œå®šå®Ÿè¡Œ"""
        try:
            numeric_cols = self.current_data.select_dtypes(include=[np.number]).columns.tolist()
            
            if len(numeric_cols) < 3:
                messagebox.showwarning("Warning", "çƒé¢æ€§æ¤œå®šã«ã¯3ã¤ä»¥ä¸Šã®æ•°å€¤åˆ—ãŒå¿…è¦ã§ã™")
                return
            
            # å¤‰æ•°é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            dialog = ctk.CTkToplevel(self.root)
            dialog.title("çƒé¢æ€§æ¤œå®š - å¤‰æ•°é¸æŠ")
            dialog.geometry("450x350")
            dialog.transient(self.root)
            dialog.grab_set()
            
            ctk.CTkLabel(dialog, text="çƒé¢æ€§æ¤œå®šï¼ˆMauchly's testï¼‰", font=("Arial", 16, "bold")).pack(pady=10)
            
            # èª¬æ˜ãƒ†ã‚­ã‚¹ãƒˆ
            info_frame = ctk.CTkFrame(dialog)
            info_frame.pack(fill="x", padx=20, pady=5)
            info_text = """
ğŸŒ çƒé¢æ€§ã®ä»®å®šã«ã¤ã„ã¦:
åå¾©æ¸¬å®šANOVAã«ãŠã„ã¦ã€å„æ¸¬å®šæ™‚ç‚¹é–“ã®åˆ†æ•£ãŒç­‰ã—ãã€
å…±åˆ†æ•£è¡Œåˆ—ãŒè¤‡åˆå¯¾ç§°æ€§ã‚’æº€ãŸã™ã‹ã‚’æ¤œå®šã—ã¾ã™ã€‚
            """
            ctk.CTkLabel(info_frame, text=info_text, justify="left").pack(pady=10)
            
            # å¤‰æ•°é¸æŠãƒ•ãƒ¬ãƒ¼ãƒ 
            var_frame = ctk.CTkFrame(dialog)
            var_frame.pack(fill="x", padx=20, pady=10)
            ctk.CTkLabel(var_frame, text="åå¾©æ¸¬å®šå¤‰æ•°ã‚’é¸æŠ:", font=("Arial", 12)).pack(pady=5)
            
            var_checkboxes = {}
            scrollable_frame = ctk.CTkScrollableFrame(var_frame, height=120)
            scrollable_frame.pack(fill="both", expand=True, padx=10, pady=5)
            
            for col in numeric_cols:
                var = tk.BooleanVar()
                checkbox = ctk.CTkCheckBox(scrollable_frame, text=col, variable=var)
                checkbox.pack(anchor="w", pady=2)
                var_checkboxes[col] = var
            
            def run_test():
                # é¸æŠã•ã‚ŒãŸå¤‰æ•°ã‚’å–å¾—
                selected_cols = [col for col, var in var_checkboxes.items() if var.get()]
                
                if len(selected_cols) < 3:
                    messagebox.showwarning("Warning", "å°‘ãªãã¨ã‚‚3ã¤ã®å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
                    return
                
                dialog.destroy()
                
                # ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆæ¬ æå€¤ã‚’å«ã‚€è¡Œã‚’é™¤å¤–ï¼‰
                data_matrix = self.current_data[selected_cols].dropna()
                
                if len(data_matrix) < 3:
                    messagebox.showerror("Error", "æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ï¼ˆæœ€ä½3ã‚±ãƒ¼ã‚¹å¿…è¦ï¼‰")
                    return
                
                # Mauchlyã®çƒé¢æ€§æ¤œå®š
                try:
                    from scipy.stats import chi2
                    import numpy.linalg as la
                    
                    # å…±åˆ†æ•£è¡Œåˆ—è¨ˆç®—
                    cov_matrix = np.cov(data_matrix.T)
                    n = len(data_matrix)
                    p = len(selected_cols)
                    
                    # å¤‰æ›è¡Œåˆ—ï¼ˆç›´äº¤ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆï¼‰
                    C = np.zeros((p-1, p))
                    for i in range(p-1):
                        C[i, i] = 1
                        C[i, i+1] = -1
                    
                    # å¤‰æ›ã•ã‚ŒãŸå…±åˆ†æ•£è¡Œåˆ—
                    S_transformed = C @ cov_matrix @ C.T
                    
                    # çƒé¢æ€§çµ±è¨ˆé‡è¨ˆç®—
                    trace_S = np.trace(S_transformed)
                    det_S = la.det(S_transformed)
                    
                    if det_S <= 0:
                        raise ValueError("è¡Œåˆ—å¼ãŒæ­£ã§ãªã„ãŸã‚ã€çƒé¢æ€§æ¤œå®šã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“")
                    
                    # Mauchlyã®çµ±è¨ˆé‡
                    W = det_S / ((trace_S / (p-1)) ** (p-1))
                    
                    # ã‚«ã‚¤äºŒä¹—çµ±è¨ˆé‡ã¸ã®å¤‰æ›
                    df = (p-1) * (p-2) / 2
                    chi2_stat = -(n - 1 - (2*p - 3) / 6) * np.log(W)
                    p_value = 1 - chi2.cdf(chi2_stat, df)
                    
                    # ã‚¤ãƒ—ã‚·ãƒ­ãƒ³ï¼ˆÎµï¼‰è¨ˆç®—ï¼ˆçƒé¢æ€§ã®ç¨‹åº¦ï¼‰
                    # Greenhouse-Geisser epsilon
                    eigenvals = la.eigvals(S_transformed)
                    epsilon_gg = (np.sum(eigenvals)**2) / ((p-1) * np.sum(eigenvals**2))
                    
                    # Huynh-Feldt epsilon  
                    epsilon_hf = min(1.0, (n * epsilon_gg - 2) / ((p-1) * (n - 1 - (p-1) * epsilon_gg)))
                    
                    # çµæœè¡¨ç¤º
                    result_text = f"""
ğŸŒ çƒé¢æ€§æ¤œå®šçµæœ (Mauchly's Sphericity Test)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š è§£æè¨­å®š:
å¤‰æ•°æ•°: {p}
ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º: {n}
é¸æŠå¤‰æ•°: {', '.join(selected_cols)}

ğŸ”¬ çƒé¢æ€§æ¤œå®šçµæœ:
Mauchly's W = {W:.6f}
ã‚«ã‚¤äºŒä¹—çµ±è¨ˆé‡ = {chi2_stat:.4f}
è‡ªç”±åº¦ = {int(df)}
på€¤ = {p_value:.6f}

âœ… çµè«– (Î± = 0.05):
çƒé¢æ€§ã®ä»®å®š: {'æ£„å´' if p_value < 0.05 else 'æ¡æŠ'}
â†’ {'çƒé¢æ€§ã®ä»®å®šã¯æº€ãŸã•ã‚Œã¦ã„ã¾ã›ã‚“' if p_value < 0.05 else 'çƒé¢æ€§ã®ä»®å®šãŒæº€ãŸã•ã‚Œã¦ã„ã¾ã™'}

ğŸ“Š è£œæ­£ä¿‚æ•°ï¼ˆÎµï¼‰:
Greenhouse-Geisser Îµ = {epsilon_gg:.4f}
Huynh-Feldt Îµ = {epsilon_hf:.4f}

ğŸ’¡ æ¨å¥¨äº‹é …:
{'çƒé¢æ€§ã®ä»®å®šãŒæ£„å´ã•ã‚ŒãŸãŸã‚ã€Greenhouse-Geisserã¾ãŸã¯Huynh-Feldtè£œæ­£ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚' if p_value < 0.05 else 'çƒé¢æ€§ã®ä»®å®šãŒæº€ãŸã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€é€šå¸¸ã®åå¾©æ¸¬å®šANOVAã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚'}

ğŸ“ˆ å…±åˆ†æ•£è¡Œåˆ—ã®è©³ç´°:
å¯¾è§’ç·šè¦ç´ ã®å¹³å‡: {np.mean(np.diag(cov_matrix)):.4f}
éå¯¾è§’ç·šè¦ç´ ã®å¹³å‡: {np.mean(cov_matrix[np.triu_indices_from(cov_matrix, k=1)]):.4f}
                    """
                    
                    self.result_text.delete("1.0", "end")
                    self.result_text.insert("1.0", result_text)
                    
                    # çµæœä¿å­˜
                    self.analysis_results['sphericity_test'] = {
                        'variables': selected_cols,
                        'mauchly_W': W,
                        'chi2_statistic': chi2_stat,
                        'p_value': p_value,
                        'epsilon_gg': epsilon_gg,
                        'epsilon_hf': epsilon_hf,
                        'sphericity_assumption': 'rejected' if p_value < 0.05 else 'accepted'
                    }
                    
                    self._update_status("çƒé¢æ€§æ¤œå®šå®Œäº†")
                    
                except Exception as calc_error:
                    messagebox.showerror("Error", f"çƒé¢æ€§æ¤œå®šè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {calc_error}")
            
            ctk.CTkButton(dialog, text="å®Ÿè¡Œ", command=run_test).pack(pady=20)
            
        except Exception as e:
            messagebox.showerror("Error", f"çƒé¢æ€§æ¤œå®šã‚¨ãƒ©ãƒ¼: {e}")
    
    def regression_analysis(self):
        """å›å¸°åˆ†æ"""
        messagebox.showinfo("Info", "Regression analysis feature coming soon!")
    
    def machine_learning(self):
        """é«˜åº¦ãªæ©Ÿæ¢°å­¦ç¿’åˆ†æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        # å¤‰æ•°é¸æŠæƒ…å ±ã‚’æº–å‚™
        variable_selection = {
            'control_variables': self.control_variables,
            'target_variables': self.target_variables,
            'residual_variables': self.residual_variables,
            'applied': self.variable_selection_applied
        }
        
        # æ©Ÿæ¢°å­¦ç¿’ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹ã
        ml_window = MLAnalysisWindow(self.root, self.current_data, variable_selection)
        ml_window.show()
    
    def deep_learning(self):
        """æ·±å±¤å­¦ç¿’åˆ†æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        # å¤‰æ•°é¸æŠæƒ…å ±ã‚’æº–å‚™
        variable_selection = {
            'control_variables': self.control_variables,
            'target_variables': self.target_variables,
            'residual_variables': self.residual_variables,
            'applied': self.variable_selection_applied
        }
        
        # æ·±å±¤å­¦ç¿’ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹ã
        dl_window = DeepLearningWindow(self.root, self.current_data, variable_selection)
        dl_window.show()
    
    def data_quality_check(self):
        """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            self._update_status("Checking data quality...")
            
            # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆ
            total_cells = len(self.current_data) * len(self.current_data.columns)
            missing_cells = self.current_data.isnull().sum().sum()
            duplicate_rows = self.current_data.duplicated().sum()
            
            quality_report = f"""
ğŸ” DATA QUALITY REPORT
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Dataset Overview:
â€¢ Total rows: {len(self.current_data):,}
â€¢ Total columns: {len(self.current_data.columns)}
â€¢ Total cells: {total_cells:,}

Completeness:
â€¢ Missing cells: {missing_cells:,} ({missing_cells/total_cells*100:.2f}%)
â€¢ Complete rows: {len(self.current_data.dropna()):,}
â€¢ Duplicate rows: {duplicate_rows:,}

Column Details:
"""
            
            for col in self.current_data.columns:
                missing_pct = self.current_data[col].isnull().sum() / len(self.current_data) * 100
                unique_count = self.current_data[col].nunique()
                quality_report += f"â€¢ {col}: {missing_pct:.1f}% missing, {unique_count} unique values\n"
            
            self.result_text.delete("1.0", "end")
            self.result_text.insert("1.0", quality_report)
            
            self._update_status("Data quality check completed")
            
        except Exception as e:
            messagebox.showerror("Error", f"Quality check failed: {e}")
    
    def show_gpu_status(self):
        """GPUçŠ¶æ…‹è¡¨ç¤º"""
        gpu_info = f"""
âš¡ GPU INFORMATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

CUDA Available: {'âœ… Yes' if CUDA_AVAILABLE else 'âŒ No'}
GPU Device: {GPU_NAME}
"""
        
        if CUDA_AVAILABLE:
            gpu_info += f"""
GPU Memory:
â€¢ Total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB
â€¢ Allocated: {torch.cuda.memory_allocated() / 1024**3:.1f} GB
â€¢ Cached: {torch.cuda.memory_reserved() / 1024**3:.1f} GB

Compute Capability: {torch.cuda.get_device_properties(0).major}.{torch.cuda.get_device_properties(0).minor}
"""
        
        self.result_text.delete("1.0", "end")
        self.result_text.insert("1.0", gpu_info)
    
    def show_memory_usage(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¡¨ç¤º"""
        memory_info = f"""
ğŸ’¾ MEMORY INFORMATION
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Process Memory:
â€¢ RSS: {psutil.Process().memory_info().rss / 1024**2:.1f} MB
â€¢ VMS: {psutil.Process().memory_info().vms / 1024**2:.1f} MB

System Memory:
â€¢ Total: {psutil.virtual_memory().total / 1024**3:.1f} GB
â€¢ Available: {psutil.virtual_memory().available / 1024**3:.1f} GB
â€¢ Used: {psutil.virtual_memory().percent:.1f}%
"""
        
        self.result_text.delete("1.0", "end")
        self.result_text.insert("1.0", memory_info)
    
    def variable_selection(self):
        """å¤‰æ•°é¸æŠã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹ã"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        def on_variable_selection(result):
            """å¤‰æ•°é¸æŠçµæœã‚’å‡¦ç†"""
            self.control_variables = result['control_variables']
            self.target_variables = result['target_variables']
            self.residual_variables = result['residual_variables']
            self.variable_selection_applied = True
            
            # ãƒ‡ãƒ¼ã‚¿æƒ…å ±æ›´æ–°
            self._update_data_info()
            
            # çµæœè¡¨ç¤º
            summary = f"""
ğŸ¯ Variable Selection Applied
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š Control Variables ({len(self.control_variables)}):
{', '.join(self.control_variables) if self.control_variables else 'None'}

ğŸ¯ Target Variables ({len(self.target_variables)}):
{', '.join(self.target_variables) if self.target_variables else 'None'}

ğŸ“¦ Residual Variables ({len(self.residual_variables)}):
{', '.join(self.residual_variables) if self.residual_variables else 'None'}

âœ… Variable selection has been applied successfully!
Use these selections in subsequent analyses (ML, regression, etc.)
            """
            
            self.result_text.delete("1.0", "end")
            self.result_text.insert("1.0", summary)
            self._update_status("Variable selection applied")
        
        # å¤‰æ•°é¸æŠã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹ã
        var_window = VariableSelectionWindow(self.root, self.current_data, on_variable_selection)
        var_window.show()
    
    def generate_professional_report(self):
        """ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not PROFESSIONAL_FEATURES_AVAILABLE:
            messagebox.showerror("Error", "ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        if self.current_data is None:
            messagebox.showerror("Error", "ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        try:
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            progress_window = ctk.CTkToplevel(self.root)
            progress_window.title("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
            progress_window.geometry("400x150")
            progress_window.transient(self.root)
            progress_window.grab_set()
            
            progress_label = ctk.CTkLabel(progress_window, text="ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
            progress_label.pack(pady=20)
            
            progress_bar = ctk.CTkProgressBar(progress_window)
            progress_bar.pack(pady=20, padx=40, fill="x")
            progress_bar.set(0)
            
            def generate_report():
                try:
                    progress_bar.set(0.2)
                    progress_window.update()
                    
                    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                    report_file = report_generator.generate_comprehensive_report(
                        data=self.current_data,
                        analysis_results=self.analysis_results,
                        title="HAD Professional Statistical Analysis Report",
                        subtitle=f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                    )
                    
                    progress_bar.set(1.0)
                    progress_window.update()
                    
                    progress_window.destroy()
                    
                    # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    result = messagebox.askyesno(
                        "ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†", 
                        f"ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ:\n{report_file}\n\nãƒ¬ãƒãƒ¼ãƒˆã‚’é–‹ãã¾ã™ã‹ï¼Ÿ"
                    )
                    
                    if result:
                        import webbrowser
                        webbrowser.open(f"file://{Path(report_file).absolute()}")
                    
                    # ãƒ­ã‚°è¨˜éŒ²
                    if PROFESSIONAL_FEATURES_AVAILABLE:
                        professional_logger.info("ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†", 
                                                file_path=report_file,
                                                data_shape=self.current_data.shape)
                
                except Exception as e:
                    progress_window.destroy()
                    messagebox.showerror("Error", f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼:\n{str(e)}")
                    if PROFESSIONAL_FEATURES_AVAILABLE:
                        professional_logger.error("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå¤±æ•—", exception=e)
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
            import threading
            thread = threading.Thread(target=generate_report)
            thread.daemon = True
            thread.start()
        
        except Exception as e:
            messagebox.showerror("Error", f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼:\n{str(e)}")
    
    def show_performance_report(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º"""
        if not PROFESSIONAL_FEATURES_AVAILABLE:
            messagebox.showerror("Error", "ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        try:
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆå–å¾—
            perf_report = performance_monitor.get_performance_report()
            
            # ãƒ¬ãƒãƒ¼ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
            report_window = ctk.CTkToplevel(self.root)
            report_window.title("ğŸ“Š Performance Report")
            report_window.geometry("800x600")
            report_window.transient(self.root)
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹
            text_widget = ctk.CTkTextbox(report_window, font=("Consolas", 11))
            text_widget.pack(fill="both", expand=True, padx=10, pady=10)
            
            # ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ç”Ÿæˆ
            report_content = "ğŸš€ HAD Professional Performance Report\n"
            report_content += "=" * 60 + "\n\n"
            report_content += f"ğŸ“… Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            report_content += f"ğŸ’¾ Session ID: {self.session_manager.session_id}\n\n"
            
            if perf_report:
                report_content += "ğŸ“Š Function Performance Metrics:\n"
                report_content += "-" * 40 + "\n"
                
                for func_name, metrics in perf_report.items():
                    report_content += f"\nğŸ”§ {func_name}:\n"
                    report_content += f"   â€¢ Call Count: {metrics['call_count']}\n"
                    report_content += f"   â€¢ Success Rate: {metrics['success_rate']:.2%}\n"
                    report_content += f"   â€¢ Avg Duration: {metrics['avg_duration']:.4f}s\n"
                    report_content += f"   â€¢ Max Duration: {metrics['max_duration']:.4f}s\n"
                    report_content += f"   â€¢ Min Duration: {metrics['min_duration']:.4f}s\n"
                    report_content += f"   â€¢ Avg Memory: {metrics['avg_memory_diff']:.2f}MB\n"
            else:
                report_content += "â„¹ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒã¾ã åé›†ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
                report_content += "ã„ãã¤ã‹ã®è§£æã‚’å®Ÿè¡Œã—ã¦ã‹ã‚‰å†åº¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
            
            # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
            report_content += "\n" + "=" * 60 + "\n"
            report_content += "ğŸ–¥ï¸ System Information:\n"
            report_content += f"   â€¢ Python: {sys.version.split()[0]}\n"
            report_content += f"   â€¢ CUDA Available: {CUDA_AVAILABLE}\n"
            report_content += f"   â€¢ GPU: {GPU_NAME}\n"
            
            try:
                import psutil
                memory_info = psutil.virtual_memory()
                report_content += f"   â€¢ Total Memory: {memory_info.total / 1024**3:.1f} GB\n"
                report_content += f"   â€¢ Available Memory: {memory_info.available / 1024**3:.1f} GB\n"
                report_content += f"   â€¢ Memory Usage: {memory_info.percent}%\n"
                report_content += f"   â€¢ CPU Count: {psutil.cpu_count()}\n"
            except:
                pass
            
            text_widget.insert("1.0", report_content)
            
            # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒœã‚¿ãƒ³
            export_btn = ctk.CTkButton(
                report_window,
                text="ğŸ“„ Export Report",
                command=lambda: self._export_performance_report(report_content)
            )
            export_btn.pack(pady=10)
        
        except Exception as e:
            messagebox.showerror("Error", f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼:\n{str(e)}")
    
    def _export_performance_report(self, content):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        try:
            file_path = filedialog.asksaveasfilename(
                defaultextension=".txt",
                filetypes=[("Text files", "*.txt"), ("All files", "*.*")]
            )
            if file_path:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                messagebox.showinfo("Success", f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã—ã¾ã—ãŸ:\n{file_path}")
        except Exception as e:
            messagebox.showerror("Error", f"ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼:\n{str(e)}")

    def ai_analysis(self):
        """AIçµ±è¨ˆåˆ†æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        # AIåˆ†æã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹ã
        ai_window = AIAnalysisWindow(self.root, self.current_data)
        ai_window.show()
    
    def save_session(self):
        """æ‰‹å‹•ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜"""
        try:
            saved_file = self.session_manager.save_session()
            messagebox.showinfo("Success", f"Session saved: {saved_file.name}")
        except Exception as e:
            messagebox.showerror("Error", f"Failed to save session: {e}")
    
    # ==================== æ–°æ©Ÿèƒ½å®Ÿè£… ====================
    
    def visualization_menu(self):
        """å¯è¦–åŒ–ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒ€ã‚¤ã‚¢ãƒ­ã‚°"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        viz_window = ctk.CTkToplevel(self.root)
        viz_window.title("ğŸ“Š Visualization Menu")
        viz_window.geometry("400x500")
        viz_window.transient(self.root)
        viz_window.grab_set()
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        title_label = ctk.CTkLabel(viz_window, text="ğŸ“Š å¯è¦–åŒ–ãƒ¡ãƒ‹ãƒ¥ãƒ¼", font=("Arial", 18, "bold"))
        title_label.pack(pady=20)
        
        # ãƒœã‚¿ãƒ³é…ç½®
        buttons = [
            ("ğŸ“Š ç›¸é–¢è¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", self.create_correlation_heatmap),
            ("ğŸ” æ•£å¸ƒå›³ãƒãƒˆãƒªãƒƒã‚¯ã‚¹", self.create_scatter_matrix),
            ("ğŸ“ˆ åˆ†å¸ƒãƒ—ãƒ­ãƒƒãƒˆ", self.create_distribution_plots),
            ("ğŸ“¦ ç®±ã²ã’å›³", self.create_box_plots),
            ("â° æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ", self.create_time_series_plot),
            ("ğŸ¯ ç‰¹å¾´é‡é‡è¦åº¦", self.create_feature_importance_plot),
            ("ğŸ“Š ROCæ›²ç·š", self.create_roc_curve),
        ]
        
        for text, command in buttons:
            btn = ctk.CTkButton(viz_window, text=text, command=lambda cmd=command: [viz_window.destroy(), cmd()], width=300, height=40)
            btn.pack(pady=5)
    
    def preprocessing_menu(self):
        """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒ€ã‚¤ã‚¢ãƒ­ã‚°"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        prep_window = ctk.CTkToplevel(self.root)
        prep_window.title("âš™ï¸ Data Processing Menu")
        prep_window.geometry("400x500")
        prep_window.transient(self.root)
        prep_window.grab_set()
        
        # ã‚¿ã‚¤ãƒˆãƒ«
        title_label = ctk.CTkLabel(prep_window, text="âš™ï¸ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¡ãƒ‹ãƒ¥ãƒ¼", font=("Arial", 18, "bold"))
        title_label.pack(pady=20)
        
        # ãƒœã‚¿ãƒ³é…ç½®
        buttons = [
            ("ğŸ” å¤–ã‚Œå€¤æ¤œå‡º", self.detect_outliers),
            ("ğŸ—‘ï¸ å¤–ã‚Œå€¤é™¤å»", self.remove_outliers),
            ("ğŸ’Š æ¬ æå€¤å‡¦ç†", self.handle_missing_values),
            ("âš™ï¸ ãƒ‡ãƒ¼ã‚¿å¤‰æ›", self.transform_data),
            ("ğŸ”§ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°", self.feature_engineering),
            ("ğŸ¯ ç‰¹å¾´é‡é¸æŠ", self.feature_selection),
        ]
        
        for text, command in buttons:
            btn = ctk.CTkButton(prep_window, text=text, command=lambda cmd=command: [prep_window.destroy(), cmd()], width=300, height=40)
            btn.pack(pady=10)
    
    # å¯è¦–åŒ–æ©Ÿèƒ½ãƒ¡ã‚½ãƒƒãƒ‰
    def create_correlation_heatmap(self):
        """ç›¸é–¢è¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            fig, message = self.visualizer.correlation_heatmap(self.current_data)
            if fig:
                plt.show()
                self.result_text.delete("1.0", "end")
                self.result_text.insert("1.0", f"âœ… {message}")
            else:
                messagebox.showerror("Error", message)
        except Exception as e:
            messagebox.showerror("Error", f"ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def create_scatter_matrix(self):
        """æ•£å¸ƒå›³ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ä½œæˆ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            target_col = self._get_column_selection("Target column (optional):", allow_none=True)
            
            fig, message = self.visualizer.scatter_matrix(self.current_data, target_col)
            if fig:
                # Plotlyã®å ´åˆã¯ãƒ–ãƒ©ã‚¦ã‚¶ã§è¡¨ç¤º
                fig.show()
                self.result_text.delete("1.0", "end")
                self.result_text.insert("1.0", f"âœ… {message}")
            else:
                messagebox.showerror("Error", message)
        except Exception as e:
            messagebox.showerror("Error", f"æ•£å¸ƒå›³ãƒãƒˆãƒªãƒƒã‚¯ã‚¹ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def create_distribution_plots(self):
        """åˆ†å¸ƒãƒ—ãƒ­ãƒƒãƒˆä½œæˆ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            fig, message = self.visualizer.distribution_plots(self.current_data)
            if fig:
                plt.show()
                self.result_text.delete("1.0", "end")
                self.result_text.insert("1.0", f"âœ… {message}")
            else:
                messagebox.showerror("Error", message)
        except Exception as e:
            messagebox.showerror("Error", f"åˆ†å¸ƒãƒ—ãƒ­ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def create_box_plots(self):
        """ç®±ã²ã’å›³ä½œæˆ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            # ã‚«ãƒ†ã‚´ãƒªåˆ—ã¨æ•°å€¤åˆ—ã®é¸æŠ
            categorical_col = self._get_column_selection("Categorical column:", 
                                                        self.current_data.select_dtypes(include=['object']).columns.tolist())
            numerical_col = self._get_column_selection("Numerical column:", 
                                                      self.current_data.select_dtypes(include=[np.number]).columns.tolist())
            
            if categorical_col and numerical_col:
                fig, message = self.visualizer.boxplot_comparison(self.current_data, categorical_col, numerical_col)
                if fig:
                    plt.show()
                    self.result_text.delete("1.0", "end")
                    self.result_text.insert("1.0", f"âœ… {message}")
                else:
                    messagebox.showerror("Error", message)
        except Exception as e:
            messagebox.showerror("Error", f"ç®±ã²ã’å›³ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def create_time_series_plot(self):
        """æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            # æ—¥ä»˜åˆ—ã®é¸æŠ
            date_col = self._get_column_selection("Date column:", list(self.current_data.columns))
            # å€¤åˆ—ã®é¸æŠ
            value_col = self._get_column_selection("Value column:", 
                                                  self.current_data.select_dtypes(include=[np.number]).columns.tolist())
            
            if date_col and value_col:
                fig, message = self.visualizer.time_series_plot(self.current_data, date_col, value_col)
                if fig:
                    fig.show()
                    self.result_text.delete("1.0", "end")
                    self.result_text.insert("1.0", f"âœ… {message}")
                else:
                    messagebox.showerror("Error", message)
        except Exception as e:
            messagebox.showerror("Error", f"æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def create_feature_importance_plot(self):
        """ç‰¹å¾´é‡é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ"""
        # MLåˆ†æçµæœã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
        if not self.analysis_results.get('feature_importance'):
            messagebox.showwarning("Warning", "æ©Ÿæ¢°å­¦ç¿’è§£æã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        try:
            importance_dict = self.analysis_results['feature_importance']
            fig, message = self.visualizer.feature_importance_plot(importance_dict)
            if fig:
                plt.show()
                self.result_text.delete("1.0", "end")
                self.result_text.insert("1.0", f"âœ… {message}")
            else:
                messagebox.showerror("Error", message)
        except Exception as e:
            messagebox.showerror("Error", f"ç‰¹å¾´é‡é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def create_roc_curve(self):
        """ROCæ›²ç·šä½œæˆ"""
        messagebox.showinfo("Info", "ROCæ›²ç·šã¯æ©Ÿæ¢°å­¦ç¿’ã®åˆ†é¡ã‚¿ã‚¹ã‚¯å®Ÿè¡Œå¾Œã«åˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã™")
    
    # ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ©Ÿèƒ½ãƒ¡ã‚½ãƒƒãƒ‰
    def detect_outliers(self):
        """å¤–ã‚Œå€¤æ¤œå‡º"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            results = self.preprocessor.detect_outliers(self.current_data)
            
            if results["success"]:
                # çµæœè¡¨ç¤º
                result_text = "\nğŸ” å¤–ã‚Œå€¤æ¤œå‡ºçµæœ\n"
                result_text += "=" * 50 + "\n\n"
                
                for column, outlier_info in results["detailed_results"].items():
                    result_text += f"ğŸ“Š {column}:\n"
                    for method, count in outlier_info["outlier_counts"].items():
                        percentage = outlier_info["outlier_percentages"][method]
                        result_text += f"  â€¢ {method}: {count}å€‹ ({percentage:.1f}%)\n"
                    result_text += "\n"
                
                # åˆæ„å¤–ã‚Œå€¤
                result_text += "ğŸ¯ åˆæ„å¤–ã‚Œå€¤ (è¤‡æ•°æ‰‹æ³•ã§æ¤œå‡º):\n"
                for column, consensus in results["consensus_outliers"].items():
                    if consensus["agreement_count"] > 0:
                        result_text += f"  â€¢ {column}: {consensus['agreement_count']}å€‹\n"
                
                self.result_text.delete("1.0", "end")
                self.result_text.insert("1.0", result_text)
                
                # å¤–ã‚Œå€¤æ¤œå‡ºçµæœã‚’ä¿å­˜
                self.analysis_results['outlier_detection'] = results
                
            else:
                messagebox.showerror("Error", results["error"])
                
        except Exception as e:
            messagebox.showerror("Error", f"å¤–ã‚Œå€¤æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def remove_outliers(self):
        """å¤–ã‚Œå€¤é™¤å»"""
        if 'outlier_detection' not in self.analysis_results:
            messagebox.showwarning("Warning", "å…ˆã«å¤–ã‚Œå€¤æ¤œå‡ºã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        try:
            # é™¤å»æ–¹æ³•é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            method = self._get_outlier_removal_method()
            if not method:
                return
            
            cleaned_data, summary = self.preprocessor.remove_outliers(
                self.current_data, 
                self.analysis_results['outlier_detection'], 
                method=method
            )
            
            if summary["success"]:
                # ãƒ‡ãƒ¼ã‚¿æ›´æ–°ç¢ºèª
                result = messagebox.askyesno(
                    "å¤–ã‚Œå€¤é™¤å»ç¢ºèª",
                    f"å¤–ã‚Œå€¤ã‚’é™¤å»ã—ã¾ã™ã‹ï¼Ÿ\n\n"
                    f"é™¤å»äºˆå®š: {summary['removed_count']}è¡Œ ({summary['removal_percentage']:.1f}%)\n"
                    f"å…ƒã®ã‚µã‚¤ã‚º: {summary['original_shape']}\n"
                    f"é™¤å»å¾Œã‚µã‚¤ã‚º: {summary['cleaned_shape']}"
                )
                
                if result:
                    self.current_data = cleaned_data
                    self._update_data_info()
                    self.result_text.delete("1.0", "end")
                    self.result_text.insert("1.0", f"âœ… å¤–ã‚Œå€¤é™¤å»å®Œäº†\né™¤å»ã•ã‚ŒãŸè¡Œæ•°: {summary['removed_count']}")
            else:
                messagebox.showerror("Error", summary["error"])
                
        except Exception as e:
            messagebox.showerror("Error", f"å¤–ã‚Œå€¤é™¤å»ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def handle_missing_values(self):
        """æ¬ æå€¤å‡¦ç†"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            # æ¬ æå€¤å‡¦ç†æ–¹æ³•é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            method = self._get_missing_value_method()
            if not method:
                return
            
            imputed_data, summary = self.preprocessor.handle_missing_values(
                self.current_data, method=method
            )
            
            if summary["success"]:
                if "message" in summary:
                    messagebox.showinfo("Info", summary["message"])
                    return
                
                # ãƒ‡ãƒ¼ã‚¿æ›´æ–°ç¢ºèª
                orig_missing = summary["original_missing"]["total_missing"]
                final_missing = summary["final_missing"]["total_missing"]
                
                result = messagebox.askyesno(
                    "æ¬ æå€¤å‡¦ç†ç¢ºèª",
                    f"æ¬ æå€¤ã‚’å‡¦ç†ã—ã¾ã™ã‹ï¼Ÿ\n\n"
                    f"å‡¦ç†å‰ã®æ¬ æå€¤: {orig_missing}å€‹\n"
                    f"å‡¦ç†å¾Œã®æ¬ æå€¤: {final_missing}å€‹\n"
                    f"å‡¦ç†ã•ã‚ŒãŸæ¬ æå€¤: {orig_missing - final_missing}å€‹"
                )
                
                if result:
                    self.current_data = imputed_data
                    self._update_data_info()
                    self.result_text.delete("1.0", "end")
                    self.result_text.insert("1.0", f"âœ… æ¬ æå€¤å‡¦ç†å®Œäº†\nå‡¦ç†æ–¹æ³•: {method}")
            else:
                messagebox.showerror("Error", summary["error"])
                
        except Exception as e:
            messagebox.showerror("Error", f"æ¬ æå€¤å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def transform_data(self):
        """ãƒ‡ãƒ¼ã‚¿å¤‰æ›"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            # å¤‰æ›æ–¹æ³•é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            transformations = self._get_transformation_methods()
            if not transformations:
                return
            
            transformed_data, summary = self.preprocessor.transform_data(
                self.current_data, transformations=transformations
            )
            
            if summary["success"]:
                # ãƒ‡ãƒ¼ã‚¿æ›´æ–°ç¢ºèª
                result = messagebox.askyesno(
                    "ãƒ‡ãƒ¼ã‚¿å¤‰æ›ç¢ºèª",
                    f"ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›ã—ã¾ã™ã‹ï¼Ÿ\n\n"
                    f"é©ç”¨ã•ã‚Œã‚‹å¤‰æ›: {', '.join(transformations)}\n"
                    f"å…ƒã®ã‚µã‚¤ã‚º: {summary['original_shape']}\n"
                    f"å¤‰æ›å¾Œã‚µã‚¤ã‚º: {summary['transformed_shape']}"
                )
                
                if result:
                    self.current_data = transformed_data
                    self._update_data_info()
                    self.result_text.delete("1.0", "end")
                    self.result_text.insert("1.0", f"âœ… ãƒ‡ãƒ¼ã‚¿å¤‰æ›å®Œäº†\né©ç”¨å¤‰æ›: {', '.join(transformations)}")
            else:
                messagebox.showerror("Error", summary["error"])
                
        except Exception as e:
            messagebox.showerror("Error", f"ãƒ‡ãƒ¼ã‚¿å¤‰æ›ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def feature_engineering(self):
        """ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—é¸æŠ
            target_col = self._get_column_selection("Target column (optional):", allow_none=True)
            
            # ç‰¹å¾´é‡ç”Ÿæˆæ–¹æ³•é¸æŠ
            methods = self._get_feature_engineering_methods()
            if not methods:
                return
            
            engineered_data, summary = self.preprocessor.feature_engineering(
                self.current_data, target_col=target_col, methods=methods
            )
            
            if summary["success"]:
                # ãƒ‡ãƒ¼ã‚¿æ›´æ–°ç¢ºèª
                result = messagebox.askyesno(
                    "ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ç¢ºèª",
                    f"æ–°ã—ã„ç‰¹å¾´é‡ã‚’ä½œæˆã—ã¾ã™ã‹ï¼Ÿ\n\n"
                    f"å…ƒã®ç‰¹å¾´é‡æ•°: {summary['original_features']}\n"
                    f"æ–°è¦ç‰¹å¾´é‡æ•°: {summary['new_features_count']}\n"
                    f"ç·ç‰¹å¾´é‡æ•°: {summary['total_features']}"
                )
                
                if result:
                    self.current_data = engineered_data
                    self._update_data_info()
                    
                    result_text = f"âœ… ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†\n"
                    result_text += f"æ–°è¦ç‰¹å¾´é‡: {summary['new_features_count']}å€‹\n\n"
                    result_text += "ä½œæˆã•ã‚ŒãŸç‰¹å¾´é‡:\n"
                    for feature in summary['new_feature_names'][:10]:  # æœ€åˆã®10å€‹ã‚’è¡¨ç¤º
                        result_text += f"â€¢ {feature}\n"
                    
                    self.result_text.delete("1.0", "end")
                    self.result_text.insert("1.0", result_text)
            else:
                messagebox.showerror("Error", summary["error"])
                
        except Exception as e:
            messagebox.showerror("Error", f"ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    def feature_selection(self):
        """ç‰¹å¾´é‡é¸æŠ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first")
            return
        
        try:
            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—é¸æŠ
            target_col = self._get_column_selection("Target column:", list(self.current_data.columns))
            if not target_col:
                return
            
            # é¸æŠã™ã‚‹ç‰¹å¾´é‡æ•°
            k = self._get_number_input("Number of features to select:", default=10, min_val=1, max_val=len(self.current_data.columns)-1)
            if k is None:
                return
            
            selected_data, summary = self.preprocessor.feature_selection(
                self.current_data, target_col=target_col, k=k
            )
            
            if summary["success"]:
                # ãƒ‡ãƒ¼ã‚¿æ›´æ–°ç¢ºèª
                result = messagebox.askyesno(
                    "ç‰¹å¾´é‡é¸æŠç¢ºèª",
                    f"é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ›´æ–°ã—ã¾ã™ã‹ï¼Ÿ\n\n"
                    f"å…ƒã®ç‰¹å¾´é‡æ•°: {summary['original_features']}\n"
                    f"é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡æ•°: {summary['selected_features']}\n"
                    f"ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—: {summary['target_column']}"
                )
                
                if result:
                    self.current_data = selected_data
                    self._update_data_info()
                    
                    result_text = f"âœ… ç‰¹å¾´é‡é¸æŠå®Œäº†\n"
                    result_text += f"é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡: {summary['selected_features']}å€‹\n\n"
                    result_text += "é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡:\n"
                    for feature in summary['selected_feature_names']:
                        result_text += f"â€¢ {feature}\n"
                    
                    self.result_text.delete("1.0", "end")
                    self.result_text.insert("1.0", result_text)
            else:
                messagebox.showerror("Error", summary["error"])
                
        except Exception as e:
            messagebox.showerror("Error", f"ç‰¹å¾´é‡é¸æŠã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    # ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰
    def _get_column_selection(self, title, columns=None, allow_none=False):
        """åˆ—é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°"""
        if columns is None:
            columns = list(self.current_data.columns)
        
        if not columns:
            messagebox.showwarning("Warning", "é¸æŠå¯èƒ½ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“")
            return None
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªé¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
        dialog = ctk.CTkToplevel(self.root)
        dialog.title(title)
        dialog.geometry("300x400")
        dialog.transient(self.root)
        dialog.grab_set()
        
        selected_value = tk.StringVar()
        
        ctk.CTkLabel(dialog, text=title).pack(pady=10)
        
        listbox = tk.Listbox(dialog, height=15)
        listbox.pack(fill="both", expand=True, padx=10, pady=10)
        
        for col in columns:
            listbox.insert(tk.END, col)
        
        def on_select():
            selection = listbox.curselection()
            if selection:
                selected_value.set(columns[selection[0]])
            elif allow_none:
                selected_value.set("")
            dialog.destroy()
        
        def on_cancel():
            selected_value.set("")
            dialog.destroy()
        
        btn_frame = ctk.CTkFrame(dialog)
        btn_frame.pack(fill="x", padx=10, pady=10)
        
        ctk.CTkButton(btn_frame, text="Select", command=on_select).pack(side="left", padx=5)
        ctk.CTkButton(btn_frame, text="Cancel", command=on_cancel).pack(side="right", padx=5)
        
        if allow_none:
            ctk.CTkButton(btn_frame, text="None", command=lambda: [selected_value.set(""), dialog.destroy()]).pack(side="left", padx=5)
        
        dialog.wait_window()
        return selected_value.get() if selected_value.get() else None
    
    def _get_outlier_removal_method(self):
        """å¤–ã‚Œå€¤é™¤å»æ–¹æ³•é¸æŠ"""
        methods = ['consensus', 'iqr', 'zscore', 'isolation']
        return self._get_single_choice("å¤–ã‚Œå€¤é™¤å»æ–¹æ³•ã‚’é¸æŠ:", methods)
    
    def _get_missing_value_method(self):
        """æ¬ æå€¤å‡¦ç†æ–¹æ³•é¸æŠ"""
        methods = ['auto', 'simple', 'knn']
        return self._get_single_choice("æ¬ æå€¤å‡¦ç†æ–¹æ³•ã‚’é¸æŠ:", methods)
    
    def _get_transformation_methods(self):
        """ãƒ‡ãƒ¼ã‚¿å¤‰æ›æ–¹æ³•é¸æŠ"""
        methods = ['standard', 'minmax', 'robust', 'log', 'sqrt', 'yeo_johnson']
        return self._get_multiple_choice("ãƒ‡ãƒ¼ã‚¿å¤‰æ›æ–¹æ³•ã‚’é¸æŠ:", methods)
    
    def _get_feature_engineering_methods(self):
        """ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ–¹æ³•é¸æŠ"""
        methods = ['polynomial', 'interaction', 'binning', 'statistical']
        return self._get_multiple_choice("ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ–¹æ³•ã‚’é¸æŠ:", methods)
    
    def _get_single_choice(self, title, choices):
        """å˜ä¸€é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°"""
        dialog = ctk.CTkToplevel(self.root)
        dialog.title(title)
        dialog.geometry("300x300")
        dialog.transient(self.root)
        dialog.grab_set()
        
        selected_value = tk.StringVar()
        
        ctk.CTkLabel(dialog, text=title).pack(pady=10)
        
        for choice in choices:
            ctk.CTkRadioButton(dialog, text=choice, variable=selected_value, value=choice).pack(pady=5)
        
        selected_value.set(choices[0])  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé¸æŠ
        
        def on_ok():
            dialog.destroy()
        
        ctk.CTkButton(dialog, text="OK", command=on_ok).pack(pady=20)
        
        dialog.wait_window()
        return selected_value.get()
    
    def _get_multiple_choice(self, title, choices):
        """è¤‡æ•°é¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°"""
        dialog = ctk.CTkToplevel(self.root)
        dialog.title(title)
        dialog.geometry("300x400")
        dialog.transient(self.root)
        dialog.grab_set()
        
        selected_choices = []
        check_vars = {}
        
        ctk.CTkLabel(dialog, text=title).pack(pady=10)
        
        for choice in choices:
            var = tk.BooleanVar()
            check_vars[choice] = var
            ctk.CTkCheckBox(dialog, text=choice, variable=var).pack(pady=5)
        
        def on_ok():
            nonlocal selected_choices
            selected_choices = [choice for choice, var in check_vars.items() if var.get()]
            dialog.destroy()
        
        ctk.CTkButton(dialog, text="OK", command=on_ok).pack(pady=20)
        
        dialog.wait_window()
        return selected_choices
    
    def _get_number_input(self, title, default=10, min_val=1, max_val=100):
        """æ•°å€¤å…¥åŠ›ãƒ€ã‚¤ã‚¢ãƒ­ã‚°"""
        result = tk.simpledialog.askinteger(title, title, initialvalue=default, minvalue=min_val, maxvalue=max_val)
        return result
    
    def _open_ml_dialog(self):
        """æ©Ÿæ¢°å­¦ç¿’ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’é–‹ã"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return
        
        # æ©Ÿæ¢°å­¦ç¿’ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã®å®Ÿè£…ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        ml_window = tk.Toplevel(self.root)
        ml_window.title("æ©Ÿæ¢°å­¦ç¿’è§£æ")
        ml_window.geometry("600x400")
        
        # æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•é¸æŠ
        ttk.Label(ml_window, text="æ©Ÿæ¢°å­¦ç¿’æ‰‹æ³•:").pack(pady=5)
        ml_method = ttk.Combobox(ml_window, values=[
            "Random Forest", "XGBoost", "LightGBM", 
            "SVM", "Logistic Regression", "Linear Regression"
        ])
        ml_method.pack(pady=5)
        ml_method.set("Random Forest")
        
        # å®Ÿè¡Œãƒœã‚¿ãƒ³
        def run_ml():
            method = ml_method.get()
            messagebox.showinfo("Info", f"{method}ã‚’å®Ÿè¡Œã—ã¾ã™ï¼ˆå®Ÿè£…äºˆå®šï¼‰")
        
        ttk.Button(ml_window, text="å®Ÿè¡Œ", command=run_ml).pack(pady=10)
    
    def _open_dl_dialog(self):
        """æ·±å±¤å­¦ç¿’ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’é–‹ã"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return
        
        # æ·±å±¤å­¦ç¿’ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã®å®Ÿè£…ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        # å¤‰æ•°é¸æŠæƒ…å ±ã‚’æº–å‚™
        variable_selection = {
            'control_variables': self.control_variables,
            'target_variables': self.target_variables,
            'residual_variables': self.residual_variables,
            'applied': self.variable_selection_applied
        }
        
        # æ·±å±¤å­¦ç¿’ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹ã
        dl_window = DeepLearningWindow(self.root, self.current_data, variable_selection)
        dl_window.show()
    
    # ==================== é«˜åº¦çµ±è¨ˆè§£æãƒ¡ã‚½ãƒƒãƒ‰ ====================
    
    def multivariate_analysis(self):
        """å¤šå¤‰é‡è§£æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first!")
            return
        
        if not self.advanced_features or not self.advanced_analyzer:
            messagebox.showwarning("Warning", "Advanced features not available!")
            return
        
        try:
            self._update_status("ğŸ”¬ å®Ÿè¡Œä¸­: å¤šå¤‰é‡è§£æ...")
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ä½œæˆ
            progress_window = tk.Toplevel(self.root)
            progress_window.title("å¤šå¤‰é‡è§£æå®Ÿè¡Œä¸­")
            progress_window.geometry("400x150")
            progress_window.transient(self.root)
            progress_window.grab_set()
            
            progress_label = ctk.CTkLabel(progress_window, text="å¤šå¤‰é‡è§£æã‚’å®Ÿè¡Œä¸­ã§ã™...")
            progress_label.pack(pady=20)
            
            progress_bar = ctk.CTkProgressBar(progress_window)
            progress_bar.pack(pady=10, padx=20, fill="x")
            progress_bar.set(0)
            
            def run_analysis():
                try:
                    # ãƒ‡ãƒ¼ã‚¿æœ€é©åŒ–
                    progress_bar.set(0.2)
                    progress_window.update()
                    optimized_data = self.parallel_processor.optimize_dataframe_operations(self.current_data)
                    
                    # å¤šå¤‰é‡è§£æå®Ÿè¡Œ
                    progress_bar.set(0.5)
                    progress_window.update()
                    results = self.advanced_analyzer.multivariate_analysis(optimized_data)
                    
                    # çµæœè¡¨ç¤º
                    progress_bar.set(1.0)
                    progress_window.update()
                    
                    # çµæœã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ä½œæˆ
                    result_window = tk.Toplevel(self.root)
                    result_window.title("ğŸ”¬ å¤šå¤‰é‡è§£æçµæœ")
                    result_window.geometry("1000x700")
                    
                    # ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ï¼ˆã‚¿ãƒ–ï¼‰ä½œæˆ
                    notebook = ctk.CTkTabview(result_window)
                    notebook.pack(fill="both", expand=True, padx=10, pady=10)
                    
                    # PCAçµæœã‚¿ãƒ–
                    pca_tab = notebook.add("ä¸»æˆåˆ†åˆ†æ")
                    pca_text = ctk.CTkTextbox(pca_tab, font=("Consolas", 11))
                    pca_text.pack(fill="both", expand=True, padx=5, pady=5)
                    
                    pca_results = results.get('pca', {})
                    pca_content = f"""
ğŸ“Š ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰çµæœ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ KaiseråŸºæº–ã«ã‚ˆã‚‹æˆåˆ†æ•°: {pca_results.get('n_components_kaiser', 'N/A')}
ğŸ“ˆ ç´¯ç©å¯„ä¸ç‡80%ã®æˆåˆ†æ•°: {pca_results.get('n_components_80', 'N/A')}

ğŸ“Š å¯„ä¸ç‡ï¼ˆä¸Šä½10æˆåˆ†ï¼‰:
"""
                    explained_var = pca_results.get('explained_variance_ratio', [])
                    for i, var in enumerate(explained_var[:10]):
                        pca_content += f"PC{i+1}: {var*100:.2f}%\n"
                    
                    cumulative_var = pca_results.get('cumulative_variance', [])
                    if cumulative_var:
                        pca_content += f"\nğŸ“ˆ ç´¯ç©å¯„ä¸ç‡ï¼ˆPC10ã¾ã§ï¼‰: {cumulative_var[min(9, len(cumulative_var)-1)]*100:.2f}%\n"
                    
                    pca_text.insert("1.0", pca_content)
                    
                    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã‚¿ãƒ–
                    cluster_tab = notebook.add("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°")
                    cluster_text = ctk.CTkTextbox(cluster_tab, font=("Consolas", 11))
                    cluster_text.pack(fill="both", expand=True, padx=5, pady=5)
                    
                    clustering_results = results.get('clustering', {})
                    kmeans_results = clustering_results.get('kmeans', {})
                    
                    cluster_content = f"""
ğŸ¯ K-means ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿æ•°: {kmeans_results.get('optimal_k', 'N/A')}

ğŸ“Š ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿æ•°åˆ¥ï¼‰:
"""
                    silhouette_scores = kmeans_results.get('silhouette_scores', [])
                    for i, score in enumerate(silhouette_scores):
                        cluster_content += f"K={i+2}: {score:.4f}\n"
                    
                    dbscan_results = clustering_results.get('dbscan', {})
                    if 'n_clusters' in dbscan_results:
                        cluster_content += f"\nğŸ” DBSCANæ¤œå‡ºã‚¯ãƒ©ã‚¹ã‚¿æ•°: {dbscan_results['n_clusters']}\n"
                    
                    cluster_text.insert("1.0", cluster_content)
                    
                    # ç›¸é–¢åˆ†æã‚¿ãƒ–
                    corr_tab = notebook.add("ç›¸é–¢åˆ†æ")
                    corr_text = ctk.CTkTextbox(corr_tab, font=("Consolas", 11))
                    corr_text.pack(fill="both", expand=True, padx=5, pady=5)
                    
                    correlation_results = results.get('correlation', {})
                    high_corr = correlation_results.get('high_correlations', [])
                    
                    corr_content = """
ğŸ”— ç›¸é–¢åˆ†æçµæœ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âš ï¸ é«˜ç›¸é–¢ãƒšã‚¢ï¼ˆ|r| > 0.7ï¼‰:

"""
                    if high_corr:
                        for pair in high_corr:
                            corr_content += f"â€¢ {pair['var1']} âŸ· {pair['var2']}: r = {pair['correlation']:.4f}\n"
                    else:
                        corr_content += "é«˜ç›¸é–¢ãƒšã‚¢ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n"
                    
                    corr_text.insert("1.0", corr_content)
                    
                    progress_window.destroy()
                    self._update_status("âœ… å¤šå¤‰é‡è§£æå®Œäº†")
                    
                except Exception as e:
                    progress_window.destroy()
                    messagebox.showerror("Error", f"å¤šå¤‰é‡è§£æã‚¨ãƒ©ãƒ¼: {e}")
                    self._update_status("âŒ å¤šå¤‰é‡è§£æå¤±æ•—")
            
            # åˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
            threading.Thread(target=run_analysis, daemon=True).start()
            
        except Exception as e:
            messagebox.showerror("Error", f"å¤šå¤‰é‡è§£æã‚¨ãƒ©ãƒ¼: {e}")
            self._update_status("âŒ å¤šå¤‰é‡è§£æå¤±æ•—")
    
    def time_series_analysis(self):
        """æ™‚ç³»åˆ—è§£æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first!")
            return
        
        if not self.advanced_features or not self.advanced_analyzer:
            messagebox.showwarning("Warning", "Advanced features not available!")
            return
        
        # æ™‚ç³»åˆ—è§£æç”¨ã®ãƒ€ã‚¤ã‚¢ãƒ­ã‚°
        dialog = tk.Toplevel(self.root)
        dialog.title("ğŸ“ˆ æ™‚ç³»åˆ—è§£æè¨­å®š")
        dialog.geometry("400x300")
        dialog.transient(self.root)
        dialog.grab_set()
        
        # æ—¥ä»˜åˆ—é¸æŠ
        date_frame = ctk.CTkFrame(dialog)
        date_frame.pack(fill="x", padx=10, pady=5)
        
        ctk.CTkLabel(date_frame, text="æ—¥ä»˜åˆ—:").pack(side="left", padx=5)
        date_var = ctk.CTkComboBox(date_frame, values=list(self.current_data.columns))
        date_var.pack(side="right", padx=5)
        
        # å€¤åˆ—é¸æŠ
        value_frame = ctk.CTkFrame(dialog)
        value_frame.pack(fill="x", padx=10, pady=5)
        
        ctk.CTkLabel(value_frame, text="å€¤åˆ—:").pack(side="left", padx=5)
        value_var = ctk.CTkComboBox(value_frame, values=list(self.current_data.select_dtypes(include=[np.number]).columns))
        value_var.pack(side="right", padx=5)
        
        def run_ts_analysis():
            date_col = date_var.get()
            value_col = value_var.get()
            
            if not date_col or not value_col:
                messagebox.showwarning("Warning", "Please select both date and value columns!")
                return
            
            dialog.destroy()
            
            try:
                self._update_status("ğŸ“ˆ å®Ÿè¡Œä¸­: æ™‚ç³»åˆ—è§£æ...")
                results = self.advanced_analyzer.time_series_analysis(self.current_data, date_col, value_col)
                
                # çµæœè¡¨ç¤º
                result_text = f"""
ğŸ“ˆ æ™‚ç³»åˆ—è§£æçµæœ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š åŸºæœ¬çµ±è¨ˆ:
å¹³å‡: {results['basic_stats']['mean']:.4f}
æ¨™æº–åå·®: {results['basic_stats']['std']:.4f}
è¦³æ¸¬æ•°: {results['basic_stats']['observations']}

ğŸ” å®šå¸¸æ€§æ¤œå®š:
ADFæ¤œå®š på€¤: {results['stationarity_tests']['adf']['p_value']:.6f}
â†’ å®šå¸¸æ€§: {'Yes' if results['stationarity_tests']['adf']['is_stationary'] else 'No'}

KPSSæ¤œå®š på€¤: {results['stationarity_tests']['kpss']['p_value']:.6f}
â†’ å®šå¸¸æ€§: {'Yes' if results['stationarity_tests']['kpss']['is_stationary'] else 'No'}
"""
                
                arima_results = results.get('arima', {})
                if 'best_params' in arima_results:
                    result_text += f"""
ğŸ“Š ARIMA ãƒ¢ãƒ‡ãƒ«:
æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {arima_results['best_params']}
AIC: {arima_results['aic']:.4f}
BIC: {arima_results['bic']:.4f}
"""
                
                self.result_text.delete("1.0", tk.END)
                self.result_text.insert("1.0", result_text)
                self._update_status("âœ… æ™‚ç³»åˆ—è§£æå®Œäº†")
                
            except Exception as e:
                messagebox.showerror("Error", f"æ™‚ç³»åˆ—è§£æã‚¨ãƒ©ãƒ¼: {e}")
                self._update_status("âŒ æ™‚ç³»åˆ—è§£æå¤±æ•—")
        
        # å®Ÿè¡Œãƒœã‚¿ãƒ³
        button_frame = ctk.CTkFrame(dialog)
        button_frame.pack(fill="x", padx=10, pady=10)
        
        ctk.CTkButton(button_frame, text="å®Ÿè¡Œ", command=run_ts_analysis).pack(side="right", padx=5)
        ctk.CTkButton(button_frame, text="ã‚­ãƒ£ãƒ³ã‚»ãƒ«", command=dialog.destroy).pack(side="right", padx=5)
    
    def survival_analysis(self):
        """ç”Ÿå­˜è§£æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first!")
            return
        
        if not self.advanced_features or not self.survival_analyzer:
            messagebox.showwarning("Warning", "Advanced features not available!")
            return
        
        messagebox.showinfo("Info", "ç”Ÿå­˜è§£ææ©Ÿèƒ½ã¯é–‹ç™ºä¸­ã§ã™ã€‚æ¬¡å›ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã§è¿½åŠ äºˆå®šã§ã™ã€‚")
    
    def bayesian_analysis(self):
        """ãƒ™ã‚¤ã‚ºçµ±è¨ˆè§£æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first!")
            return
        
        if not self.advanced_features or not self.bayesian_analyzer:
            messagebox.showwarning("Warning", "Advanced features not available!")
            return
        
        messagebox.showinfo("Info", "ãƒ™ã‚¤ã‚ºçµ±è¨ˆè§£ææ©Ÿèƒ½ã¯é–‹ç™ºä¸­ã§ã™ã€‚PyMCãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™ã€‚")
    
    def comprehensive_eda(self):
        """åŒ…æ‹¬çš„æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿è§£æ"""
        if self.current_data is None:
            messagebox.showwarning("Warning", "Please load data first!")
            return
        
        if not self.advanced_features or not self.advanced_analyzer:
            messagebox.showwarning("Warning", "Advanced features not available!")
            return
        
        try:
            self._update_status("ğŸ“Š å®Ÿè¡Œä¸­: åŒ…æ‹¬çš„EDA...")
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒ€ã‚¤ã‚¢ãƒ­ã‚°
            progress_window = tk.Toplevel(self.root)
            progress_window.title("åŒ…æ‹¬çš„EDAå®Ÿè¡Œä¸­")
            progress_window.geometry("400x120")
            progress_window.transient(self.root)
            progress_window.grab_set()
            
            progress_label = ctk.CTkLabel(progress_window, text="ãƒ‡ãƒ¼ã‚¿è§£æä¸­...")
            progress_label.pack(pady=10)
            
            progress_bar = ctk.CTkProgressBar(progress_window)
            progress_bar.pack(pady=10, padx=20, fill="x")
            progress_bar.set(0)
            
            def run_eda():
                try:
                    progress_bar.set(0.3)
                    progress_window.update()
                    
                    results = self.advanced_analyzer.comprehensive_eda(self.current_data)
                    
                    progress_bar.set(1.0)
                    progress_window.update()
                    
                    # çµæœè¡¨ç¤º
                    result_text = f"""
ğŸ“Š åŒ…æ‹¬çš„æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿è§£æï¼ˆEDAï¼‰çµæœ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:
â€¢ ç·è¡Œæ•°: {results['data_overview']['total_rows']:,}
â€¢ ç·åˆ—æ•°: {results['data_overview']['total_columns']}
â€¢ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {results['data_overview']['memory_usage_mb']:.1f} MB
â€¢ æ•°å€¤åˆ—: {results['data_overview']['numeric_columns']}
â€¢ ã‚«ãƒ†ã‚´ãƒªåˆ—: {results['data_overview']['categorical_columns']}

âŒ æ¬ æå€¤åˆ†æ:
â€¢ æ¬ æå€¤ç·æ•°: {results['missing_values']['total_missing']:,}
â€¢ æ¬ æå€¤ã®ã‚ã‚‹åˆ—æ•°: {results['missing_values']['columns_with_missing']}
â€¢ å®Œå…¨ãªè¡Œæ•°: {results['missing_values']['complete_rows']:,}

ğŸ¯ å¤–ã‚Œå€¤æ¤œå‡ºï¼ˆä¸Šä½5åˆ—ï¼‰:
"""
                    outliers = results.get('outliers', {})
                    for i, (col, info) in enumerate(list(outliers.items())[:5]):
                        result_text += f"â€¢ {col}: IQRæ³• {info['iqr_outliers']}å€‹ ({info['outlier_percentage_iqr']:.1f}%)\n"
                    
                    # åˆ†å¸ƒåˆ†æ
                    distributions = results.get('distributions', {})
                    normal_cols = [col for col, info in distributions.items() if info.get('is_normal', False)]
                    
                    result_text += f"""

ğŸ“ˆ åˆ†å¸ƒåˆ†æ:
â€¢ æ­£è¦åˆ†å¸ƒã«å¾“ã†åˆ—: {len(normal_cols)}å€‹
â€¢ éæ­£è¦åˆ†å¸ƒã®åˆ—: {len(distributions) - len(normal_cols)}å€‹

ğŸ”— é–¢ä¿‚æ€§åˆ†æ:
"""
                    relationships = results.get('relationships', {})
                    if 'strong_correlations' in relationships:
                        strong_corr = relationships['strong_correlations']
                        result_text += f"â€¢ å¼·ã„ç›¸é–¢ã‚’æŒã¤ãƒšã‚¢: {len(strong_corr)}å€‹\n"
                        
                        if strong_corr:
                            result_text += "\nå¼·ç›¸é–¢ãƒšã‚¢:\n"
                            for pair in strong_corr[:5]:  # ä¸Šä½5å€‹
                                result_text += f"  - {pair['var1']} âŸ· {pair['var2']}: r = {pair['correlation']:.3f}\n"
                    
                    result_text += f"""

âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±:
â€¢ è§£æå®Œäº†æ™‚åˆ»: {results['timestamp']}
â€¢ ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {results['data_shape']}
"""
                    
                    progress_window.destroy()
                    
                    self.result_text.delete("1.0", tk.END)
                    self.result_text.insert("1.0", result_text)
                    self._update_status("âœ… åŒ…æ‹¬çš„EDAå®Œäº†")
                    
                except Exception as e:
                    progress_window.destroy()
                    messagebox.showerror("Error", f"EDAã‚¨ãƒ©ãƒ¼: {e}")
                    self._update_status("âŒ EDAå¤±æ•—")
            
            threading.Thread(target=run_eda, daemon=True).start()
            
        except Exception as e:
            messagebox.showerror("Error", f"EDAã‚¨ãƒ©ãƒ¼: {e}")
            self._update_status("âŒ EDAå¤±æ•—")
    
    def run(self):
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        try:
            self.root.mainloop()
        except KeyboardInterrupt:
            print("\nğŸ›‘ Application interrupted by user")
        finally:
            # çµ‚äº†æ™‚ä¿å­˜
            try:
                self.session_manager.save_session()
                print("âœ… Final session saved")
            except:
                pass

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("ğŸ”¬ Professional Statistical Analysis Software")
    print("=" * 50)
    print(f"Python: {sys.version}")
    print(f"CUDA: {'Available' if CUDA_AVAILABLE else 'Not Available'}")
    if CUDA_AVAILABLE:
        print(f"GPU: {GPU_NAME}")
    print("=" * 50)
    
    try:
        print("ğŸ“‹ Initializing application...")
        app = StatisticalAnalysisGUI()
        print("âœ… Application initialized successfully")
        print("ğŸš€ Starting main loop...")
        app.run()
    except Exception as e:
        import traceback
        print(f"âŒ Application error: {e}")
        print("ğŸ“‹ Full traceback:")
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main() 