# ğŸ”¬  Professional Statistical Analysis Software

**ä¸–ç•Œæœ€é«˜æ°´æº–ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«çµ±è¨ˆè§£æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ **

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Platform](https://img.shields.io/badge/Platform-Windows%20%7C%20Mac%20M2%20%7C%20Linux-lightgrey.svg)]()
[![GPU](https://img.shields.io/badge/GPU-CUDA%20Enabled-orange.svg)]()

## ğŸ¯ **æ¦‚è¦**

Professional Statistical Analysis Softwareã¯ã€ç ”ç©¶è€…ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆãƒ»çµ±è¨ˆå°‚é–€å®¶ã®ãŸã‚ã®**æ¬¡ä¸–ä»£çµ±è¨ˆè§£æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ **ã§ã™ã€‚é«˜åº¦ãªçµ±è¨ˆæ‰‹æ³•ã€æ©Ÿæ¢°å­¦ç¿’ã€ãƒ™ã‚¤ã‚ºè§£æã€ç”Ÿå­˜è§£æã‚’çµ±åˆã—ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒ™ãƒ«ã®è§£æã‚’å®Ÿç¾ã—ã¾ã™ã€‚

### âœ¨ **ä¸»è¦ç‰¹å¾´**

- ğŸ§  **é«˜åº¦çµ±è¨ˆè§£æ**: å¤šå¤‰é‡è§£æã€æ™‚ç³»åˆ—è§£æã€åŒ…æ‹¬çš„EDA
- â±ï¸ **ç”Ÿå­˜è§£æ**: Kaplan-Meierã€Coxå›å¸°ã€ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ç”Ÿå­˜è§£æ
- ğŸ² **ãƒ™ã‚¤ã‚ºçµ±è¨ˆè§£æ**: éšå±¤ãƒ¢ãƒ‡ãƒ«ã€MCMCã€ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
- ğŸ¤– **æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è‡ªå‹•åŒ–**: AutoMLã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
- ğŸŒ **å¤šè¨€èªWebãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**: æ—¥æœ¬èªãƒ»è‹±èªå¯¾å¿œã€Mac M2æœ€é©åŒ–
- âš¡ **é«˜æ€§èƒ½å‡¦ç†**: GPUåŠ é€Ÿã€ä¸¦åˆ—å‡¦ç†ã€Numba JITæœ€é©åŒ–
- ğŸ›¡ï¸ **ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**: è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
- ğŸ“Š **ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒãƒ¼ãƒˆ**: è«–æ–‡å“è³ªã®å‡ºåŠ›

## ğŸš€ **æ–°æ©Ÿèƒ½ãƒã‚¤ãƒ©ã‚¤ãƒˆ**

### ğŸ”¬ **å®Œå…¨çµ±åˆã•ã‚ŒãŸè§£ææ©Ÿèƒ½**

#### **1. ç”Ÿå­˜è§£æ (`survival_analysis.py`)**
```python
# Kaplan-Meierç”Ÿå­˜è§£æ
results = complete_survival_analyzer.kaplan_meier_analysis(
    data, duration_col='time', event_col='event', group_col='treatment'
)

# Coxæ¯”ä¾‹ãƒã‚¶ãƒ¼ãƒ‰å›å¸°
cox_results = complete_survival_analyzer.cox_regression_analysis(
    data, duration_col='time', event_col='event', 
    covariate_cols=['age', 'gender', 'treatment']
)
```

#### **2. ãƒ™ã‚¤ã‚ºçµ±è¨ˆè§£æ (`bayesian_analysis.py`)**
```python
# ãƒ™ã‚¤ã‚ºç·šå½¢å›å¸°
bayesian_results = deep_bayesian_analyzer.bayesian_linear_regression(
    data, target_col='outcome', predictor_cols=['x1', 'x2', 'x3']
)

# éšå±¤ãƒ™ã‚¤ã‚ºãƒ¢ãƒ‡ãƒªãƒ³ã‚°
hierarchical_results = deep_bayesian_analyzer.hierarchical_modeling(
    data, target_col='outcome', predictor_cols=['x1', 'x2'], 
    group_col='cluster'
)
```

#### **3. æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è‡ªå‹•åŒ– (`ml_pipeline_automation.py`)**
```python
# å®Œå…¨è‡ªå‹•åŒ–æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
ml_results = ml_pipeline_automator.complete_ml_pipeline(
    data, target_col='target', task_type='auto', 
    optimize_hyperparams=True
)
```

#### **4. å¤šè¨€èªWebãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ (`web_dashboard.py`)**
```bash
# Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰èµ·å‹•
py -3 run_web_dashboard.py
```

## ğŸ› ï¸ **ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**

### **å¿…è¦æ¡ä»¶**
- Python 3.9 ä»¥ä¸Š
- Windows 10/11, macOS (Intel/M2/M3), Linux
- ãƒ¡ãƒ¢ãƒª: 8GBä»¥ä¸Šæ¨å¥¨
- GPU: CUDAå¯¾å¿œGPUï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

### **1. ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³**
```bash
git clone https://github.com/your-repo/HAD_backups.git
cd HAD_backups
```

### **2. ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**
```bash
# åŸºæœ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt

# Mac M2æœ€é©åŒ–ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆMacä½¿ç”¨è€…ï¼‰
pip install --upgrade tensorflow-macos tensorflow-metal

# GPUåŠ é€Ÿï¼ˆNVIDIA GPUä½¿ç”¨è€…ï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### **3. ã‚ªãƒ—ã‚·ãƒ§ãƒ³: é«˜åº¦æ©Ÿèƒ½**
```bash
# ãƒ™ã‚¤ã‚ºçµ±è¨ˆè§£æï¼ˆPyMCï¼‰
pip install pymc arviz

# åˆ†æ•£å‡¦ç†ï¼ˆå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼‰
pip install dask[complete]
```

## ğŸ® **ä½¿ç”¨æ–¹æ³•**

### **ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³**
```bash
py -3 main.py
```
![Desktop Application](docs/images/desktop_app.png)

### **Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**
```bash
py -3 run_web_dashboard.py
```
- ãƒ–ãƒ©ã‚¦ã‚¶ã§ `http://localhost:8501` ã«ã‚¢ã‚¯ã‚»ã‚¹
- æ—¥æœ¬èªãƒ»è‹±èªãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ‡ã‚Šæ›¿ãˆ
- ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è§£æãƒ»å¯è¦–åŒ–

![Web Dashboard](docs/images/web_dashboard.png)

## ğŸ“Š **è§£ææ©Ÿèƒ½ä¸€è¦§**

### **åŸºæœ¬çµ±è¨ˆè§£æ**
- âœ… è¨˜è¿°çµ±è¨ˆãƒ»æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿è§£æ
- âœ… ä»®èª¬æ¤œå®šï¼ˆtæ¤œå®šã€ã‚«ã‚¤äºŒä¹—æ¤œå®šã€ANOVAç­‰ï¼‰
- âœ… ç›¸é–¢åˆ†æãƒ»å›å¸°åˆ†æ
- âœ… ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯

### **é«˜åº¦çµ±è¨ˆè§£æ**
- ğŸ§  **å¤šå¤‰é‡è§£æ**: PCAã€å› å­åˆ†æã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
- ğŸ“ˆ **æ™‚ç³»åˆ—è§£æ**: ARIMAã€å­£ç¯€åˆ†è§£ã€å®šå¸¸æ€§æ¤œå®š
- ğŸ“Š **åŒ…æ‹¬çš„EDA**: æ¬ æå€¤åˆ†æã€å¤–ã‚Œå€¤æ¤œå‡ºã€åˆ†å¸ƒåˆ†æ

### **ç”Ÿå­˜è§£æ**
- â±ï¸ **Kaplan-Meieræ¨å®š**: ç”Ÿå­˜æ›²ç·šã€ä¿¡é ¼åŒºé–“ã€ãƒªã‚¹ã‚¯ãƒ†ãƒ¼ãƒ–ãƒ«
- ğŸ“‰ **Coxæ¯”ä¾‹ãƒã‚¶ãƒ¼ãƒ‰å›å¸°**: ãƒã‚¶ãƒ¼ãƒ‰æ¯”ã€æ¯”ä¾‹ãƒã‚¶ãƒ¼ãƒ‰ä»®å®šæ¤œå®š
- ğŸ“Š **ãƒ‘ãƒ©ãƒ¡ãƒˆãƒªãƒƒã‚¯ç”Ÿå­˜è§£æ**: Weibullã€æŒ‡æ•°åˆ†å¸ƒã€å¯¾æ•°æ­£è¦åˆ†å¸ƒ
- ğŸ”¬ **çµ±è¨ˆæ¤œå®š**: Log-rankæ¤œå®šã€å¤šç¾¤æ¯”è¼ƒ
- ğŸ“ˆ **é«˜åº¦æ©Ÿèƒ½**: Nelson-Aalenã€æ¡ä»¶ä»˜ãç”Ÿå­˜ç¢ºç‡ã€RMST

### **ãƒ™ã‚¤ã‚ºçµ±è¨ˆè§£æ**
- ğŸ² **ãƒ™ã‚¤ã‚ºå›å¸°**: ç·šå½¢ãƒ»ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã€ä¸ç¢ºå®Ÿæ€§å®šé‡åŒ–
- ğŸ—ï¸ **éšå±¤ãƒ™ã‚¤ã‚ºãƒ¢ãƒ‡ãƒªãƒ³ã‚°**: ã‚°ãƒ«ãƒ¼ãƒ—åŠ¹æœã€åˆ†æ•£æˆåˆ†
- ğŸ“ˆ **ãƒ™ã‚¤ã‚ºæ™‚ç³»åˆ—**: çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã€äºˆæ¸¬
- âš–ï¸ **ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ**: WAICã€LOOã€ãƒ™ã‚¤ã‚ºãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼
- ğŸ” **è¨ºæ–­**: ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆã€åæŸè¨ºæ–­

### **æ©Ÿæ¢°å­¦ç¿’**
- ğŸ¤– **AutoML**: è‡ªå‹•å‰å‡¦ç†ã€ç‰¹å¾´é¸æŠã€ãƒ¢ãƒ‡ãƒ«é¸æŠ
- âš¡ **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–**: Optunaã€ãƒ™ã‚¤ã‚ºæœ€é©åŒ–
- ğŸ¯ **åˆ†é¡ãƒ»å›å¸°**: RFã€XGBoostã€LightGBMã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ
- ğŸ“Š **è©•ä¾¡**: ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã€ç‰¹å¾´é‡è¦åº¦ã€æ··åŒè¡Œåˆ—
- ğŸ”„ **ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³**: å®Œå…¨è‡ªå‹•åŒ–ã€ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿

### **æ·±å±¤å­¦ç¿’**
- ğŸ§  **ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ**: åˆ†é¡ãƒ»å›å¸°ã€è‡ªå‹•æ§‹ç¯‰
- ğŸ” **LSTM**: æ™‚ç³»åˆ—äºˆæ¸¬ã€sequence-to-sequence
- ğŸ–¼ï¸ **CNN**: ç”»åƒè§£æã€ç•³ã¿è¾¼ã¿å±¤
- ğŸ”€ **ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€**: æ¬¡å…ƒå‰Šæ¸›ã€ç•°å¸¸æ¤œçŸ¥

## ğŸŒŸ **ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½**

### **ğŸ›¡ï¸ ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ»å¾©æ—§**
- è‡ªå‹•ä¿å­˜ï¼ˆ5åˆ†é–“éš”ï¼‰
- ç•°å¸¸çµ‚äº†æ™‚ã®ç·Šæ€¥ä¿å­˜
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæœ€å¤§10ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
- ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©æ—§æ©Ÿèƒ½

### **ğŸ“‹ ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ¬ãƒãƒ¼ãƒˆ**
- è«–æ–‡å“è³ªã®HTML/PDFå‡ºåŠ›
- çµ±è¨ˆçµæœã®è‡ªå‹•æ•´ç†
- ã‚°ãƒ©ãƒ•ãƒ»ãƒ†ãƒ¼ãƒ–ãƒ«ã®çµ±åˆ
- ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

### **âš¡ é«˜æ€§èƒ½æœ€é©åŒ–**
- Numba JITæœ€é©åŒ–
- ä¸¦åˆ—å‡¦ç†ï¼ˆãƒãƒ«ãƒã‚³ã‚¢å¯¾å¿œï¼‰
- GPUåŠ é€Ÿï¼ˆCUDAï¼‰
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–

### **ğŸ¤– AIçµ±åˆ**
- OpenAI GPTçµ±åˆ
- Google Geminiå¯¾å¿œ
- è‡ªç„¶è¨€èªã«ã‚ˆã‚‹è§£ææŒ‡ç¤º
- ç”»åƒãƒ‡ãƒ¼ã‚¿åˆ†æ

## ğŸ¨ **å¯è¦–åŒ–æ©Ÿèƒ½**

- ğŸ“Š **çµ±è¨ˆã‚°ãƒ©ãƒ•**: ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã€æ•£å¸ƒå›³ã€ç®±ã²ã’å›³
- ğŸ“ˆ **é«˜åº¦ãªå¯è¦–åŒ–**: PCA biplotã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ¨¹å½¢å›³
- â±ï¸ **ç”Ÿå­˜æ›²ç·š**: Kaplan-Meierã€ç´¯ç©ãƒã‚¶ãƒ¼ãƒ‰
- ğŸ² **ãƒ™ã‚¤ã‚ºè¨ºæ–­**: äº‹å¾Œåˆ†å¸ƒã€ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
- ğŸ¤– **MLè©•ä¾¡**: ROCæ›²ç·šã€å­¦ç¿’æ›²ç·šã€ç‰¹å¾´é‡è¦åº¦
- ğŸŒ **ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–**: Plotlyã€å‹•çš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

## ğŸ”§ **è¨­å®šãƒ»ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º**

### **è¨€èªè¨­å®š**
```python
# æ—¥æœ¬èªè¡¨ç¤º
app.set_language('ja')

# è‹±èªè¡¨ç¤º  
app.set_language('en')
```

### **GPUè¨­å®š**
```python
# CUDAåˆ©ç”¨è¨­å®š
app.enable_gpu_acceleration(device='cuda:0')

# CPUä¸¦åˆ—å‡¦ç†
app.set_parallel_jobs(n_jobs=8)
```

### **Mac M2æœ€é©åŒ–**
```bash
# M2æœ€é©åŒ–ç’°å¢ƒå¤‰æ•°
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1
```

## ğŸ“ **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ **

```
HAD_backups/
â”œâ”€â”€ main.py                      # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”œâ”€â”€ web_dashboard.py             # Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
â”œâ”€â”€ run_web_dashboard.py         # Webèµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ advanced_statistics.py       # é«˜åº¦çµ±è¨ˆè§£æ
â”œâ”€â”€ survival_analysis.py         # ç”Ÿå­˜è§£æ
â”œâ”€â”€ bayesian_analysis.py         # ãƒ™ã‚¤ã‚ºçµ±è¨ˆè§£æ
â”œâ”€â”€ ml_pipeline_automation.py    # MLè‡ªå‹•åŒ–
â”œâ”€â”€ parallel_optimization.py     # ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–
â”œâ”€â”€ professional_utils.py        # ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«æ©Ÿèƒ½
â”œâ”€â”€ professional_reports.py      # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
â”œâ”€â”€ ai_integration.py            # AIçµ±åˆ
â”œâ”€â”€ config.py                    # è¨­å®šç®¡ç†
â”œâ”€â”€ requirements.txt             # ä¾å­˜é–¢ä¿‚
â”œâ”€â”€ README.md                    # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ LICENSE                      # ãƒ©ã‚¤ã‚»ãƒ³ã‚¹
â”œâ”€â”€ backup/                      # è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
â”œâ”€â”€ checkpoints/                 # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
â”œâ”€â”€ config/                      # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ data/                        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
â”œâ”€â”€ logs/                        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ reports/                     # ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ
â””â”€â”€ templates/                   # ãƒ¬ãƒãƒ¼ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
```

## ğŸ“ **ä½¿ç”¨ä¾‹**

### **ä¾‹1: è‡¨åºŠè©¦é¨“ã®ç”Ÿå­˜è§£æ**
```python
import pandas as pd
from survival_analysis import complete_survival_analyzer

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
data = pd.read_csv('clinical_trial.csv')

# Kaplan-Meierè§£æ
km_results = complete_survival_analyzer.kaplan_meier_analysis(
    data, 
    duration_col='survival_time',
    event_col='death_event',
    group_col='treatment_group'
)

# Coxå›å¸°è§£æ
cox_results = complete_survival_analyzer.cox_regression_analysis(
    data,
    duration_col='survival_time',
    event_col='death_event',
    covariate_cols=['age', 'gender', 'stage', 'treatment']
)

print(f"ä¸­å¤®ç”Ÿå­˜æ™‚é–“: {km_results['overall']['median_survival']}")
print(f"æ²»ç™‚åŠ¹æœã®ãƒã‚¶ãƒ¼ãƒ‰æ¯”: {cox_results['model_summary']['hazard_ratios']['treatment']}")
```

### **ä¾‹2: ãƒ™ã‚¤ã‚ºA/Bãƒ†ã‚¹ãƒˆ**
```python
from bayesian_analysis import deep_bayesian_analyzer

# A/Bãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
ab_data = pd.read_csv('ab_test.csv')

# ãƒ™ã‚¤ã‚ºãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°
bayesian_results = deep_bayesian_analyzer.bayesian_logistic_regression(
    ab_data,
    target_col='conversion',
    predictor_cols=['variant', 'age', 'device_type']
)

# å¤‰æ›ç‡å‘ä¸Šã®ç¢ºç‡
variant_effect = bayesian_results['odds_ratios']['variant']
print(f"variant Bã®æ”¹å–„ç¢ºç‡: {variant_effect['probability_beneficial']:.2%}")
```

### **ä¾‹3: å®Œå…¨è‡ªå‹•åŒ–æ©Ÿæ¢°å­¦ç¿’**
```python
from ml_pipeline_automation import ml_pipeline_automator

# è‡ªå‹•åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
ml_results = ml_pipeline_automator.complete_ml_pipeline(
    data=sales_data,
    target_col='revenue',
    task_type='regression',
    optimize_hyperparams=True
)

# çµæœç¢ºèª
print(f"æœ€è‰¯ãƒ¢ãƒ‡ãƒ«: {ml_results['model_selection']['best_model']['name']}")
print(f"RÂ²ã‚¹ã‚³ã‚¢: {ml_results['final_evaluation']['r2_score']:.4f}")
```

## ğŸ”¬ **ç ”ç©¶ãƒ»è«–æ–‡ã§ã®ä½¿ç”¨**

### **çµ±è¨ˆæ‰‹æ³•ã®å¼•ç”¨**
æœ¬ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚’ç ”ç©¶ã§ä½¿ç”¨ã™ã‚‹éš›ã®å¼•ç”¨ä¾‹ï¼š

```
Statistical analyses were performed using HAD Professional Statistical Analysis Software v2.0 
(Minegishi, 2024), which implements advanced statistical methods including Kaplan-Meier survival 
analysis, Bayesian hierarchical modeling, and automated machine learning pipelines.
```

### **å¯¾å¿œã™ã‚‹çµ±è¨ˆæ‰‹æ³•**
- ç”Ÿå­˜è§£æ: Kaplan & Meier (1958), Cox (1972)
- ãƒ™ã‚¤ã‚ºçµ±è¨ˆ: Gelman et al. (2013), McElreath (2020)
- æ©Ÿæ¢°å­¦ç¿’: Hastie et al. (2009), Bishop (2006)

## ğŸ¤ **ã‚µãƒãƒ¼ãƒˆãƒ»ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£**

### **æŠ€è¡“ã‚µãƒãƒ¼ãƒˆ**
- ğŸ“§ Email: support@had-statistics.com
- ğŸ’¬ Discord: [HAD Community](https://discord.gg/had-stats)
- ğŸ“š Documentation: [docs.had-statistics.com](https://docs.had-statistics.com)

### **è²¢çŒ®**
ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã€ãƒã‚°ãƒ¬ãƒãƒ¼ãƒˆã€æ©Ÿèƒ½ææ¡ˆã‚’æ­“è¿ã—ã¾ã™ï¼

1. ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒ•ã‚©ãƒ¼ã‚¯
2. æ©Ÿèƒ½ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆ (`git checkout -b feature/AmazingFeature`)
3. å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ (`git commit -m 'Add some AmazingFeature'`)
4. ãƒ–ãƒ©ãƒ³ãƒã«ãƒ—ãƒƒã‚·ãƒ¥ (`git push origin feature/AmazingFeature`)
5. ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é–‹ã

## ğŸ“„ **ãƒ©ã‚¤ã‚»ãƒ³ã‚¹**

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§é…å¸ƒã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ç´°ã¯ [LICENSE](LICENSE) ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## ğŸ™ **è¬è¾**

- Pythonç§‘å­¦è¨ˆç®—ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£
- scikit-learnã€PyMCã€lifelinesé–‹ç™ºãƒãƒ¼ãƒ 
- çµ±è¨ˆè§£ææ‰‹æ³•ã®ç ”ç©¶è€…ã®çš†æ§˜

---

## ğŸš€ **ä»Šã™ãå§‹ã‚ã‚‹**

```bash
# 1. ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/your-repo/HAD_backups.git
cd HAD_backups

# 2. ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt

# 3. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•
py -3 main.py

# ã¾ãŸã¯ Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
py -3 run_web_dashboard.py
```

**ä¸–ç•Œæœ€é«˜æ°´æº–ã®çµ±è¨ˆè§£æã‚’ã€ä»Šã™ãã‚ãªãŸã®æ‰‹ã«ï¼** ğŸ‰

---

*Made with â¤ï¸ by Ryo Minegishi | Â© 2024 HAD Professional Statistical Analysis Software*
