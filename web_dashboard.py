#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Multilingual Web Dashboard for Statistical Analysis
å¤šè¨€èªçµ±è¨ˆè§£æWebãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

Mac M2 Optimized with ARM64 Support
Author: Ryo Minegishi
License: MIT
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from typing import Dict, List, Optional, Any
from datetime import datetime
import io
import base64
import json
import platform

# å¤šè¨€èªå¯¾å¿œ
import gettext
import locale

# ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«çµ±è¨ˆè§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from advanced_statistics import advanced_analyzer
    from survival_analysis import complete_survival_analyzer
    from bayesian_analysis import deep_bayesian_analyzer
    from ml_pipeline_automation import ml_pipeline_automator
    ADVANCED_MODULES_AVAILABLE = True
except ImportError:
    ADVANCED_MODULES_AVAILABLE = False

warnings.filterwarnings('ignore')

# Mac M2æœ€é©åŒ–è¨­å®š
if platform.machine() == 'arm64':
    import os
    os.environ['OMP_NUM_THREADS'] = '1'
    os.environ['MKL_NUM_THREADS'] = '1'

class MultilingualWebDashboard:
    """å¤šè¨€èªçµ±è¨ˆè§£æWebãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"""
    
    def __init__(self):
        self.supported_languages = {'en': 'English', 'ja': 'æ—¥æœ¬èª'}
        self.current_language = 'ja'
        self.translations = self._load_translations()
        
        # Streamlitè¨­å®š
        st.set_page_config(
            page_title="HAD Professional Statistical Analysis",
            page_icon="ğŸ“Š",
            layout="wide",
            initial_sidebar_state="expanded"
        )
    
    def _load_translations(self) -> Dict[str, Dict[str, str]]:
        """ç¿»è¨³ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        
        translations = {
            'ja': {
                'title': 'HAD ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«çµ±è¨ˆè§£æã‚·ã‚¹ãƒ†ãƒ ',
                'subtitle': 'é«˜åº¦çµ±è¨ˆè§£æãƒ»æ©Ÿæ¢°å­¦ç¿’ãƒ»ãƒ™ã‚¤ã‚ºçµ±è¨ˆãƒ»ç”Ÿå­˜è§£æ',
                'language_selector': 'è¨€èªé¸æŠ',
                'data_upload': 'ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰',
                'analysis_type': 'è§£æã‚¿ã‚¤ãƒ—',
                'basic_stats': 'åŸºæœ¬çµ±è¨ˆ',
                'advanced_analysis': 'é«˜åº¦è§£æ',
                'survival_analysis': 'ç”Ÿå­˜è§£æ',
                'bayesian_analysis': 'ãƒ™ã‚¤ã‚ºè§£æ',
                'ml_pipeline': 'æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³',
                'multivariate': 'å¤šå¤‰é‡è§£æ',
                'time_series': 'æ™‚ç³»åˆ—è§£æ',
                'upload_data': 'CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰',
                'data_preview': 'ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼',
                'analysis_results': 'è§£æçµæœ',
                'download_results': 'çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰',
                'target_variable': 'ç›®çš„å¤‰æ•°',
                'predictor_variables': 'èª¬æ˜å¤‰æ•°',
                'group_variable': 'ã‚°ãƒ«ãƒ¼ãƒ—å¤‰æ•°',
                'date_variable': 'æ—¥ä»˜å¤‰æ•°',
                'event_variable': 'ã‚¤ãƒ™ãƒ³ãƒˆå¤‰æ•°',
                'duration_variable': 'æ™‚é–“å¤‰æ•°',
                'run_analysis': 'è§£æå®Ÿè¡Œ',
                'processing': 'å‡¦ç†ä¸­...',
                'no_data': 'ãƒ‡ãƒ¼ã‚¿ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“',
                'error': 'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ',
                'success': 'è§£æãŒå®Œäº†ã—ã¾ã—ãŸ',
                'export_plot': 'ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜',
                'model_performance': 'ãƒ¢ãƒ‡ãƒ«æ€§èƒ½',
                'feature_importance': 'ç‰¹å¾´é‡é‡è¦åº¦',
                'confusion_matrix': 'æ··åŒè¡Œåˆ—',
                'survival_curve': 'ç”Ÿå­˜æ›²ç·š',
                'hazard_ratio': 'ãƒã‚¶ãƒ¼ãƒ‰æ¯”',
                'posterior_distribution': 'äº‹å¾Œåˆ†å¸ƒ',
                'trace_plot': 'ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ',
                'system_info': 'ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±'
            },
            'en': {
                'title': 'HAD Professional Statistical Analysis System',
                'subtitle': 'Advanced Statisticsãƒ»Machine Learningãƒ»Bayesian Analysisãƒ»Survival Analysis',
                'language_selector': 'Language Selection',
                'data_upload': 'Data Upload',
                'analysis_type': 'Analysis Type',
                'basic_stats': 'Basic Statistics',
                'advanced_analysis': 'Advanced Analysis',
                'survival_analysis': 'Survival Analysis',
                'bayesian_analysis': 'Bayesian Analysis',
                'ml_pipeline': 'Machine Learning Pipeline',
                'multivariate': 'Multivariate Analysis',
                'time_series': 'Time Series Analysis',
                'upload_data': 'Upload CSV File',
                'data_preview': 'Data Preview',
                'analysis_results': 'Analysis Results',
                'download_results': 'Download Results',
                'target_variable': 'Target Variable',
                'predictor_variables': 'Predictor Variables',
                'group_variable': 'Group Variable',
                'date_variable': 'Date Variable',
                'event_variable': 'Event Variable',
                'duration_variable': 'Duration Variable',
                'run_analysis': 'Run Analysis',
                'processing': 'Processing...',
                'no_data': 'No data uploaded',
                'error': 'An error occurred',
                'success': 'Analysis completed',
                'export_plot': 'Export Plot',
                'model_performance': 'Model Performance',
                'feature_importance': 'Feature Importance',
                'confusion_matrix': 'Confusion Matrix',
                'survival_curve': 'Survival Curve',
                'hazard_ratio': 'Hazard Ratio',
                'posterior_distribution': 'Posterior Distribution',
                'trace_plot': 'Trace Plot',
                'system_info': 'System Information'
            }
        }
        
        return translations
    
    def t(self, key: str) -> str:
        """ç¿»è¨³å–å¾—"""
        return self.translations.get(self.current_language, {}).get(key, key)
    
    def render_header(self):
        """ãƒ˜ãƒƒãƒ€ãƒ¼æç”»"""
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.title(self.t('title'))
            st.markdown(f"### {self.t('subtitle')}")
        
        with col2:
            self.current_language = st.selectbox(
                self.t('language_selector'),
                options=list(self.supported_languages.keys()),
                format_func=lambda x: self.supported_languages[x],
                index=list(self.supported_languages.keys()).index(self.current_language)
            )
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º
        if st.sidebar.checkbox(self.t('system_info')):
            self._display_system_info()
    
    def _display_system_info(self):
        """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º"""
        
        system_info = {
            'Platform': platform.platform(),
            'Architecture': platform.machine(),
            'Python': platform.python_version(),
            'Advanced Modules': 'Available' if ADVANCED_MODULES_AVAILABLE else 'Not Available'
        }
        
        st.sidebar.markdown("### " + self.t('system_info'))
        for key, value in system_info.items():
            st.sidebar.text(f"{key}: {value}")
    
    def data_upload_section(self) -> Optional[pd.DataFrame]:
        """ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³"""
        
        st.sidebar.markdown("### " + self.t('data_upload'))
        
        uploaded_file = st.sidebar.file_uploader(
            self.t('upload_data'),
            type=['csv'],
            help="CSVå½¢å¼ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„"
        )
        
        if uploaded_file is not None:
            try:
                data = pd.read_csv(uploaded_file)
                
                st.sidebar.success(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {data.shape[0]}è¡Œ Ã— {data.shape[1]}åˆ—")
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
                with st.expander(self.t('data_preview')):
                    st.dataframe(data.head())
                    
                    # åŸºæœ¬æƒ…å ±
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("è¡Œæ•°", data.shape[0])
                    with col2:
                        st.metric("åˆ—æ•°", data.shape[1])
                    with col3:
                        st.metric("æ¬ æå€¤", data.isnull().sum().sum())
                
                return data
                
            except Exception as e:
                st.sidebar.error(f"{self.t('error')}: {str(e)}")
                return None
        
        return None
    
    def analysis_selection(self) -> str:
        """è§£æã‚¿ã‚¤ãƒ—é¸æŠ"""
        
        analysis_types = {
            'basic_stats': self.t('basic_stats'),
            'multivariate': self.t('multivariate'),
            'time_series': self.t('time_series'),
            'survival_analysis': self.t('survival_analysis'),
            'bayesian_analysis': self.t('bayesian_analysis'),
            'ml_pipeline': self.t('ml_pipeline')
        }
        
        return st.sidebar.selectbox(
            self.t('analysis_type'),
            options=list(analysis_types.keys()),
            format_func=lambda x: analysis_types[x]
        )
    
    def basic_statistics_analysis(self, data: pd.DataFrame):
        """åŸºæœ¬çµ±è¨ˆè§£æ"""
        
        st.header(self.t('basic_stats'))
        
        # æ•°å€¤å¤‰æ•°ã®é¸æŠ
        numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
        
        if not numeric_cols:
            st.warning("æ•°å€¤å¤‰æ•°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        selected_cols = st.multiselect("å¤‰æ•°é¸æŠ", numeric_cols, default=numeric_cols[:5])
        
        if selected_cols:
            # åŸºæœ¬çµ±è¨ˆé‡
            st.subheader("è¨˜è¿°çµ±è¨ˆ")
            st.dataframe(data[selected_cols].describe())
            
            # åˆ†å¸ƒãƒ—ãƒ­ãƒƒãƒˆ
            st.subheader("åˆ†å¸ƒãƒ—ãƒ­ãƒƒãƒˆ")
            for col in selected_cols[:4]:  # æœ€å¤§4ã¤ã¾ã§
                fig = px.histogram(data, x=col, title=f'{col} ã®åˆ†å¸ƒ')
                st.plotly_chart(fig, use_container_width=True)
            
            # ç›¸é–¢è¡Œåˆ—
            if len(selected_cols) > 1:
                st.subheader("ç›¸é–¢è¡Œåˆ—")
                corr_matrix = data[selected_cols].corr()
                
                fig = px.imshow(corr_matrix, 
                              title="ç›¸é–¢è¡Œåˆ—",
                              color_continuous_scale='RdBu_r',
                              aspect="auto")
                st.plotly_chart(fig, use_container_width=True)
    
    def multivariate_analysis(self, data: pd.DataFrame):
        """å¤šå¤‰é‡è§£æ"""
        
        if not ADVANCED_MODULES_AVAILABLE:
            st.error("é«˜åº¦è§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        st.header(self.t('multivariate'))
        
        with st.form("multivariate_form"):
            numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
            
            if len(numeric_cols) < 2:
                st.warning("å¤šå¤‰é‡è§£æã«ã¯æœ€ä½2ã¤ã®æ•°å€¤å¤‰æ•°ãŒå¿…è¦ã§ã™")
                return
            
            target_col = st.selectbox(self.t('target_variable'), numeric_cols)
            
            submitted = st.form_submit_button(self.t('run_analysis'))
            
            if submitted:
                with st.spinner(self.t('processing')):
                    try:
                        results = advanced_analyzer.multivariate_analysis(data, target_col)
                        
                        # PCAçµæœ
                        st.subheader("ä¸»æˆåˆ†åˆ†æçµæœ")
                        pca_results = results.get('pca', {})
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("KaiseråŸºæº–æˆåˆ†æ•°", pca_results.get('n_components_kaiser', 0))
                        with col2:
                            st.metric("å¯„ä¸ç‡80%æˆåˆ†æ•°", pca_results.get('n_components_80', 0))
                        
                        # å¯„ä¸ç‡ãƒ—ãƒ­ãƒƒãƒˆ
                        if 'explained_variance_ratio' in pca_results:
                            fig = go.Figure()
                            fig.add_trace(go.Scatter(
                                y=pca_results['explained_variance_ratio'],
                                mode='lines+markers',
                                name='å¯„ä¸ç‡'
                            ))
                            fig.add_trace(go.Scatter(
                                y=pca_results['cumulative_variance'],
                                mode='lines+markers',
                                name='ç´¯ç©å¯„ä¸ç‡'
                            ))
                            fig.update_layout(title="ä¸»æˆåˆ†ã®å¯„ä¸ç‡")
                            st.plotly_chart(fig, use_container_width=True)
                        
                        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ
                        st.subheader("ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ")
                        clustering_results = results.get('clustering', {})
                        
                        if 'kmeans' in clustering_results:
                            kmeans_results = clustering_results['kmeans']
                            st.metric("æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿æ•° (K-means)", kmeans_results.get('optimal_k', 0))
                        
                        st.json(results)
                        
                    except Exception as e:
                        st.error(f"{self.t('error')}: {str(e)}")
    
    def survival_analysis(self, data: pd.DataFrame):
        """ç”Ÿå­˜è§£æ"""
        
        if not ADVANCED_MODULES_AVAILABLE:
            st.error("é«˜åº¦è§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        st.header(self.t('survival_analysis'))
        
        with st.form("survival_form"):
            numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
            all_cols = data.columns.tolist()
            
            duration_col = st.selectbox(self.t('duration_variable'), numeric_cols)
            event_col = st.selectbox(self.t('event_variable'), numeric_cols)
            group_col = st.selectbox(self.t('group_variable'), ['None'] + all_cols)
            
            submitted = st.form_submit_button(self.t('run_analysis'))
            
            if submitted:
                with st.spinner(self.t('processing')):
                    try:
                        group_col_param = None if group_col == 'None' else group_col
                        
                        results = complete_survival_analyzer.kaplan_meier_analysis(
                            data, duration_col, event_col, group_col_param
                        )
                        
                        # å…¨ä½“çµæœ
                        st.subheader("Kaplan-Meierè§£æçµæœ")
                        overall_results = results.get('overall', {})
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("ä¸­å¤®ç”Ÿå­˜æ™‚é–“", f"{overall_results.get('median_survival', 'N/A')}")
                        with col2:
                            st.metric("å¯¾è±¡è€…æ•°", overall_results.get('n_subjects', 0))
                        with col3:
                            st.metric("ã‚¤ãƒ™ãƒ³ãƒˆæ•°", overall_results.get('n_events', 0))
                        
                        # ç”Ÿå­˜æ›²ç·šãƒ—ãƒ­ãƒƒãƒˆ
                        survival_function = overall_results.get('survival_function', {})
                        if survival_function:
                            fig = go.Figure()
                            
                            timeline = survival_function.get('timeline', [])
                            survival_prob = survival_function.get('survival_prob', [])
                            ci_lower = survival_function.get('ci_lower', [])
                            ci_upper = survival_function.get('ci_upper', [])
                            
                            # ç”Ÿå­˜æ›²ç·š
                            fig.add_trace(go.Scatter(
                                x=timeline, y=survival_prob,
                                mode='lines',
                                name='ç”Ÿå­˜ç¢ºç‡',
                                line=dict(color='blue')
                            ))
                            
                            # ä¿¡é ¼åŒºé–“
                            fig.add_trace(go.Scatter(
                                x=timeline + timeline[::-1],
                                y=ci_upper + ci_lower[::-1],
                                fill='tonexty',
                                fillcolor='rgba(0,0,255,0.2)',
                                line=dict(color='rgba(255,255,255,0)'),
                                name='95% ä¿¡é ¼åŒºé–“'
                            ))
                            
                            fig.update_layout(
                                title="Kaplan-Meierç”Ÿå­˜æ›²ç·š",
                                xaxis_title="æ™‚é–“",
                                yaxis_title="ç”Ÿå­˜ç¢ºç‡"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                        
                        # ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥çµæœ
                        if 'group_analysis' in results:
                            st.subheader("ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥è§£æ")
                            group_results = results['group_analysis']
                            
                            group_df = pd.DataFrame(group_results).T
                            st.dataframe(group_df)
                        
                        # çµ±è¨ˆæ¤œå®šçµæœ
                        if 'statistical_tests' in results:
                            st.subheader("çµ±è¨ˆæ¤œå®š")
                            tests = results['statistical_tests']
                            
                            if 'overall_logrank' in tests:
                                logrank = tests['overall_logrank']
                                st.write(f"Log-rankæ¤œå®š på€¤: {logrank.get('p_value', 'N/A')}")
                                st.write(f"æœ‰æ„æ€§: {'æœ‰æ„' if logrank.get('significant', False) else 'éæœ‰æ„'}")
                        
                    except Exception as e:
                        st.error(f"{self.t('error')}: {str(e)}")
    
    def machine_learning_pipeline(self, data: pd.DataFrame):
        """æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
        
        if not ADVANCED_MODULES_AVAILABLE:
            st.error("é«˜åº¦è§£æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        st.header(self.t('ml_pipeline'))
        
        with st.form("ml_form"):
            all_cols = data.columns.tolist()
            
            target_col = st.selectbox(self.t('target_variable'), all_cols)
            task_type = st.selectbox("ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—", ['auto', 'classification', 'regression'])
            test_size = st.slider("ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º", 0.1, 0.5, 0.2, 0.05)
            optimize_hyperparams = st.checkbox("ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–", value=True)
            
            submitted = st.form_submit_button(self.t('run_analysis'))
            
            if submitted:
                with st.spinner(self.t('processing')):
                    try:
                        results = ml_pipeline_automator.complete_ml_pipeline(
                            data, target_col, task_type, test_size, optimize_hyperparams
                        )
                        
                        # æœ€çµ‚è©•ä¾¡çµæœ
                        st.subheader(self.t('model_performance'))
                        
                        if 'final_evaluation' in results:
                            metrics = results['final_evaluation']
                            
                            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
                            metric_cols = st.columns(len(metrics))
                            for i, (metric, value) in enumerate(metrics.items()):
                                if isinstance(value, (int, float)):
                                    metric_cols[i].metric(metric, f"{value:.4f}")
                        
                        # ãƒ¢ãƒ‡ãƒ«é¸æŠçµæœ
                        if 'model_selection' in results:
                            st.subheader("ãƒ¢ãƒ‡ãƒ«é¸æŠçµæœ")
                            model_selection = results['model_selection']
                            
                            if 'best_model' in model_selection:
                                best_model = model_selection['best_model']
                                st.write(f"æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«: {best_model.get('name', 'N/A')}")
                                st.write(f"ã‚¹ã‚³ã‚¢: {best_model.get('score', 'N/A'):.4f}")
                            
                            # CVçµæœ
                            if 'cv_results' in model_selection:
                                cv_results = model_selection['cv_results']
                                
                                cv_df = pd.DataFrame({
                                    'Model': list(cv_results.keys()),
                                    'Mean Score': [r.get('mean_score', 0) if isinstance(r, dict) else 0 
                                                 for r in cv_results.values()],
                                    'Std Score': [r.get('std_score', 0) if isinstance(r, dict) else 0 
                                                for r in cv_results.values()]
                                })
                                
                                fig = px.bar(cv_df, x='Model', y='Mean Score', 
                                           error_y='Std Score',
                                           title="ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ")
                                st.plotly_chart(fig, use_container_width=True)
                        
                        # ç‰¹å¾´é¸æŠçµæœ
                        if 'feature_selection' in results:
                            st.subheader(self.t('feature_importance'))
                            feature_selection = results['feature_selection']
                            
                            if 'feature_importance' in feature_selection:
                                importance_data = feature_selection['feature_importance']
                                importance_df = pd.DataFrame(importance_data)
                                
                                fig = px.bar(importance_df.head(10), 
                                           x='importance', y='feature',
                                           orientation='h',
                                           title="ç‰¹å¾´é‡é‡è¦åº¦ (Top 10)")
                                st.plotly_chart(fig, use_container_width=True)
                        
                        # çµæœè©³ç´°
                        with st.expander("è©³ç´°çµæœ"):
                            st.json(results)
                        
                    except Exception as e:
                        st.error(f"{self.t('error')}: {str(e)}")
    
    def run(self):
        """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        self.render_header()
        
        # ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        data = self.data_upload_section()
        
        if data is not None:
            # è§£æã‚¿ã‚¤ãƒ—é¸æŠ
            analysis_type = self.analysis_selection()
            
            # è§£æå®Ÿè¡Œ
            if analysis_type == 'basic_stats':
                self.basic_statistics_analysis(data)
            elif analysis_type == 'multivariate':
                self.multivariate_analysis(data)
            elif analysis_type == 'survival_analysis':
                self.survival_analysis(data)
            elif analysis_type == 'ml_pipeline':
                self.machine_learning_pipeline(data)
            else:
                st.info(f"{analysis_type} ã¯ç¾åœ¨é–‹ç™ºä¸­ã§ã™")
        
        else:
            st.info(self.t('no_data'))
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
            if st.button("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"):
                sample_data = self._generate_sample_data()
                st.session_state['sample_data'] = sample_data
                st.success("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
                st.rerun()
    
    def _generate_sample_data(self) -> pd.DataFrame:
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        
        np.random.seed(42)
        n_samples = 200
        
        data = pd.DataFrame({
            'age': np.random.normal(50, 15, n_samples),
            'income': np.random.lognormal(10, 0.5, n_samples),
            'education_years': np.random.randint(8, 20, n_samples),
            'gender': np.random.choice(['Male', 'Female'], n_samples),
            'region': np.random.choice(['North', 'South', 'East', 'West'], n_samples),
            'satisfaction': np.random.randint(1, 6, n_samples),
            'purchase_amount': np.random.exponential(100, n_samples),
            'time_to_event': np.random.exponential(12, n_samples),
            'event_occurred': np.random.binomial(1, 0.7, n_samples)
        })
        
        return data

# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    
    dashboard = MultilingualWebDashboard()
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if 'sample_data' in st.session_state:
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯è¡¨ç¤º
        st.sidebar.success("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
        if st.sidebar.button("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨"):
            data = st.session_state['sample_data']
            st.session_state['uploaded_data'] = data
    
    dashboard.run()

if __name__ == "__main__":
    main() 